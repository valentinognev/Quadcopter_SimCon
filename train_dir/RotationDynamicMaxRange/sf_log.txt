[2025-09-21 17:34:24,474][3092699] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:34:24,477][3092699] Rollout worker 0 uses device cpu
[2025-09-21 17:34:24,486][3092699] InferenceWorker_p0-w0: min num requests: 1
[2025-09-21 17:34:24,493][3092699] WARNING! It is generally recommended to enable Fixed KL loss (https://arxiv.org/pdf/1707.06347.pdf) for continuous action tasks to avoid potential numerical issues. I.e. set --kl_loss_coeff=0.1
[2025-09-21 17:34:24,494][3092699] Starting seed is not provided
[2025-09-21 17:34:24,494][3092699] Initializing actor-critic model on device cpu
[2025-09-21 17:34:24,497][3092699] RunningMeanStd input shape: (4,)
[2025-09-21 17:34:24,500][3092699] RunningMeanStd input shape: (1,)
[2025-09-21 17:34:24,675][3092699] Created Actor Critic model with architecture:
[2025-09-21 17:34:24,675][3092699] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=6, bias=True)
  )
)
[2025-09-21 17:34:25,336][3092699] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-21 17:34:26,589][3092699] No checkpoints found
[2025-09-21 17:34:26,589][3092699] Did not load from checkpoint, starting from scratch!
[2025-09-21 17:34:26,589][3092699] Initialized policy 0 weights for model version 0
[2025-09-21 17:34:26,589][3092699] LearnerWorker_p0 finished initialization!
[2025-09-21 17:34:26,591][3092699] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:34:26,592][3092699] Inference worker 0-0 is ready!
[2025-09-21 17:34:26,592][3092699] All inference workers are ready! Signal rollout workers to start!
[2025-09-21 17:34:26,597][3092699] Decorrelating experience for 0 frames...
[2025-09-21 17:34:26,643][3092699] EvtLoop [Runner_EvtLoop, process=main process 3092699] unhandled exception in slot='advance_rollouts' connected to emitter=Emitter(object_id='InferenceWorker_p0-w0', signal_name='advance0'), args=(0, 0)
Traceback (most recent call last):
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/signal_slot/signal_slot.py", line 355, in _process_signal
    slot_callable(*args)
  File "/home/valentin/RL/sample-factory/sample_factory/algo/sampling/rollout_worker.py", line 240, in advance_rollouts
    complete_rollouts, episodic_stats = runner.advance_rollouts(policy_id, self.timing)
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/sample-factory/sample_factory/algo/sampling/non_batched_sampling.py", line 634, in advance_rollouts
    new_obs, rewards, terminated, truncated, infos = e.step(actions)
                                                     ^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/gymnasium/core.py", line 408, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/sample-factory/sample_factory/algo/utils/make_env.py", line 129, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
                                            ^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/sample-factory/sample_factory/algo/utils/make_env.py", line 115, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
                                            ^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/waypoint_follow/envs/point_trajectory_env.py", line 301, in step
    r = np.min(r, self.max_range)
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/numpy/core/fromnumeric.py", line 2953, in min
    return _wrapreduction(a, np.minimum, 'min', axis, None, out,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return reduction(axis=axis, out=out, **passkwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/numpy/core/_methods.py", line 45, in _amin
    return umr_minimum(a, axis, None, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'numpy.float64' object cannot be interpreted as an integer
[2025-09-21 17:34:26,647][3092699] Unhandled exception 'numpy.float64' object cannot be interpreted as an integer in evt loop Runner_EvtLoop
[2025-09-21 17:34:26,648][3092699] Uncaught exception in Runner evt loop
Traceback (most recent call last):
  File "/home/valentin/RL/sample-factory/sample_factory/algo/runners/runner.py", line 751, in run
    evt_loop_status = self.event_loop.exec()
                      ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/signal_slot/signal_slot.py", line 403, in exec
    raise exc
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/signal_slot/signal_slot.py", line 399, in exec
    while self._loop_iteration():
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/signal_slot/signal_slot.py", line 383, in _loop_iteration
    self._process_signal(s)
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/signal_slot/signal_slot.py", line 358, in _process_signal
    raise exc
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/signal_slot/signal_slot.py", line 355, in _process_signal
    slot_callable(*args)
  File "/home/valentin/RL/sample-factory/sample_factory/algo/sampling/rollout_worker.py", line 240, in advance_rollouts
    complete_rollouts, episodic_stats = runner.advance_rollouts(policy_id, self.timing)
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/sample-factory/sample_factory/algo/sampling/non_batched_sampling.py", line 634, in advance_rollouts
    new_obs, rewards, terminated, truncated, infos = e.step(actions)
                                                     ^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/gymnasium/core.py", line 408, in step
    return self.env.step(action)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/sample-factory/sample_factory/algo/utils/make_env.py", line 129, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
                                            ^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/sample-factory/sample_factory/algo/utils/make_env.py", line 115, in step
    obs, rew, terminated, truncated, info = self.env.step(action)
                                            ^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/RL/waypoint_follow/envs/point_trajectory_env.py", line 301, in step
    r = np.min(r, self.max_range)
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/numpy/core/fromnumeric.py", line 2953, in min
    return _wrapreduction(a, np.minimum, 'min', axis, None, out,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return reduction(axis=axis, out=out, **passkwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/valentin/anaconda3/envs/swarm-rl/lib/python3.11/site-packages/numpy/core/_methods.py", line 45, in _amin
    return umr_minimum(a, axis, None, out, keepdims, initial, where)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'numpy.float64' object cannot be interpreted as an integer
[2025-09-21 17:34:26,649][3092699] Runner profile tree view:
main_loop: 2.1574
[2025-09-21 17:34:26,649][3092699] Collected {0: 0}, FPS: 0.0
[2025-09-21 17:34:54,444][3092992] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:34:54,448][3092992] Rollout worker 0 uses device cpu
[2025-09-21 17:34:54,458][3092992] InferenceWorker_p0-w0: min num requests: 1
[2025-09-21 17:34:54,464][3092992] WARNING! It is generally recommended to enable Fixed KL loss (https://arxiv.org/pdf/1707.06347.pdf) for continuous action tasks to avoid potential numerical issues. I.e. set --kl_loss_coeff=0.1
[2025-09-21 17:34:54,465][3092992] Starting seed is not provided
[2025-09-21 17:34:54,466][3092992] Initializing actor-critic model on device cpu
[2025-09-21 17:34:54,468][3092992] RunningMeanStd input shape: (4,)
[2025-09-21 17:34:54,470][3092992] RunningMeanStd input shape: (1,)
[2025-09-21 17:34:54,645][3092992] Created Actor Critic model with architecture:
[2025-09-21 17:34:54,645][3092992] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=6, bias=True)
  )
)
[2025-09-21 17:34:54,963][3092992] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-21 17:34:56,104][3092992] No checkpoints found
[2025-09-21 17:34:56,105][3092992] Did not load from checkpoint, starting from scratch!
[2025-09-21 17:34:56,105][3092992] Initialized policy 0 weights for model version 0
[2025-09-21 17:34:56,105][3092992] LearnerWorker_p0 finished initialization!
[2025-09-21 17:34:56,107][3092992] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:34:56,107][3092992] Inference worker 0-0 is ready!
[2025-09-21 17:34:56,107][3092992] All inference workers are ready! Signal rollout workers to start!
[2025-09-21 17:34:56,113][3092992] Decorrelating experience for 0 frames...
[2025-09-21 17:35:22,314][3093464] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:35:22,317][3093464] Rollout worker 0 uses device cpu
[2025-09-21 17:35:22,324][3093464] InferenceWorker_p0-w0: min num requests: 1
[2025-09-21 17:35:22,330][3093464] WARNING! It is generally recommended to enable Fixed KL loss (https://arxiv.org/pdf/1707.06347.pdf) for continuous action tasks to avoid potential numerical issues. I.e. set --kl_loss_coeff=0.1
[2025-09-21 17:35:22,331][3093464] Starting seed is not provided
[2025-09-21 17:35:22,331][3093464] Initializing actor-critic model on device cpu
[2025-09-21 17:35:22,333][3093464] RunningMeanStd input shape: (4,)
[2025-09-21 17:35:22,335][3093464] RunningMeanStd input shape: (1,)
[2025-09-21 17:35:22,552][3093464] Created Actor Critic model with architecture:
[2025-09-21 17:35:22,552][3093464] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=6, bias=True)
  )
)
[2025-09-21 17:35:22,873][3093464] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-21 17:35:24,022][3093464] No checkpoints found
[2025-09-21 17:35:24,022][3093464] Did not load from checkpoint, starting from scratch!
[2025-09-21 17:35:24,022][3093464] Initialized policy 0 weights for model version 0
[2025-09-21 17:35:24,023][3093464] LearnerWorker_p0 finished initialization!
[2025-09-21 17:35:24,025][3093464] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:35:24,025][3093464] Inference worker 0-0 is ready!
[2025-09-21 17:35:24,026][3093464] All inference workers are ready! Signal rollout workers to start!
[2025-09-21 17:35:44,028][3093464] Decorrelating experience for 0 frames...
[2025-09-21 17:35:44,049][3093464] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:36:19,624][3094045] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:36:19,627][3094045] Rollout worker 0 uses device cpu
[2025-09-21 17:36:19,635][3094045] InferenceWorker_p0-w0: min num requests: 1
[2025-09-21 17:36:19,640][3094045] WARNING! It is generally recommended to enable Fixed KL loss (https://arxiv.org/pdf/1707.06347.pdf) for continuous action tasks to avoid potential numerical issues. I.e. set --kl_loss_coeff=0.1
[2025-09-21 17:36:19,640][3094045] Starting seed is not provided
[2025-09-21 17:36:19,640][3094045] Initializing actor-critic model on device cpu
[2025-09-21 17:36:19,641][3094045] RunningMeanStd input shape: (4,)
[2025-09-21 17:36:19,642][3094045] RunningMeanStd input shape: (1,)
[2025-09-21 17:36:19,802][3094045] Created Actor Critic model with architecture:
[2025-09-21 17:36:19,803][3094045] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=6, bias=True)
  )
)
[2025-09-21 17:36:20,151][3094045] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-21 17:36:21,130][3094045] No checkpoints found
[2025-09-21 17:36:21,130][3094045] Did not load from checkpoint, starting from scratch!
[2025-09-21 17:36:21,130][3094045] Initialized policy 0 weights for model version 0
[2025-09-21 17:36:21,131][3094045] LearnerWorker_p0 finished initialization!
[2025-09-21 17:36:21,133][3094045] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:36:21,133][3094045] Inference worker 0-0 is ready!
[2025-09-21 17:36:21,133][3094045] All inference workers are ready! Signal rollout workers to start!
[2025-09-21 17:37:21,921][3094848] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:37:21,924][3094848] Rollout worker 0 uses device cpu
[2025-09-21 17:37:21,932][3094848] InferenceWorker_p0-w0: min num requests: 1
[2025-09-21 17:37:21,938][3094848] WARNING! It is generally recommended to enable Fixed KL loss (https://arxiv.org/pdf/1707.06347.pdf) for continuous action tasks to avoid potential numerical issues. I.e. set --kl_loss_coeff=0.1
[2025-09-21 17:37:21,939][3094848] Starting seed is not provided
[2025-09-21 17:37:21,939][3094848] Initializing actor-critic model on device cpu
[2025-09-21 17:37:21,941][3094848] RunningMeanStd input shape: (4,)
[2025-09-21 17:37:21,943][3094848] RunningMeanStd input shape: (1,)
[2025-09-21 17:37:22,136][3094848] Created Actor Critic model with architecture:
[2025-09-21 17:37:22,137][3094848] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=6, bias=True)
  )
)
[2025-09-21 17:37:22,479][3094848] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-21 17:37:23,892][3094848] No checkpoints found
[2025-09-21 17:37:23,893][3094848] Did not load from checkpoint, starting from scratch!
[2025-09-21 17:37:23,893][3094848] Initialized policy 0 weights for model version 0
[2025-09-21 17:37:23,893][3094848] LearnerWorker_p0 finished initialization!
[2025-09-21 17:37:23,895][3094848] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:37:23,895][3094848] Inference worker 0-0 is ready!
[2025-09-21 17:37:23,895][3094848] All inference workers are ready! Signal rollout workers to start!
[2025-09-21 17:37:23,900][3094848] Decorrelating experience for 0 frames...
[2025-09-21 17:37:28,017][3094848] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 1.9. Samples: 8. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:37:32,974][3094848] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 30.4. Samples: 276. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:37:37,976][3094848] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 28.8. Samples: 406. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:37:41,949][3094848] Heartbeat connected on Batcher_0
[2025-09-21 17:37:41,950][3094848] Heartbeat connected on LearnerWorker_p0
[2025-09-21 17:37:41,952][3094848] Heartbeat connected on InferenceWorker_p0-w0
[2025-09-21 17:37:41,967][3094848] Heartbeat connected on RolloutWorker_w0
[2025-09-21 17:37:42,978][3094848] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 38.7. Samples: 738. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:37:48,001][3094848] Fps is (10 sec: 102.1, 60 sec: 42.5, 300 sec: 42.5). Total num frames: 1024. Throughput: 0: 37.0. Samples: 892. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-21 17:37:52,977][3094848] Fps is (10 sec: 102.4, 60 sec: 35.2, 300 sec: 35.2). Total num frames: 1024. Throughput: 0: 38.2. Samples: 1112. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-21 17:39:33,783][3096047] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:39:33,785][3096047] Rollout worker 0 uses device cpu
[2025-09-21 17:40:08,000][3096566] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:40:08,003][3096566] Rollout worker 0 uses device cpu
[2025-09-21 17:40:08,056][3096566] InferenceWorker_p0-w0: min num requests: 1
[2025-09-21 17:40:08,073][3096566] Starting all processes...
[2025-09-21 17:40:08,074][3096566] Starting process learner_proc0
[2025-09-21 17:40:08,122][3096566] Starting all processes...
[2025-09-21 17:40:08,143][3096566] Starting process inference_proc0-0
[2025-09-21 17:40:08,150][3096566] Starting process rollout_proc0
[2025-09-21 17:40:10,816][3096753] WARNING! It is generally recommended to enable Fixed KL loss (https://arxiv.org/pdf/1707.06347.pdf) for continuous action tasks to avoid potential numerical issues. I.e. set --kl_loss_coeff=0.1
[2025-09-21 17:40:10,817][3096753] Starting seed is not provided
[2025-09-21 17:40:10,817][3096753] Initializing actor-critic model on device cpu
[2025-09-21 17:40:10,817][3096753] RunningMeanStd input shape: (4,)
[2025-09-21 17:40:10,818][3096753] RunningMeanStd input shape: (1,)
[2025-09-21 17:40:10,879][3096753] Created Actor Critic model with architecture:
[2025-09-21 17:40:10,879][3096753] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=6, bias=True)
  )
)
[2025-09-21 17:40:11,036][3096774] Worker 0 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:40:11,114][3096753] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-21 17:40:12,026][3096753] No checkpoints found
[2025-09-21 17:40:12,026][3096753] Did not load from checkpoint, starting from scratch!
[2025-09-21 17:40:12,027][3096753] Initialized policy 0 weights for model version 0
[2025-09-21 17:40:12,028][3096753] LearnerWorker_p0 finished initialization!
[2025-09-21 17:40:12,031][3096775] RunningMeanStd input shape: (4,)
[2025-09-21 17:40:12,032][3096775] RunningMeanStd input shape: (1,)
[2025-09-21 17:40:12,095][3096566] Inference worker 0-0 is ready!
[2025-09-21 17:40:12,095][3096566] All inference workers are ready! Signal rollout workers to start!
[2025-09-21 17:40:12,103][3096774] Decorrelating experience for 0 frames...
[2025-09-21 17:40:14,050][3096566] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:40:19,050][3096566] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 71.4. Samples: 357. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:40:24,050][3096566] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 56.7. Samples: 567. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:40:28,032][3096566] Heartbeat connected on Batcher_0
[2025-09-21 17:40:28,042][3096566] Heartbeat connected on LearnerWorker_p0
[2025-09-21 17:40:28,075][3096566] Heartbeat connected on RolloutWorker_w0
[2025-09-21 17:40:28,094][3096566] Heartbeat connected on InferenceWorker_p0-w0
[2025-09-21 17:40:29,050][3096566] Fps is (10 sec: 102.4, 60 sec: 68.3, 300 sec: 68.3). Total num frames: 1024. Throughput: 0: 63.8. Samples: 957. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-21 17:40:29,050][3096566] Avg episode reward: [(0, '-0.055')]
[2025-09-21 17:40:34,050][3096566] Fps is (10 sec: 102.4, 60 sec: 51.2, 300 sec: 51.2). Total num frames: 1024. Throughput: 0: 62.0. Samples: 1241. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-21 17:40:34,050][3096566] Avg episode reward: [(0, '-0.055')]
[2025-09-21 17:40:39,051][3096566] Fps is (10 sec: 0.0, 60 sec: 41.0, 300 sec: 41.0). Total num frames: 1024. Throughput: 0: 56.4. Samples: 1410. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-21 17:40:39,051][3096566] Avg episode reward: [(0, '-0.055')]
[2025-09-21 17:40:44,050][3096566] Fps is (10 sec: 0.0, 60 sec: 34.1, 300 sec: 34.1). Total num frames: 1024. Throughput: 0: 59.4. Samples: 1783. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-21 17:40:44,051][3096566] Avg episode reward: [(0, '-0.055')]
[2025-09-21 17:40:49,051][3096566] Fps is (10 sec: 102.4, 60 sec: 58.5, 300 sec: 58.5). Total num frames: 2048. Throughput: 0: 60.0. Samples: 2099. Policy #0 lag: (min: 0.0, avg: 0.0, max: 1.0)
[2025-09-21 17:40:49,051][3096566] Avg episode reward: [(0, '-0.503')]
[2025-09-21 17:40:54,050][3096566] Fps is (10 sec: 102.4, 60 sec: 51.2, 300 sec: 51.2). Total num frames: 2048. Throughput: 0: 56.1. Samples: 2245. Policy #0 lag: (min: 0.0, avg: 0.0, max: 1.0)
[2025-09-21 17:40:54,050][3096566] Avg episode reward: [(0, '-0.503')]
[2025-09-21 17:40:59,050][3096566] Fps is (10 sec: 0.0, 60 sec: 45.5, 300 sec: 45.5). Total num frames: 2048. Throughput: 0: 57.5. Samples: 2587. Policy #0 lag: (min: 0.0, avg: 0.0, max: 1.0)
[2025-09-21 17:40:59,050][3096566] Avg episode reward: [(0, '-0.503')]
[2025-09-21 17:41:04,050][3096566] Fps is (10 sec: 0.0, 60 sec: 41.0, 300 sec: 41.0). Total num frames: 2048. Throughput: 0: 57.0. Samples: 2922. Policy #0 lag: (min: 0.0, avg: 0.0, max: 1.0)
[2025-09-21 17:41:04,051][3096566] Avg episode reward: [(0, '-0.503')]
[2025-09-21 17:41:09,050][3096566] Fps is (10 sec: 102.4, 60 sec: 55.9, 300 sec: 55.9). Total num frames: 3072. Throughput: 0: 54.8. Samples: 3035. Policy #0 lag: (min: 0.0, avg: 0.0, max: 1.0)
[2025-09-21 17:41:09,050][3096566] Avg episode reward: [(0, '-0.635')]
[2025-09-21 17:41:14,050][3096566] Fps is (10 sec: 102.4, 60 sec: 51.2, 300 sec: 51.2). Total num frames: 3072. Throughput: 0: 53.1. Samples: 3348. Policy #0 lag: (min: 0.0, avg: 0.0, max: 1.0)
[2025-09-21 17:41:14,051][3096566] Avg episode reward: [(0, '-0.635')]
[2025-09-21 17:42:52,874][3098297] Saving configuration to ./train_dir/RotationDynamicMaxRange/config.json...
[2025-09-21 17:42:52,877][3098297] Rollout worker 0 uses device cpu
[2025-09-21 17:42:52,877][3098297] Rollout worker 1 uses device cpu
[2025-09-21 17:42:52,878][3098297] Rollout worker 2 uses device cpu
[2025-09-21 17:42:52,878][3098297] Rollout worker 3 uses device cpu
[2025-09-21 17:42:52,878][3098297] Rollout worker 4 uses device cpu
[2025-09-21 17:42:52,879][3098297] Rollout worker 5 uses device cpu
[2025-09-21 17:42:52,879][3098297] Rollout worker 6 uses device cpu
[2025-09-21 17:42:52,879][3098297] Rollout worker 7 uses device cpu
[2025-09-21 17:42:52,879][3098297] Rollout worker 8 uses device cpu
[2025-09-21 17:42:52,879][3098297] Rollout worker 9 uses device cpu
[2025-09-21 17:42:52,880][3098297] Rollout worker 10 uses device cpu
[2025-09-21 17:42:52,880][3098297] Rollout worker 11 uses device cpu
[2025-09-21 17:42:52,880][3098297] Rollout worker 12 uses device cpu
[2025-09-21 17:42:52,880][3098297] Rollout worker 13 uses device cpu
[2025-09-21 17:42:52,880][3098297] Rollout worker 14 uses device cpu
[2025-09-21 17:42:52,881][3098297] Rollout worker 15 uses device cpu
[2025-09-21 17:42:52,881][3098297] Rollout worker 16 uses device cpu
[2025-09-21 17:42:52,881][3098297] Rollout worker 17 uses device cpu
[2025-09-21 17:42:52,881][3098297] Rollout worker 18 uses device cpu
[2025-09-21 17:42:52,881][3098297] Rollout worker 19 uses device cpu
[2025-09-21 17:42:52,882][3098297] Rollout worker 20 uses device cpu
[2025-09-21 17:42:52,882][3098297] Rollout worker 21 uses device cpu
[2025-09-21 17:42:52,882][3098297] Rollout worker 22 uses device cpu
[2025-09-21 17:42:52,882][3098297] Rollout worker 23 uses device cpu
[2025-09-21 17:42:52,882][3098297] Rollout worker 24 uses device cpu
[2025-09-21 17:42:52,883][3098297] Rollout worker 25 uses device cpu
[2025-09-21 17:42:52,883][3098297] Rollout worker 26 uses device cpu
[2025-09-21 17:42:52,883][3098297] Rollout worker 27 uses device cpu
[2025-09-21 17:42:52,883][3098297] Rollout worker 28 uses device cpu
[2025-09-21 17:42:52,883][3098297] Rollout worker 29 uses device cpu
[2025-09-21 17:42:52,884][3098297] Rollout worker 30 uses device cpu
[2025-09-21 17:42:52,884][3098297] Rollout worker 31 uses device cpu
[2025-09-21 17:42:52,965][3098297] InferenceWorker_p0-w0: min num requests: 10
[2025-09-21 17:42:53,151][3098297] Starting all processes...
[2025-09-21 17:42:53,152][3098297] Starting process learner_proc0
[2025-09-21 17:42:53,201][3098297] Starting all processes...
[2025-09-21 17:42:53,239][3098297] Starting process inference_proc0-0
[2025-09-21 17:42:53,239][3098297] Starting process rollout_proc0
[2025-09-21 17:42:53,248][3098297] Starting process rollout_proc1
[2025-09-21 17:42:53,257][3098297] Starting process rollout_proc2
[2025-09-21 17:42:53,262][3098297] Starting process rollout_proc3
[2025-09-21 17:42:53,263][3098297] Starting process rollout_proc4
[2025-09-21 17:42:53,264][3098297] Starting process rollout_proc5
[2025-09-21 17:42:53,264][3098297] Starting process rollout_proc6
[2025-09-21 17:42:53,265][3098297] Starting process rollout_proc7
[2025-09-21 17:42:53,265][3098297] Starting process rollout_proc8
[2025-09-21 17:42:53,266][3098297] Starting process rollout_proc9
[2025-09-21 17:42:53,266][3098297] Starting process rollout_proc10
[2025-09-21 17:42:53,267][3098297] Starting process rollout_proc11
[2025-09-21 17:42:53,268][3098297] Starting process rollout_proc12
[2025-09-21 17:42:53,283][3098297] Starting process rollout_proc13
[2025-09-21 17:42:53,284][3098297] Starting process rollout_proc14
[2025-09-21 17:42:53,286][3098297] Starting process rollout_proc15
[2025-09-21 17:42:53,288][3098297] Starting process rollout_proc16
[2025-09-21 17:42:53,288][3098297] Starting process rollout_proc17
[2025-09-21 17:42:53,288][3098297] Starting process rollout_proc18
[2025-09-21 17:42:53,290][3098297] Starting process rollout_proc19
[2025-09-21 17:42:53,290][3098297] Starting process rollout_proc20
[2025-09-21 17:42:53,311][3098297] Starting process rollout_proc21
[2025-09-21 17:42:53,311][3098297] Starting process rollout_proc22
[2025-09-21 17:42:53,325][3098297] Starting process rollout_proc23
[2025-09-21 17:42:53,350][3098297] Starting process rollout_proc24
[2025-09-21 17:42:53,357][3098297] Starting process rollout_proc25
[2025-09-21 17:42:53,367][3098297] Starting process rollout_proc26
[2025-09-21 17:42:53,391][3098297] Starting process rollout_proc27
[2025-09-21 17:42:53,394][3098297] Starting process rollout_proc28
[2025-09-21 17:42:53,398][3098297] Starting process rollout_proc30
[2025-09-21 17:42:53,396][3098297] Starting process rollout_proc29
[2025-09-21 17:42:53,413][3098297] Starting process rollout_proc31
[2025-09-21 17:42:56,281][3098570] WARNING! It is generally recommended to enable Fixed KL loss (https://arxiv.org/pdf/1707.06347.pdf) for continuous action tasks to avoid potential numerical issues. I.e. set --kl_loss_coeff=0.1
[2025-09-21 17:42:56,282][3098570] Starting seed is not provided
[2025-09-21 17:42:56,282][3098570] Initializing actor-critic model on device cpu
[2025-09-21 17:42:56,283][3098570] RunningMeanStd input shape: (4,)
[2025-09-21 17:42:56,283][3098570] RunningMeanStd input shape: (1,)
[2025-09-21 17:42:56,313][3098655] Worker 7 uses CPU cores [7]
[2025-09-21 17:42:56,348][3098570] Created Actor Critic model with architecture:
[2025-09-21 17:42:56,348][3098570] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Linear)
          (5): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=6, bias=True)
  )
)
[2025-09-21 17:42:56,633][3098570] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-21 17:42:57,164][3098650] Worker 3 uses CPU cores [3]
[2025-09-21 17:42:57,710][3098648] Worker 1 uses CPU cores [1]
[2025-09-21 17:42:58,015][3098570] No checkpoints found
[2025-09-21 17:42:58,015][3098570] Did not load from checkpoint, starting from scratch!
[2025-09-21 17:42:58,016][3098570] Initialized policy 0 weights for model version 0
[2025-09-21 17:42:58,022][3098570] LearnerWorker_p0 finished initialization!
[2025-09-21 17:42:58,030][3098647] RunningMeanStd input shape: (4,)
[2025-09-21 17:42:58,033][3098647] RunningMeanStd input shape: (1,)
[2025-09-21 17:42:58,119][3098652] Worker 2 uses CPU cores [2]
[2025-09-21 17:42:58,172][3098297] Inference worker 0-0 is ready!
[2025-09-21 17:42:58,172][3098297] All inference workers are ready! Signal rollout workers to start!
[2025-09-21 17:42:58,180][3098650] Decorrelating experience for 0 frames...
[2025-09-21 17:42:58,181][3098648] Decorrelating experience for 0 frames...
[2025-09-21 17:42:58,181][3098655] Decorrelating experience for 0 frames...
[2025-09-21 17:42:58,182][3098648] Decorrelating experience for 32 frames...
[2025-09-21 17:42:58,182][3098650] Decorrelating experience for 32 frames...
[2025-09-21 17:42:58,183][3098655] Decorrelating experience for 32 frames...
[2025-09-21 17:42:58,369][3098652] Decorrelating experience for 0 frames...
[2025-09-21 17:42:58,381][3098652] Decorrelating experience for 32 frames...
[2025-09-21 17:42:58,753][3098297] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:42:58,867][3098651] Worker 4 uses CPU cores [4]
[2025-09-21 17:42:58,913][3098651] Decorrelating experience for 0 frames...
[2025-09-21 17:42:58,914][3098651] Decorrelating experience for 32 frames...
[2025-09-21 17:42:58,921][3098648] Decorrelating experience for 64 frames...
[2025-09-21 17:42:58,943][3098655] Decorrelating experience for 64 frames...
[2025-09-21 17:42:59,219][3098649] Worker 0 uses CPU cores [0]
[2025-09-21 17:42:59,341][3098649] Decorrelating experience for 0 frames...
[2025-09-21 17:42:59,342][3098649] Decorrelating experience for 32 frames...
[2025-09-21 17:42:59,526][3098650] Decorrelating experience for 64 frames...
[2025-09-21 17:42:59,717][3098652] Decorrelating experience for 64 frames...
[2025-09-21 17:43:00,031][3098651] Decorrelating experience for 64 frames...
[2025-09-21 17:43:00,151][3098663] Worker 12 uses CPU cores [12]
[2025-09-21 17:43:00,166][3098654] Worker 6 uses CPU cores [6]
[2025-09-21 17:43:00,257][3098663] Decorrelating experience for 0 frames...
[2025-09-21 17:43:00,277][3098663] Decorrelating experience for 32 frames...
[2025-09-21 17:43:00,372][3098654] Decorrelating experience for 0 frames...
[2025-09-21 17:43:00,374][3098654] Decorrelating experience for 32 frames...
[2025-09-21 17:43:00,624][3098657] Worker 11 uses CPU cores [11]
[2025-09-21 17:43:00,715][3098657] Decorrelating experience for 0 frames...
[2025-09-21 17:43:00,718][3098657] Decorrelating experience for 32 frames...
[2025-09-21 17:43:00,730][3098655] Decorrelating experience for 96 frames...
[2025-09-21 17:43:00,853][3098649] Decorrelating experience for 64 frames...
[2025-09-21 17:43:01,635][3098667] Worker 15 uses CPU cores [15]
[2025-09-21 17:43:01,770][3098667] Decorrelating experience for 0 frames...
[2025-09-21 17:43:01,788][3098667] Decorrelating experience for 32 frames...
[2025-09-21 17:43:01,898][3098663] Decorrelating experience for 64 frames...
[2025-09-21 17:43:02,000][3098648] Decorrelating experience for 96 frames...
[2025-09-21 17:43:02,048][3098668] Worker 14 uses CPU cores [14]
[2025-09-21 17:43:02,156][3098654] Decorrelating experience for 64 frames...
[2025-09-21 17:43:02,364][3098650] Decorrelating experience for 96 frames...
[2025-09-21 17:43:02,368][3098651] Decorrelating experience for 96 frames...
[2025-09-21 17:43:02,355][3098668] Decorrelating experience for 0 frames...
[2025-09-21 17:43:02,409][3098657] Decorrelating experience for 64 frames...
[2025-09-21 17:43:02,405][3098668] Decorrelating experience for 32 frames...
[2025-09-21 17:43:02,444][3098658] Worker 9 uses CPU cores [9]
[2025-09-21 17:43:02,645][3098658] Decorrelating experience for 0 frames...
[2025-09-21 17:43:02,675][3098658] Decorrelating experience for 32 frames...
[2025-09-21 17:43:03,128][3098653] Worker 5 uses CPU cores [5]
[2025-09-21 17:43:03,224][3098652] Decorrelating experience for 96 frames...
[2025-09-21 17:43:03,319][3098667] Decorrelating experience for 64 frames...
[2025-09-21 17:43:03,352][3098653] Decorrelating experience for 0 frames...
[2025-09-21 17:43:03,416][3098653] Decorrelating experience for 32 frames...
[2025-09-21 17:43:03,701][3098656] Worker 8 uses CPU cores [8]
[2025-09-21 17:43:03,753][3098297] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:43:04,011][3098656] Decorrelating experience for 0 frames...
[2025-09-21 17:43:04,027][3098656] Decorrelating experience for 32 frames...
[2025-09-21 17:43:04,114][3098666] Worker 13 uses CPU cores [13]
[2025-09-21 17:43:04,332][3098666] Decorrelating experience for 0 frames...
[2025-09-21 17:43:04,351][3098666] Decorrelating experience for 32 frames...
[2025-09-21 17:43:04,694][3098671] Worker 17 uses CPU cores [17]
[2025-09-21 17:43:04,889][3098671] Decorrelating experience for 0 frames...
[2025-09-21 17:43:04,892][3098671] Decorrelating experience for 32 frames...
[2025-09-21 17:43:05,256][3098669] Worker 16 uses CPU cores [16]
[2025-09-21 17:43:05,523][3098669] Decorrelating experience for 0 frames...
[2025-09-21 17:43:05,578][3098669] Decorrelating experience for 32 frames...
[2025-09-21 17:43:05,659][3098665] Worker 10 uses CPU cores [10]
[2025-09-21 17:43:05,686][3098657] Decorrelating experience for 96 frames...
[2025-09-21 17:43:05,989][3098665] Decorrelating experience for 0 frames...
[2025-09-21 17:43:06,037][3098665] Decorrelating experience for 32 frames...
[2025-09-21 17:43:06,296][3098687] Worker 24 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:06,298][3098667] Decorrelating experience for 96 frames...
[2025-09-21 17:43:06,324][3098668] Decorrelating experience for 64 frames...
[2025-09-21 17:43:06,320][3098658] Decorrelating experience for 64 frames...
[2025-09-21 17:43:06,537][3098687] Decorrelating experience for 0 frames...
[2025-09-21 17:43:06,606][3098687] Decorrelating experience for 32 frames...
[2025-09-21 17:43:06,810][3098679] Worker 20 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:06,834][3098671] Decorrelating experience for 64 frames...
[2025-09-21 17:43:06,895][3098680] Worker 21 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:06,954][3098680] Decorrelating experience for 0 frames...
[2025-09-21 17:43:06,961][3098680] Decorrelating experience for 32 frames...
[2025-09-21 17:43:06,965][3098679] Decorrelating experience for 0 frames...
[2025-09-21 17:43:06,984][3098679] Decorrelating experience for 32 frames...
[2025-09-21 17:43:07,295][3098656] Decorrelating experience for 64 frames...
[2025-09-21 17:43:07,588][3098689] Worker 28 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:07,608][3098653] Decorrelating experience for 64 frames...
[2025-09-21 17:43:07,662][3098689] Decorrelating experience for 0 frames...
[2025-09-21 17:43:07,671][3098689] Decorrelating experience for 32 frames...
[2025-09-21 17:43:07,913][3098654] Decorrelating experience for 96 frames...
[2025-09-21 17:43:08,075][3098665] Decorrelating experience for 64 frames...
[2025-09-21 17:43:08,227][3098675] Worker 18 uses CPU cores [18]
[2025-09-21 17:43:08,394][3098675] Decorrelating experience for 0 frames...
[2025-09-21 17:43:08,432][3098675] Decorrelating experience for 32 frames...
[2025-09-21 17:43:08,588][3098674] Worker 23 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:08,642][3098678] Worker 19 uses CPU cores [19]
[2025-09-21 17:43:08,703][3098674] Decorrelating experience for 0 frames...
[2025-09-21 17:43:08,723][3098674] Decorrelating experience for 32 frames...
[2025-09-21 17:43:08,753][3098297] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.6. Samples: 6. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:43:08,792][3098678] Decorrelating experience for 0 frames...
[2025-09-21 17:43:08,846][3098666] Decorrelating experience for 64 frames...
[2025-09-21 17:43:08,823][3098678] Decorrelating experience for 32 frames...
[2025-09-21 17:43:08,986][3098663] Decorrelating experience for 96 frames...
[2025-09-21 17:43:09,182][3098690] Worker 26 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:09,280][3098669] Decorrelating experience for 64 frames...
[2025-09-21 17:43:09,350][3098649] Decorrelating experience for 96 frames...
[2025-09-21 17:43:09,371][3098690] Decorrelating experience for 0 frames...
[2025-09-21 17:43:09,410][3098692] Worker 31 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:09,395][3098690] Decorrelating experience for 32 frames...
[2025-09-21 17:43:09,538][3098692] Decorrelating experience for 0 frames...
[2025-09-21 17:43:09,547][3098671] Decorrelating experience for 96 frames...
[2025-09-21 17:43:09,560][3098692] Decorrelating experience for 32 frames...
[2025-09-21 17:43:09,651][3098691] Worker 30 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:09,688][3098691] Decorrelating experience for 0 frames...
[2025-09-21 17:43:09,745][3098691] Decorrelating experience for 32 frames...
[2025-09-21 17:43:10,417][3098683] Worker 22 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:10,575][3098683] Decorrelating experience for 0 frames...
[2025-09-21 17:43:10,577][3098683] Decorrelating experience for 32 frames...
[2025-09-21 17:43:10,870][3098687] Decorrelating experience for 64 frames...
[2025-09-21 17:43:11,037][3098658] Decorrelating experience for 96 frames...
[2025-09-21 17:43:11,123][3098679] Decorrelating experience for 64 frames...
[2025-09-21 17:43:11,363][3098693] Worker 29 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:11,392][3098680] Decorrelating experience for 64 frames...
[2025-09-21 17:43:11,638][3098693] Decorrelating experience for 0 frames...
[2025-09-21 17:43:11,663][3098693] Decorrelating experience for 32 frames...
[2025-09-21 17:43:12,021][3098684] Worker 25 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:12,294][3098684] Decorrelating experience for 0 frames...
[2025-09-21 17:43:12,300][3098684] Decorrelating experience for 32 frames...
[2025-09-21 17:43:12,708][3098689] Decorrelating experience for 64 frames...
[2025-09-21 17:43:12,765][3098665] Decorrelating experience for 96 frames...
[2025-09-21 17:43:12,931][3098297] Heartbeat connected on Batcher_0
[2025-09-21 17:43:12,945][3098297] Heartbeat connected on LearnerWorker_p0
[2025-09-21 17:43:13,018][3098297] Heartbeat connected on InferenceWorker_p0-w0
[2025-09-21 17:43:13,127][3098297] Heartbeat connected on RolloutWorker_w2
[2025-09-21 17:43:13,169][3098297] Heartbeat connected on RolloutWorker_w7
[2025-09-21 17:43:13,228][3098297] Heartbeat connected on RolloutWorker_w11
[2025-09-21 17:43:13,252][3098297] Heartbeat connected on RolloutWorker_w3
[2025-09-21 17:43:13,298][3098690] Decorrelating experience for 64 frames...
[2025-09-21 17:43:13,399][3098297] Heartbeat connected on RolloutWorker_w4
[2025-09-21 17:43:13,587][3098692] Decorrelating experience for 64 frames...
[2025-09-21 17:43:13,633][3098688] Worker 27 uses CPU cores [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-09-21 17:43:13,680][3098688] Decorrelating experience for 0 frames...
[2025-09-21 17:43:13,687][3098688] Decorrelating experience for 32 frames...
[2025-09-21 17:43:13,710][3098656] Decorrelating experience for 96 frames...
[2025-09-21 17:43:13,731][3098691] Decorrelating experience for 64 frames...
[2025-09-21 17:43:13,753][3098297] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 12.5. Samples: 188. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:43:14,215][3098683] Decorrelating experience for 64 frames...
[2025-09-21 17:43:14,553][3098297] Heartbeat connected on RolloutWorker_w15
[2025-09-21 17:43:15,258][3098653] Decorrelating experience for 96 frames...
[2025-09-21 17:43:15,511][3098674] Decorrelating experience for 64 frames...
[2025-09-21 17:43:16,028][3098297] Heartbeat connected on RolloutWorker_w6
[2025-09-21 17:43:16,557][3098684] Decorrelating experience for 64 frames...
[2025-09-21 17:43:16,691][3098688] Decorrelating experience for 64 frames...
[2025-09-21 17:43:16,852][3098693] Decorrelating experience for 64 frames...
[2025-09-21 17:43:16,951][3098297] Heartbeat connected on RolloutWorker_w1
[2025-09-21 17:43:17,506][3098675] Decorrelating experience for 64 frames...
[2025-09-21 17:43:17,935][3098297] Heartbeat connected on RolloutWorker_w0
[2025-09-21 17:43:18,239][3098678] Decorrelating experience for 64 frames...
[2025-09-21 17:43:18,753][3098297] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 19.3. Samples: 386. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:43:19,303][3098687] Decorrelating experience for 96 frames...
[2025-09-21 17:43:19,568][3098680] Decorrelating experience for 96 frames...
[2025-09-21 17:43:19,765][3098297] Heartbeat connected on RolloutWorker_w10
[2025-09-21 17:43:19,950][3098679] Decorrelating experience for 96 frames...
[2025-09-21 17:43:20,049][3098668] Decorrelating experience for 96 frames...
[2025-09-21 17:43:20,601][3098690] Decorrelating experience for 96 frames...
[2025-09-21 17:43:20,618][3098689] Decorrelating experience for 96 frames...
[2025-09-21 17:43:21,470][3098692] Decorrelating experience for 96 frames...
[2025-09-21 17:43:21,583][3098297] Heartbeat connected on RolloutWorker_w9
[2025-09-21 17:43:21,589][3098297] Heartbeat connected on RolloutWorker_w5
[2025-09-21 17:43:22,051][3098691] Decorrelating experience for 96 frames...
[2025-09-21 17:43:22,721][3098666] Decorrelating experience for 96 frames...
[2025-09-21 17:43:22,755][3098683] Decorrelating experience for 96 frames...
[2025-09-21 17:43:23,753][3098297] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 36.6. Samples: 916. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:43:23,872][3098297] Heartbeat connected on RolloutWorker_w8
[2025-09-21 17:43:24,111][3098684] Decorrelating experience for 96 frames...
[2025-09-21 17:43:24,578][3098688] Decorrelating experience for 96 frames...
[2025-09-21 17:43:24,659][3098674] Decorrelating experience for 96 frames...
[2025-09-21 17:43:25,595][3098693] Decorrelating experience for 96 frames...
[2025-09-21 17:43:28,753][3098297] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 57.3. Samples: 1720. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-21 17:43:28,748][3098669] Decorrelating experience for 96 frames...
[2025-09-21 17:43:29,517][3098297] Heartbeat connected on RolloutWorker_w24
[2025-09-21 17:43:30,810][3098297] Heartbeat connected on RolloutWorker_w26
[2025-09-21 17:43:31,304][3098297] Heartbeat connected on RolloutWorker_w28
[2025-09-21 17:43:31,577][3098297] Heartbeat connected on RolloutWorker_w20
[2025-09-21 17:43:31,689][3098297] Heartbeat connected on RolloutWorker_w21
[2025-09-21 17:43:31,840][3098297] Heartbeat connected on RolloutWorker_w17
[2025-09-21 17:43:32,070][3098297] Heartbeat connected on RolloutWorker_w12
[2025-09-21 17:43:33,032][3098297] Heartbeat connected on RolloutWorker_w30
[2025-09-21 17:43:33,086][3098297] Heartbeat connected on RolloutWorker_w31
[2025-09-21 17:43:33,753][3098297] Fps is (10 sec: 102.4, 60 sec: 29.3, 300 sec: 29.3). Total num frames: 1024. Throughput: 0: 61.0. Samples: 2136. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-21 17:43:33,921][3098297] Heartbeat connected on RolloutWorker_w22
[2025-09-21 17:43:34,994][3098297] Heartbeat connected on RolloutWorker_w25
[2025-09-21 17:43:35,838][3098675] Decorrelating experience for 96 frames...
[2025-09-21 17:43:36,029][3098297] Heartbeat connected on RolloutWorker_w23
[2025-09-21 17:43:36,161][3098297] Heartbeat connected on RolloutWorker_w29
[2025-09-21 17:43:36,519][3098678] Decorrelating experience for 96 frames...
[2025-09-21 17:43:36,997][3098297] Heartbeat connected on RolloutWorker_w27
[2025-09-21 17:43:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 51.2, 300 sec: 51.2). Total num frames: 2048. Throughput: 0: 84.1. Samples: 3364. Policy #0 lag: (min: 0.0, avg: 0.7, max: 1.0)
[2025-09-21 17:43:43,753][3098297] Fps is (10 sec: 102.4, 60 sec: 45.5, 300 sec: 45.5). Total num frames: 2048. Throughput: 0: 106.6. Samples: 4796. Policy #0 lag: (min: 0.0, avg: 0.7, max: 1.0)
[2025-09-21 17:43:48,636][3098297] Heartbeat connected on RolloutWorker_w14
[2025-09-21 17:43:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 81.9, 300 sec: 81.9). Total num frames: 4096. Throughput: 0: 122.8. Samples: 5526. Policy #0 lag: (min: 0.0, avg: 1.2, max: 3.0)
[2025-09-21 17:43:51,123][3098297] Heartbeat connected on RolloutWorker_w13
[2025-09-21 17:43:53,755][3098297] Fps is (10 sec: 307.2, 60 sec: 93.1, 300 sec: 93.1). Total num frames: 5120. Throughput: 0: 155.2. Samples: 6990. Policy #0 lag: (min: 0.0, avg: 1.8, max: 3.0)
[2025-09-21 17:43:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 102.4, 300 sec: 102.4). Total num frames: 6144. Throughput: 0: 183.3. Samples: 8436. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 17:43:58,777][3098297] Heartbeat connected on RolloutWorker_w16
[2025-09-21 17:44:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 119.5, 300 sec: 110.3). Total num frames: 7168. Throughput: 0: 195.9. Samples: 9200. Policy #0 lag: (min: 0.0, avg: 1.3, max: 4.0)
[2025-09-21 17:44:04,516][3098297] Heartbeat connected on RolloutWorker_w19
[2025-09-21 17:44:05,605][3098297] Heartbeat connected on RolloutWorker_w18
[2025-09-21 17:44:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 153.6, 300 sec: 131.7). Total num frames: 9216. Throughput: 0: 217.6. Samples: 10710. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 17:44:13,698][3098647] Updated weights for policy 0, policy_version 10 (0.0042)
[2025-09-21 17:44:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 170.7, 300 sec: 136.5). Total num frames: 10240. Throughput: 0: 234.4. Samples: 12268. Policy #0 lag: (min: 0.0, avg: 2.8, max: 8.0)
[2025-09-21 17:44:18,754][3098297] Fps is (10 sec: 102.4, 60 sec: 170.7, 300 sec: 128.0). Total num frames: 10240. Throughput: 0: 242.3. Samples: 13042. Policy #0 lag: (min: 0.0, avg: 2.8, max: 8.0)
[2025-09-21 17:44:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 221.9, 300 sec: 156.6). Total num frames: 13312. Throughput: 0: 249.6. Samples: 14596. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 17:44:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 221.9, 300 sec: 147.9). Total num frames: 13312. Throughput: 0: 252.4. Samples: 16154. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 17:44:33,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 161.7). Total num frames: 15360. Throughput: 0: 253.2. Samples: 16918. Policy #0 lag: (min: 0.0, avg: 1.7, max: 10.0)
[2025-09-21 17:44:38,753][3098297] Fps is (10 sec: 307.3, 60 sec: 238.9, 300 sec: 163.8). Total num frames: 16384. Throughput: 0: 255.3. Samples: 18478. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 17:44:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 165.8). Total num frames: 17408. Throughput: 0: 257.3. Samples: 20016. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 17:44:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 167.6). Total num frames: 18432. Throughput: 0: 257.8. Samples: 20802. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 17:44:48,755][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000018_18432.pth...
[2025-09-21 17:44:52,076][3098647] Updated weights for policy 0, policy_version 20 (0.0074)
[2025-09-21 17:44:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 178.1). Total num frames: 20480. Throughput: 0: 258.1. Samples: 22324. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 17:44:58,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 179.2). Total num frames: 21504. Throughput: 0: 257.5. Samples: 23856. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 17:45:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 180.2). Total num frames: 22528. Throughput: 0: 257.8. Samples: 24644. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 17:45:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 181.2). Total num frames: 23552. Throughput: 0: 257.7. Samples: 26192. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 17:45:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 182.0). Total num frames: 24576. Throughput: 0: 257.3. Samples: 27734. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 17:45:18,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 182.9). Total num frames: 25600. Throughput: 0: 257.2. Samples: 28494. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 17:45:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 190.7). Total num frames: 27648. Throughput: 0: 257.1. Samples: 30048. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 17:45:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 191.1). Total num frames: 28672. Throughput: 0: 257.2. Samples: 31590. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 17:45:33,361][3098647] Updated weights for policy 0, policy_version 30 (0.0060)
[2025-09-21 17:45:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 198.2). Total num frames: 30720. Throughput: 0: 256.7. Samples: 32354. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 17:45:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 198.4). Total num frames: 31744. Throughput: 0: 257.4. Samples: 33906. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:45:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 198.6). Total num frames: 32768. Throughput: 0: 257.6. Samples: 35448. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 17:45:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 198.8). Total num frames: 33792. Throughput: 0: 257.1. Samples: 36212. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 17:45:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 204.8). Total num frames: 35840. Throughput: 0: 257.4. Samples: 37776. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:45:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 204.8). Total num frames: 36864. Throughput: 0: 256.6. Samples: 39282. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:46:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 204.8). Total num frames: 37888. Throughput: 0: 257.2. Samples: 40066. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 17:46:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 210.2). Total num frames: 39936. Throughput: 0: 256.6. Samples: 41594. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 17:46:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 204.8). Total num frames: 39936. Throughput: 0: 256.5. Samples: 43134. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 17:46:13,821][3098647] Updated weights for policy 0, policy_version 40 (0.0070)
[2025-09-21 17:46:18,754][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 209.9). Total num frames: 41984. Throughput: 0: 257.2. Samples: 43930. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 17:46:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 209.8). Total num frames: 43008. Throughput: 0: 256.6. Samples: 45452. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 17:46:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 209.7). Total num frames: 44032. Throughput: 0: 256.8. Samples: 47004. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:46:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 214.3). Total num frames: 46080. Throughput: 0: 257.4. Samples: 47796. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 17:46:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 214.1). Total num frames: 47104. Throughput: 0: 256.5. Samples: 49320. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 17:46:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 213.9). Total num frames: 48128. Throughput: 0: 257.5. Samples: 50870. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:46:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 218.2). Total num frames: 50176. Throughput: 0: 257.5. Samples: 51652. Policy #0 lag: (min: 0.0, avg: 2.5, max: 12.0)
[2025-09-21 17:46:48,755][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000049_50176.pth...
[2025-09-21 17:46:52,881][3098647] Updated weights for policy 0, policy_version 50 (0.0080)
[2025-09-21 17:46:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 217.9). Total num frames: 51200. Throughput: 0: 257.7. Samples: 53190. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 17:46:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 217.6). Total num frames: 52224. Throughput: 0: 257.2. Samples: 54710. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 17:47:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 217.3). Total num frames: 53248. Throughput: 0: 256.5. Samples: 55470. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 17:47:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 217.1). Total num frames: 54272. Throughput: 0: 256.7. Samples: 57004. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:47:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 220.9). Total num frames: 56320. Throughput: 0: 256.6. Samples: 58552. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 17:47:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 220.6). Total num frames: 57344. Throughput: 0: 256.5. Samples: 59340. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 17:47:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 220.3). Total num frames: 58368. Throughput: 0: 256.9. Samples: 60878. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:47:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 220.0). Total num frames: 59392. Throughput: 0: 257.3. Samples: 62448. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 17:47:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 219.7). Total num frames: 60416. Throughput: 0: 257.1. Samples: 63222. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:47:34,918][3098647] Updated weights for policy 0, policy_version 60 (0.0072)
[2025-09-21 17:47:38,756][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 223.1). Total num frames: 62464. Throughput: 0: 257.0. Samples: 64756. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 17:47:43,755][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 222.8). Total num frames: 63488. Throughput: 0: 257.8. Samples: 66310. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 17:47:48,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 226.0). Total num frames: 65536. Throughput: 0: 257.8. Samples: 67072. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 17:47:53,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 225.6). Total num frames: 66560. Throughput: 0: 258.2. Samples: 68622. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 17:47:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 229.1). Total num frames: 67584. Throughput: 0: 257.7. Samples: 70146. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 17:48:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 232.6). Total num frames: 68608. Throughput: 0: 257.2. Samples: 70914. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:48:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 236.0). Total num frames: 69632. Throughput: 0: 257.5. Samples: 72464. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 17:48:12,262][3098647] Updated weights for policy 0, policy_version 70 (0.0084)
[2025-09-21 17:48:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 243.0). Total num frames: 71680. Throughput: 0: 256.9. Samples: 74010. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 17:48:13,756][3098297] Avg episode reward: [(0, '0.122')]
[2025-09-21 17:48:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 246.5). Total num frames: 72704. Throughput: 0: 257.2. Samples: 74796. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:48:18,753][3098297] Avg episode reward: [(0, '0.122')]
[2025-09-21 17:48:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 73728. Throughput: 0: 257.5. Samples: 76342. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:48:23,753][3098297] Avg episode reward: [(0, '-0.258')]
[2025-09-21 17:48:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 75776. Throughput: 0: 257.3. Samples: 77890. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:48:28,753][3098297] Avg episode reward: [(0, '-0.225')]
[2025-09-21 17:48:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 76800. Throughput: 0: 257.3. Samples: 78652. Policy #0 lag: (min: 0.0, avg: 1.9, max: 6.0)
[2025-09-21 17:48:33,753][3098297] Avg episode reward: [(0, '-0.309')]
[2025-09-21 17:48:38,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 77824. Throughput: 0: 257.0. Samples: 80186. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:48:38,757][3098297] Avg episode reward: [(0, '-0.330')]
[2025-09-21 17:48:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 78848. Throughput: 0: 256.9. Samples: 81708. Policy #0 lag: (min: 0.0, avg: 1.9, max: 12.0)
[2025-09-21 17:48:43,757][3098297] Avg episode reward: [(0, '-0.379')]
[2025-09-21 17:48:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 80896. Throughput: 0: 256.4. Samples: 82454. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 17:48:48,753][3098297] Avg episode reward: [(0, '-0.446')]
[2025-09-21 17:48:48,757][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000079_80896.pth...
[2025-09-21 17:48:48,783][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000018_18432.pth
[2025-09-21 17:48:53,120][3098647] Updated weights for policy 0, policy_version 80 (0.0107)
[2025-09-21 17:48:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 81920. Throughput: 0: 255.8. Samples: 83976. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 17:48:53,753][3098297] Avg episode reward: [(0, '-0.422')]
[2025-09-21 17:48:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 82944. Throughput: 0: 254.6. Samples: 85468. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 17:48:58,753][3098297] Avg episode reward: [(0, '-0.466')]
[2025-09-21 17:49:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 83968. Throughput: 0: 254.1. Samples: 86230. Policy #0 lag: (min: 0.0, avg: 3.1, max: 11.0)
[2025-09-21 17:49:03,753][3098297] Avg episode reward: [(0, '-0.456')]
[2025-09-21 17:49:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 84992. Throughput: 0: 254.1. Samples: 87776. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 17:49:08,753][3098297] Avg episode reward: [(0, '-0.521')]
[2025-09-21 17:49:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 87040. Throughput: 0: 254.0. Samples: 89320. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 17:49:13,753][3098297] Avg episode reward: [(0, '-0.523')]
[2025-09-21 17:49:18,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 88064. Throughput: 0: 254.3. Samples: 90098. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 17:49:18,759][3098297] Avg episode reward: [(0, '-0.526')]
[2025-09-21 17:49:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 89088. Throughput: 0: 254.0. Samples: 91616. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:49:23,753][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:49:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 90112. Throughput: 0: 254.8. Samples: 93172. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:49:28,754][3098297] Avg episode reward: [(0, '-0.517')]
[2025-09-21 17:49:33,285][3098647] Updated weights for policy 0, policy_version 90 (0.0065)
[2025-09-21 17:49:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 92160. Throughput: 0: 255.1. Samples: 93934. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 17:49:33,755][3098297] Avg episode reward: [(0, '-0.516')]
[2025-09-21 17:49:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 93184. Throughput: 0: 255.4. Samples: 95468. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 17:49:38,756][3098297] Avg episode reward: [(0, '-0.533')]
[2025-09-21 17:49:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 94208. Throughput: 0: 256.9. Samples: 97028. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 17:49:43,757][3098297] Avg episode reward: [(0, '-0.541')]
[2025-09-21 17:49:48,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 95232. Throughput: 0: 257.1. Samples: 97802. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:49:48,757][3098297] Avg episode reward: [(0, '-0.541')]
[2025-09-21 17:49:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 97280. Throughput: 0: 257.4. Samples: 99358. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:49:53,753][3098297] Avg episode reward: [(0, '-0.549')]
[2025-09-21 17:49:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 98304. Throughput: 0: 256.7. Samples: 100874. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 17:49:58,757][3098297] Avg episode reward: [(0, '-0.549')]
[2025-09-21 17:50:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 99328. Throughput: 0: 256.7. Samples: 101650. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 17:50:03,753][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 101376. Throughput: 0: 254.3. Samples: 103060. Policy #0 lag: (min: 0.0, avg: 2.9, max: 11.0)
[2025-09-21 17:50:08,753][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:08,755][3098570] Saving new best policy, reward=-0.542!
[2025-09-21 17:50:13,090][3098647] Updated weights for policy 0, policy_version 100 (0.0042)
[2025-09-21 17:50:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 102400. Throughput: 0: 253.2. Samples: 104566. Policy #0 lag: (min: 0.0, avg: 2.4, max: 12.0)
[2025-09-21 17:50:13,753][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 103424. Throughput: 0: 253.5. Samples: 105340. Policy #0 lag: (min: 0.0, avg: 1.4, max: 5.0)
[2025-09-21 17:50:18,753][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 105472. Throughput: 0: 254.2. Samples: 106908. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 17:50:23,757][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:28,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 105472. Throughput: 0: 254.1. Samples: 108462. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 17:50:28,762][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 107520. Throughput: 0: 254.1. Samples: 109238. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 17:50:33,753][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 108544. Throughput: 0: 253.8. Samples: 110778. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 17:50:38,753][3098297] Avg episode reward: [(0, '-0.542')]
[2025-09-21 17:50:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 109568. Throughput: 0: 255.1. Samples: 112352. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 17:50:43,753][3098297] Avg episode reward: [(0, '-0.543')]
[2025-09-21 17:50:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 110592. Throughput: 0: 254.9. Samples: 113122. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 17:50:48,753][3098297] Avg episode reward: [(0, '-0.549')]
[2025-09-21 17:50:48,756][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000108_110592.pth...
[2025-09-21 17:50:48,787][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000049_50176.pth
[2025-09-21 17:50:51,648][3098647] Updated weights for policy 0, policy_version 110 (0.0099)
[2025-09-21 17:50:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 112640. Throughput: 0: 257.3. Samples: 114640. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:50:53,753][3098297] Avg episode reward: [(0, '-0.504')]
[2025-09-21 17:50:53,754][3098570] Saving new best policy, reward=-0.504!
[2025-09-21 17:50:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 113664. Throughput: 0: 257.2. Samples: 116138. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 17:50:58,753][3098297] Avg episode reward: [(0, '-0.512')]
[2025-09-21 17:51:03,753][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 113664. Throughput: 0: 257.1. Samples: 116910. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 17:51:03,753][3098297] Avg episode reward: [(0, '-0.517')]
[2025-09-21 17:51:08,754][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 116736. Throughput: 0: 256.1. Samples: 118432. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 17:51:08,755][3098297] Avg episode reward: [(0, '-0.513')]
[2025-09-21 17:51:13,753][3098297] Fps is (10 sec: 409.6, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 117760. Throughput: 0: 255.7. Samples: 119966. Policy #0 lag: (min: 0.0, avg: 2.4, max: 5.0)
[2025-09-21 17:51:13,753][3098297] Avg episode reward: [(0, '-0.517')]
[2025-09-21 17:51:18,754][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 117760. Throughput: 0: 255.7. Samples: 120744. Policy #0 lag: (min: 0.0, avg: 2.4, max: 5.0)
[2025-09-21 17:51:18,757][3098297] Avg episode reward: [(0, '-0.505')]
[2025-09-21 17:51:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 119808. Throughput: 0: 255.8. Samples: 122288. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 17:51:23,753][3098297] Avg episode reward: [(0, '-0.514')]
[2025-09-21 17:51:28,753][3098297] Fps is (10 sec: 409.7, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 121856. Throughput: 0: 254.6. Samples: 123810. Policy #0 lag: (min: 0.0, avg: 2.9, max: 11.0)
[2025-09-21 17:51:28,753][3098297] Avg episode reward: [(0, '-0.522')]
[2025-09-21 17:51:33,712][3098647] Updated weights for policy 0, policy_version 120 (0.0061)
[2025-09-21 17:51:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 122880. Throughput: 0: 255.1. Samples: 124602. Policy #0 lag: (min: 0.0, avg: 1.1, max: 4.0)
[2025-09-21 17:51:33,753][3098297] Avg episode reward: [(0, '-0.522')]
[2025-09-21 17:51:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 123904. Throughput: 0: 255.3. Samples: 126128. Policy #0 lag: (min: 0.0, avg: 2.3, max: 12.0)
[2025-09-21 17:51:38,753][3098297] Avg episode reward: [(0, '-0.517')]
[2025-09-21 17:51:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 124928. Throughput: 0: 256.1. Samples: 127664. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:51:43,753][3098297] Avg episode reward: [(0, '-0.510')]
[2025-09-21 17:51:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 126976. Throughput: 0: 255.9. Samples: 128426. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 17:51:48,754][3098297] Avg episode reward: [(0, '-0.503')]
[2025-09-21 17:51:48,756][3098570] Saving new best policy, reward=-0.503!
[2025-09-21 17:51:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 128000. Throughput: 0: 256.0. Samples: 129950. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 17:51:53,753][3098297] Avg episode reward: [(0, '-0.503')]
[2025-09-21 17:51:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 129024. Throughput: 0: 255.9. Samples: 131480. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 17:51:58,757][3098297] Avg episode reward: [(0, '-0.503')]
[2025-09-21 17:52:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 130048. Throughput: 0: 256.1. Samples: 132268. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 17:52:03,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:03,754][3098570] Saving new best policy, reward=-0.498!
[2025-09-21 17:52:08,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 131072. Throughput: 0: 255.9. Samples: 133802. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 17:52:08,757][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:13,442][3098647] Updated weights for policy 0, policy_version 130 (0.0080)
[2025-09-21 17:52:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 133120. Throughput: 0: 256.9. Samples: 135370. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 17:52:13,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:18,755][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 134144. Throughput: 0: 256.5. Samples: 136146. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 17:52:18,757][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 135168. Throughput: 0: 257.5. Samples: 137716. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 17:52:23,756][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:28,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 137216. Throughput: 0: 257.6. Samples: 139256. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 17:52:28,757][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 137216. Throughput: 0: 258.1. Samples: 140040. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 17:52:33,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 139264. Throughput: 0: 258.5. Samples: 141584. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:52:38,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 140288. Throughput: 0: 259.1. Samples: 143140. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 17:52:43,758][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:48,755][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 142336. Throughput: 0: 258.7. Samples: 143912. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:52:48,760][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:48,769][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000139_142336.pth...
[2025-09-21 17:52:48,795][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000079_80896.pth
[2025-09-21 17:52:53,022][3098647] Updated weights for policy 0, policy_version 140 (0.0069)
[2025-09-21 17:52:53,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 143360. Throughput: 0: 259.3. Samples: 145470. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 17:52:53,756][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:52:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 144384. Throughput: 0: 258.2. Samples: 146990. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 17:52:58,758][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 145408. Throughput: 0: 258.1. Samples: 147762. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 17:53:03,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 147456. Throughput: 0: 257.5. Samples: 149302. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 17:53:08,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 148480. Throughput: 0: 258.1. Samples: 150872. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 17:53:13,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 149504. Throughput: 0: 257.5. Samples: 151628. Policy #0 lag: (min: 0.0, avg: 1.8, max: 6.0)
[2025-09-21 17:53:18,760][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 150528. Throughput: 0: 258.0. Samples: 153194. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 17:53:23,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 151552. Throughput: 0: 257.9. Samples: 154746. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 17:53:28,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:33,680][3098647] Updated weights for policy 0, policy_version 150 (0.0087)
[2025-09-21 17:53:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 153600. Throughput: 0: 257.7. Samples: 155508. Policy #0 lag: (min: 0.0, avg: 2.2, max: 4.0)
[2025-09-21 17:53:33,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 154624. Throughput: 0: 257.7. Samples: 157066. Policy #0 lag: (min: 0.0, avg: 2.9, max: 10.0)
[2025-09-21 17:53:38,756][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 155648. Throughput: 0: 258.5. Samples: 158620. Policy #0 lag: (min: 0.0, avg: 2.2, max: 5.0)
[2025-09-21 17:53:43,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 157696. Throughput: 0: 258.7. Samples: 159404. Policy #0 lag: (min: 0.0, avg: 2.4, max: 5.0)
[2025-09-21 17:53:48,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 158720. Throughput: 0: 258.2. Samples: 160922. Policy #0 lag: (min: 0.0, avg: 3.5, max: 12.0)
[2025-09-21 17:53:53,753][3098297] Avg episode reward: [(0, '-0.498')]
[2025-09-21 17:53:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 159744. Throughput: 0: 256.7. Samples: 162422. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 17:53:58,753][3098297] Avg episode reward: [(0, '-0.488')]
[2025-09-21 17:53:58,755][3098570] Saving new best policy, reward=-0.488!
[2025-09-21 17:54:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 160768. Throughput: 0: 257.3. Samples: 163204. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 17:54:03,753][3098297] Avg episode reward: [(0, '-0.488')]
[2025-09-21 17:54:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 162816. Throughput: 0: 255.7. Samples: 164702. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 17:54:08,753][3098297] Avg episode reward: [(0, '-0.476')]
[2025-09-21 17:54:08,755][3098570] Saving new best policy, reward=-0.476!
[2025-09-21 17:54:12,384][3098647] Updated weights for policy 0, policy_version 160 (0.0055)
[2025-09-21 17:54:13,754][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 163840. Throughput: 0: 256.0. Samples: 166266. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 17:54:13,755][3098297] Avg episode reward: [(0, '-0.467')]
[2025-09-21 17:54:13,756][3098570] Saving new best policy, reward=-0.467!
[2025-09-21 17:54:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 164864. Throughput: 0: 256.3. Samples: 167040. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:54:18,753][3098297] Avg episode reward: [(0, '-0.467')]
[2025-09-21 17:54:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 165888. Throughput: 0: 256.3. Samples: 168600. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 17:54:23,753][3098297] Avg episode reward: [(0, '-0.467')]
[2025-09-21 17:54:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 166912. Throughput: 0: 256.0. Samples: 170140. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 17:54:28,753][3098297] Avg episode reward: [(0, '-0.456')]
[2025-09-21 17:54:29,921][3098570] Saving new best policy, reward=-0.456!
[2025-09-21 17:54:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 168960. Throughput: 0: 255.5. Samples: 170902. Policy #0 lag: (min: 0.0, avg: 2.9, max: 12.0)
[2025-09-21 17:54:33,753][3098297] Avg episode reward: [(0, '-0.432')]
[2025-09-21 17:54:33,754][3098570] Saving new best policy, reward=-0.432!
[2025-09-21 17:54:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 169984. Throughput: 0: 255.9. Samples: 172440. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 17:54:38,759][3098297] Avg episode reward: [(0, '-0.422')]
[2025-09-21 17:54:38,909][3098570] Saving new best policy, reward=-0.422!
[2025-09-21 17:54:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 172032. Throughput: 0: 257.0. Samples: 173988. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 17:54:43,756][3098297] Avg episode reward: [(0, '-0.406')]
[2025-09-21 17:54:43,759][3098570] Saving new best policy, reward=-0.406!
[2025-09-21 17:54:48,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 173056. Throughput: 0: 256.7. Samples: 174756. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:54:48,759][3098297] Avg episode reward: [(0, '-0.356')]
[2025-09-21 17:54:48,801][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000169_173056.pth...
[2025-09-21 17:54:48,924][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000108_110592.pth
[2025-09-21 17:54:48,937][3098570] Saving new best policy, reward=-0.356!
[2025-09-21 17:54:52,729][3098647] Updated weights for policy 0, policy_version 170 (0.0070)
[2025-09-21 17:54:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 174080. Throughput: 0: 257.8. Samples: 176302. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 17:54:53,753][3098297] Avg episode reward: [(0, '-0.338')]
[2025-09-21 17:54:53,754][3098570] Saving new best policy, reward=-0.338!
[2025-09-21 17:54:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 175104. Throughput: 0: 256.3. Samples: 177798. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:54:58,753][3098297] Avg episode reward: [(0, '-0.332')]
[2025-09-21 17:54:58,762][3098570] Saving new best policy, reward=-0.332!
[2025-09-21 17:55:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 177152. Throughput: 0: 256.6. Samples: 178588. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 17:55:03,753][3098297] Avg episode reward: [(0, '-0.304')]
[2025-09-21 17:55:03,754][3098570] Saving new best policy, reward=-0.304!
[2025-09-21 17:55:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 178176. Throughput: 0: 255.9. Samples: 180114. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 17:55:08,753][3098297] Avg episode reward: [(0, '-0.298')]
[2025-09-21 17:55:08,761][3098570] Saving new best policy, reward=-0.298!
[2025-09-21 17:55:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 179200. Throughput: 0: 256.2. Samples: 181670. Policy #0 lag: (min: 0.0, avg: 3.1, max: 11.0)
[2025-09-21 17:55:13,757][3098297] Avg episode reward: [(0, '-0.270')]
[2025-09-21 17:55:13,762][3098570] Saving new best policy, reward=-0.270!
[2025-09-21 17:55:18,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 180224. Throughput: 0: 256.0. Samples: 182422. Policy #0 lag: (min: 0.0, avg: 2.1, max: 12.0)
[2025-09-21 17:55:18,757][3098297] Avg episode reward: [(0, '-0.229')]
[2025-09-21 17:55:18,978][3098570] Saving new best policy, reward=-0.229!
[2025-09-21 17:55:23,756][3098297] Fps is (10 sec: 307.1, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 182272. Throughput: 0: 256.5. Samples: 183984. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 17:55:23,760][3098297] Avg episode reward: [(0, '-0.202')]
[2025-09-21 17:55:23,763][3098570] Saving new best policy, reward=-0.202!
[2025-09-21 17:55:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 183296. Throughput: 0: 256.4. Samples: 185524. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 17:55:28,753][3098297] Avg episode reward: [(0, '-0.187')]
[2025-09-21 17:55:28,761][3098570] Saving new best policy, reward=-0.187!
[2025-09-21 17:55:31,917][3098647] Updated weights for policy 0, policy_version 180 (0.0093)
[2025-09-21 17:55:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 184320. Throughput: 0: 256.5. Samples: 186300. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:55:33,756][3098297] Avg episode reward: [(0, '-0.158')]
[2025-09-21 17:55:33,759][3098570] Saving new best policy, reward=-0.158!
[2025-09-21 17:55:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 185344. Throughput: 0: 256.9. Samples: 187864. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 17:55:38,753][3098297] Avg episode reward: [(0, '-0.131')]
[2025-09-21 17:55:38,761][3098570] Saving new best policy, reward=-0.131!
[2025-09-21 17:55:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 186368. Throughput: 0: 258.4. Samples: 189424. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 17:55:43,753][3098297] Avg episode reward: [(0, '-0.126')]
[2025-09-21 17:55:43,757][3098570] Saving new best policy, reward=-0.126!
[2025-09-21 17:55:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 187392. Throughput: 0: 258.0. Samples: 190196. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 17:55:48,753][3098297] Avg episode reward: [(0, '-0.124')]
[2025-09-21 17:55:49,390][3098570] Saving new best policy, reward=-0.124!
[2025-09-21 17:55:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 189440. Throughput: 0: 258.4. Samples: 191740. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 17:55:53,753][3098297] Avg episode reward: [(0, '-0.119')]
[2025-09-21 17:55:53,754][3098570] Saving new best policy, reward=-0.119!
[2025-09-21 17:55:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 190464. Throughput: 0: 257.6. Samples: 193262. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 17:55:58,753][3098297] Avg episode reward: [(0, '-0.108')]
[2025-09-21 17:55:58,846][3098570] Saving new best policy, reward=-0.108!
[2025-09-21 17:56:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 192512. Throughput: 0: 258.2. Samples: 194042. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 17:56:03,753][3098297] Avg episode reward: [(0, '-0.108')]
[2025-09-21 17:56:08,766][3098297] Fps is (10 sec: 306.8, 60 sec: 255.9, 300 sec: 256.9). Total num frames: 193536. Throughput: 0: 258.0. Samples: 195598. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 17:56:08,767][3098297] Avg episode reward: [(0, '-0.104')]
[2025-09-21 17:56:08,781][3098570] Saving new best policy, reward=-0.104!
[2025-09-21 17:56:11,933][3098647] Updated weights for policy 0, policy_version 190 (0.0068)
[2025-09-21 17:56:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 194560. Throughput: 0: 258.3. Samples: 197146. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 17:56:13,753][3098297] Avg episode reward: [(0, '-0.104')]
[2025-09-21 17:56:18,754][3098297] Fps is (10 sec: 205.0, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 195584. Throughput: 0: 258.7. Samples: 197942. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 17:56:18,757][3098297] Avg episode reward: [(0, '-0.092')]
[2025-09-21 17:56:18,794][3098570] Saving new best policy, reward=-0.092!
[2025-09-21 17:56:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 197632. Throughput: 0: 258.2. Samples: 199484. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 17:56:23,753][3098297] Avg episode reward: [(0, '-0.092')]
[2025-09-21 17:56:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 198656. Throughput: 0: 258.3. Samples: 201048. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 17:56:28,753][3098297] Avg episode reward: [(0, '-0.092')]
[2025-09-21 17:56:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 199680. Throughput: 0: 258.9. Samples: 201848. Policy #0 lag: (min: 0.0, avg: 1.9, max: 8.0)
[2025-09-21 17:56:33,756][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:56:33,759][3098570] Saving new best policy, reward=-0.087!
[2025-09-21 17:56:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 201728. Throughput: 0: 258.7. Samples: 203380. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:56:38,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:56:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 202752. Throughput: 0: 259.4. Samples: 204934. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 17:56:43,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:56:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 203776. Throughput: 0: 259.9. Samples: 205738. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 17:56:48,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:56:48,760][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000199_203776.pth...
[2025-09-21 17:56:48,790][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000139_142336.pth
[2025-09-21 17:56:51,951][3098647] Updated weights for policy 0, policy_version 200 (0.0084)
[2025-09-21 17:56:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 204800. Throughput: 0: 259.7. Samples: 207280. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 17:56:53,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:56:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 206848. Throughput: 0: 258.9. Samples: 208796. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 17:56:58,764][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 207872. Throughput: 0: 258.6. Samples: 209578. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 17:57:03,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.1, 300 sec: 256.9). Total num frames: 208896. Throughput: 0: 258.7. Samples: 211126. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 17:57:08,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 209920. Throughput: 0: 258.8. Samples: 212692. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 17:57:13,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:18,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 211968. Throughput: 0: 258.4. Samples: 213478. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:57:18,758][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 211968. Throughput: 0: 259.2. Samples: 215044. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:57:23,757][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:28,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 214016. Throughput: 0: 259.2. Samples: 216598. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 17:57:28,757][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:30,794][3098647] Updated weights for policy 0, policy_version 210 (0.0105)
[2025-09-21 17:57:33,753][3098297] Fps is (10 sec: 409.7, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 216064. Throughput: 0: 258.8. Samples: 217384. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:57:33,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:38,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 216064. Throughput: 0: 259.2. Samples: 218944. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:57:38,757][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 218112. Throughput: 0: 260.5. Samples: 220520. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 17:57:43,756][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 219136. Throughput: 0: 260.2. Samples: 221286. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 17:57:48,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:53,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 220160. Throughput: 0: 259.1. Samples: 222788. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 17:57:53,756][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:57:58,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 222208. Throughput: 0: 258.5. Samples: 224326. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 17:57:58,758][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:03,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 223232. Throughput: 0: 258.5. Samples: 225110. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 17:58:03,758][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:08,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 224256. Throughput: 0: 257.9. Samples: 226648. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 17:58:08,757][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:10,249][3098647] Updated weights for policy 0, policy_version 220 (0.0081)
[2025-09-21 17:58:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 225280. Throughput: 0: 258.3. Samples: 228222. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:58:13,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 227328. Throughput: 0: 258.0. Samples: 228996. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:58:18,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 228352. Throughput: 0: 258.1. Samples: 230560. Policy #0 lag: (min: 0.0, avg: 2.9, max: 10.0)
[2025-09-21 17:58:23,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 229376. Throughput: 0: 257.5. Samples: 232108. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 17:58:28,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 230400. Throughput: 0: 258.2. Samples: 232906. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 17:58:33,753][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 232448. Throughput: 0: 259.5. Samples: 234466. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:58:38,757][3098297] Avg episode reward: [(0, '-0.087')]
[2025-09-21 17:58:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 232448. Throughput: 0: 259.9. Samples: 236020. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:58:43,753][3098297] Avg episode reward: [(0, '-0.072')]
[2025-09-21 17:58:44,638][3098570] Saving new best policy, reward=-0.072!
[2025-09-21 17:58:48,547][3098647] Updated weights for policy 0, policy_version 230 (0.0070)
[2025-09-21 17:58:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 235520. Throughput: 0: 259.8. Samples: 236802. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:58:48,753][3098297] Avg episode reward: [(0, '-0.072')]
[2025-09-21 17:58:48,764][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000230_235520.pth...
[2025-09-21 17:58:48,795][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000169_173056.pth
[2025-09-21 17:58:53,753][3098297] Fps is (10 sec: 409.6, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 236544. Throughput: 0: 259.9. Samples: 238342. Policy #0 lag: (min: 0.0, avg: 3.0, max: 11.0)
[2025-09-21 17:58:53,753][3098297] Avg episode reward: [(0, '-0.070')]
[2025-09-21 17:58:53,754][3098570] Saving new best policy, reward=-0.070!
[2025-09-21 17:58:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 237568. Throughput: 0: 258.7. Samples: 239862. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 17:58:58,753][3098297] Avg episode reward: [(0, '-0.019')]
[2025-09-21 17:58:58,761][3098570] Saving new best policy, reward=-0.019!
[2025-09-21 17:59:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 238592. Throughput: 0: 259.1. Samples: 240654. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 17:59:03,753][3098297] Avg episode reward: [(0, '-0.019')]
[2025-09-21 17:59:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 239616. Throughput: 0: 258.0. Samples: 242170. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 17:59:08,753][3098297] Avg episode reward: [(0, '0.000')]
[2025-09-21 17:59:08,761][3098570] Saving new best policy, reward=0.000!
[2025-09-21 17:59:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 240640. Throughput: 0: 258.1. Samples: 243722. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 17:59:13,753][3098297] Avg episode reward: [(0, '0.048')]
[2025-09-21 17:59:13,755][3098570] Saving new best policy, reward=0.048!
[2025-09-21 17:59:18,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 242688. Throughput: 0: 256.9. Samples: 244468. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 17:59:18,757][3098297] Avg episode reward: [(0, '0.062')]
[2025-09-21 17:59:18,794][3098570] Saving new best policy, reward=0.062!
[2025-09-21 17:59:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 243712. Throughput: 0: 256.7. Samples: 246018. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 17:59:23,753][3098297] Avg episode reward: [(0, '0.098')]
[2025-09-21 17:59:23,754][3098570] Saving new best policy, reward=0.098!
[2025-09-21 17:59:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 244736. Throughput: 0: 256.5. Samples: 247562. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 17:59:28,753][3098297] Avg episode reward: [(0, '0.161')]
[2025-09-21 17:59:28,771][3098570] Saving new best policy, reward=0.161!
[2025-09-21 17:59:29,398][3098647] Updated weights for policy 0, policy_version 240 (0.0075)
[2025-09-21 17:59:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 246784. Throughput: 0: 255.9. Samples: 248316. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 17:59:33,753][3098297] Avg episode reward: [(0, '0.175')]
[2025-09-21 17:59:33,754][3098570] Saving new best policy, reward=0.175!
[2025-09-21 17:59:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 247808. Throughput: 0: 256.1. Samples: 249868. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:59:38,753][3098297] Avg episode reward: [(0, '0.213')]
[2025-09-21 17:59:38,771][3098570] Saving new best policy, reward=0.213!
[2025-09-21 17:59:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 248832. Throughput: 0: 256.5. Samples: 251404. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 17:59:43,753][3098297] Avg episode reward: [(0, '0.270')]
[2025-09-21 17:59:43,754][3098570] Saving new best policy, reward=0.270!
[2025-09-21 17:59:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 249856. Throughput: 0: 256.4. Samples: 252194. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 17:59:48,753][3098297] Avg episode reward: [(0, '0.291')]
[2025-09-21 17:59:48,761][3098570] Saving new best policy, reward=0.291!
[2025-09-21 17:59:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 251904. Throughput: 0: 256.8. Samples: 253726. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 17:59:53,753][3098297] Avg episode reward: [(0, '0.334')]
[2025-09-21 17:59:53,754][3098570] Saving new best policy, reward=0.334!
[2025-09-21 17:59:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 252928. Throughput: 0: 255.4. Samples: 255216. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 17:59:58,753][3098297] Avg episode reward: [(0, '0.374')]
[2025-09-21 17:59:58,765][3098570] Saving new best policy, reward=0.374!
[2025-09-21 18:00:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 253952. Throughput: 0: 256.5. Samples: 256008. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:00:03,753][3098297] Avg episode reward: [(0, '0.383')]
[2025-09-21 18:00:03,754][3098570] Saving new best policy, reward=0.383!
[2025-09-21 18:00:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 254976. Throughput: 0: 256.4. Samples: 257554. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:00:08,753][3098297] Avg episode reward: [(0, '0.389')]
[2025-09-21 18:00:08,761][3098570] Saving new best policy, reward=0.389!
[2025-09-21 18:00:09,255][3098647] Updated weights for policy 0, policy_version 250 (0.0082)
[2025-09-21 18:00:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 257024. Throughput: 0: 256.3. Samples: 259096. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:00:13,760][3098297] Avg episode reward: [(0, '0.387')]
[2025-09-21 18:00:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 258048. Throughput: 0: 257.4. Samples: 259898. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:00:18,753][3098297] Avg episode reward: [(0, '0.394')]
[2025-09-21 18:00:18,771][3098570] Saving new best policy, reward=0.394!
[2025-09-21 18:00:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 259072. Throughput: 0: 257.3. Samples: 261446. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:00:23,753][3098297] Avg episode reward: [(0, '0.404')]
[2025-09-21 18:00:23,754][3098570] Saving new best policy, reward=0.404!
[2025-09-21 18:00:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 260096. Throughput: 0: 257.6. Samples: 262998. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:00:28,753][3098297] Avg episode reward: [(0, '0.389')]
[2025-09-21 18:00:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 261120. Throughput: 0: 257.4. Samples: 263778. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:00:33,768][3098297] Avg episode reward: [(0, '0.385')]
[2025-09-21 18:00:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 263168. Throughput: 0: 258.0. Samples: 265336. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:00:38,753][3098297] Avg episode reward: [(0, '0.385')]
[2025-09-21 18:00:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 264192. Throughput: 0: 259.2. Samples: 266882. Policy #0 lag: (min: 0.0, avg: 2.9, max: 11.0)
[2025-09-21 18:00:43,753][3098297] Avg episode reward: [(0, '0.392')]
[2025-09-21 18:00:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 265216. Throughput: 0: 258.8. Samples: 267654. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:00:48,757][3098297] Avg episode reward: [(0, '0.383')]
[2025-09-21 18:00:48,799][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000259_265216.pth...
[2025-09-21 18:00:48,822][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000199_203776.pth
[2025-09-21 18:00:49,256][3098647] Updated weights for policy 0, policy_version 260 (0.0090)
[2025-09-21 18:00:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 267264. Throughput: 0: 257.9. Samples: 269160. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:00:53,753][3098297] Avg episode reward: [(0, '0.381')]
[2025-09-21 18:00:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 268288. Throughput: 0: 256.6. Samples: 270642. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:00:58,757][3098297] Avg episode reward: [(0, '0.403')]
[2025-09-21 18:01:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 269312. Throughput: 0: 256.4. Samples: 271436. Policy #0 lag: (min: 0.0, avg: 1.8, max: 6.0)
[2025-09-21 18:01:03,756][3098297] Avg episode reward: [(0, '0.403')]
[2025-09-21 18:01:08,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 270336. Throughput: 0: 255.9. Samples: 272960. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:01:08,757][3098297] Avg episode reward: [(0, '0.417')]
[2025-09-21 18:01:08,787][3098570] Saving new best policy, reward=0.417!
[2025-09-21 18:01:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 272384. Throughput: 0: 256.0. Samples: 274518. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:01:13,756][3098297] Avg episode reward: [(0, '0.426')]
[2025-09-21 18:01:13,759][3098570] Saving new best policy, reward=0.426!
[2025-09-21 18:01:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 273408. Throughput: 0: 256.1. Samples: 275300. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:01:18,753][3098297] Avg episode reward: [(0, '0.430')]
[2025-09-21 18:01:18,761][3098570] Saving new best policy, reward=0.430!
[2025-09-21 18:01:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 274432. Throughput: 0: 255.7. Samples: 276842. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:01:23,753][3098297] Avg episode reward: [(0, '0.425')]
[2025-09-21 18:01:28,746][3098647] Updated weights for policy 0, policy_version 270 (0.0061)
[2025-09-21 18:01:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 276480. Throughput: 0: 255.9. Samples: 278396. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:01:28,753][3098297] Avg episode reward: [(0, '0.430')]
[2025-09-21 18:01:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 277504. Throughput: 0: 255.9. Samples: 279170. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:01:33,753][3098297] Avg episode reward: [(0, '0.436')]
[2025-09-21 18:01:33,755][3098570] Saving new best policy, reward=0.436!
[2025-09-21 18:01:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 278528. Throughput: 0: 256.2. Samples: 280688. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:01:38,753][3098297] Avg episode reward: [(0, '0.448')]
[2025-09-21 18:01:38,760][3098570] Saving new best policy, reward=0.448!
[2025-09-21 18:01:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 279552. Throughput: 0: 257.8. Samples: 282242. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:01:43,753][3098297] Avg episode reward: [(0, '0.443')]
[2025-09-21 18:01:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 280576. Throughput: 0: 257.6. Samples: 283028. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:01:48,753][3098297] Avg episode reward: [(0, '0.449')]
[2025-09-21 18:01:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 282624. Throughput: 0: 257.8. Samples: 284560. Policy #0 lag: (min: 0.0, avg: 1.8, max: 8.0)
[2025-09-21 18:01:53,753][3098297] Avg episode reward: [(0, '0.449')]
[2025-09-21 18:01:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 282624. Throughput: 0: 256.7. Samples: 286070. Policy #0 lag: (min: 0.0, avg: 1.8, max: 8.0)
[2025-09-21 18:01:58,753][3098297] Avg episode reward: [(0, '0.449')]
[2025-09-21 18:02:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 284672. Throughput: 0: 256.6. Samples: 286846. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:02:03,753][3098297] Avg episode reward: [(0, '0.445')]
[2025-09-21 18:02:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 285696. Throughput: 0: 256.3. Samples: 288376. Policy #0 lag: (min: 0.0, avg: 3.3, max: 12.0)
[2025-09-21 18:02:08,753][3098297] Avg episode reward: [(0, '0.445')]
[2025-09-21 18:02:10,248][3098647] Updated weights for policy 0, policy_version 280 (0.0060)
[2025-09-21 18:02:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 287744. Throughput: 0: 256.2. Samples: 289924. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:02:13,756][3098297] Avg episode reward: [(0, '0.444')]
[2025-09-21 18:02:18,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 288768. Throughput: 0: 256.4. Samples: 290708. Policy #0 lag: (min: 0.0, avg: 2.2, max: 5.0)
[2025-09-21 18:02:18,757][3098297] Avg episode reward: [(0, '0.444')]
[2025-09-21 18:02:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 289792. Throughput: 0: 257.2. Samples: 292264. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:02:23,754][3098297] Avg episode reward: [(0, '0.455')]
[2025-09-21 18:02:23,755][3098570] Saving new best policy, reward=0.455!
[2025-09-21 18:02:28,756][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 291840. Throughput: 0: 257.7. Samples: 293840. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:02:28,760][3098297] Avg episode reward: [(0, '0.455')]
[2025-09-21 18:02:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 291840. Throughput: 0: 257.5. Samples: 294616. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:02:33,753][3098297] Avg episode reward: [(0, '0.455')]
[2025-09-21 18:02:38,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 293888. Throughput: 0: 258.1. Samples: 296174. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:02:38,753][3098297] Avg episode reward: [(0, '0.455')]
[2025-09-21 18:02:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 294912. Throughput: 0: 259.1. Samples: 297730. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:02:43,753][3098297] Avg episode reward: [(0, '0.457')]
[2025-09-21 18:02:45,431][3098570] Saving new best policy, reward=0.457!
[2025-09-21 18:02:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 295936. Throughput: 0: 258.9. Samples: 298496. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:02:48,753][3098297] Avg episode reward: [(0, '0.453')]
[2025-09-21 18:02:48,771][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000289_295936.pth...
[2025-09-21 18:02:48,910][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000230_235520.pth
[2025-09-21 18:02:51,292][3098647] Updated weights for policy 0, policy_version 290 (0.0085)
[2025-09-21 18:02:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 297984. Throughput: 0: 259.0. Samples: 300030. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:02:53,753][3098297] Avg episode reward: [(0, '0.450')]
[2025-09-21 18:02:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 299008. Throughput: 0: 258.7. Samples: 301566. Policy #0 lag: (min: 0.0, avg: 2.4, max: 5.0)
[2025-09-21 18:02:58,760][3098297] Avg episode reward: [(0, '0.450')]
[2025-09-21 18:03:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 300032. Throughput: 0: 258.4. Samples: 302336. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:03:03,756][3098297] Avg episode reward: [(0, '0.422')]
[2025-09-21 18:03:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 302080. Throughput: 0: 258.2. Samples: 303884. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:03:08,753][3098297] Avg episode reward: [(0, '0.422')]
[2025-09-21 18:03:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 302080. Throughput: 0: 257.8. Samples: 305442. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:03:13,753][3098297] Avg episode reward: [(0, '0.422')]
[2025-09-21 18:03:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 304128. Throughput: 0: 257.9. Samples: 306224. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:03:18,757][3098297] Avg episode reward: [(0, '0.422')]
[2025-09-21 18:03:23,754][3098297] Fps is (10 sec: 409.5, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 306176. Throughput: 0: 257.7. Samples: 307772. Policy #0 lag: (min: 0.0, avg: 2.3, max: 12.0)
[2025-09-21 18:03:23,756][3098297] Avg episode reward: [(0, '0.422')]
[2025-09-21 18:03:27,606][3098647] Updated weights for policy 0, policy_version 300 (0.0084)
[2025-09-21 18:03:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 307200. Throughput: 0: 257.6. Samples: 309322. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:03:28,753][3098297] Avg episode reward: [(0, '0.411')]
[2025-09-21 18:03:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 308224. Throughput: 0: 258.1. Samples: 310112. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:03:33,756][3098297] Avg episode reward: [(0, '0.406')]
[2025-09-21 18:03:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 263.8). Total num frames: 310272. Throughput: 0: 258.5. Samples: 311662. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:03:38,757][3098297] Avg episode reward: [(0, '0.408')]
[2025-09-21 18:03:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 310272. Throughput: 0: 259.2. Samples: 313228. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:03:43,757][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:03:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 312320. Throughput: 0: 259.1. Samples: 313994. Policy #0 lag: (min: 0.0, avg: 1.3, max: 4.0)
[2025-09-21 18:03:48,756][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:03:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 313344. Throughput: 0: 259.7. Samples: 315570. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:03:53,753][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:03:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 314368. Throughput: 0: 258.6. Samples: 317078. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:03:58,754][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:04:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 315392. Throughput: 0: 258.7. Samples: 317864. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:04:03,753][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:04:07,161][3098647] Updated weights for policy 0, policy_version 310 (0.0045)
[2025-09-21 18:04:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 317440. Throughput: 0: 258.0. Samples: 319380. Policy #0 lag: (min: 0.0, avg: 2.9, max: 12.0)
[2025-09-21 18:04:08,753][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:04:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 318464. Throughput: 0: 254.6. Samples: 320780. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:04:13,756][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:04:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 319488. Throughput: 0: 254.1. Samples: 321546. Policy #0 lag: (min: 0.0, avg: 2.4, max: 12.0)
[2025-09-21 18:04:18,759][3098297] Avg episode reward: [(0, '0.403')]
[2025-09-21 18:04:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 320512. Throughput: 0: 252.6. Samples: 323030. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:04:23,759][3098297] Avg episode reward: [(0, '0.414')]
[2025-09-21 18:04:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 322560. Throughput: 0: 252.0. Samples: 324568. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:04:28,759][3098297] Avg episode reward: [(0, '0.396')]
[2025-09-21 18:04:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 322560. Throughput: 0: 252.3. Samples: 325348. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:04:33,753][3098297] Avg episode reward: [(0, '0.396')]
[2025-09-21 18:04:38,756][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 324608. Throughput: 0: 251.8. Samples: 326900. Policy #0 lag: (min: 0.0, avg: 1.7, max: 10.0)
[2025-09-21 18:04:38,758][3098297] Avg episode reward: [(0, '0.396')]
[2025-09-21 18:04:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 325632. Throughput: 0: 252.4. Samples: 328436. Policy #0 lag: (min: 0.0, avg: 1.9, max: 8.0)
[2025-09-21 18:04:43,757][3098297] Avg episode reward: [(0, '0.396')]
[2025-09-21 18:04:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 326656. Throughput: 0: 252.3. Samples: 329220. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:04:48,757][3098297] Avg episode reward: [(0, '0.396')]
[2025-09-21 18:04:48,778][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000319_326656.pth...
[2025-09-21 18:04:48,809][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000259_265216.pth
[2025-09-21 18:04:49,124][3098647] Updated weights for policy 0, policy_version 320 (0.0069)
[2025-09-21 18:04:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 327680. Throughput: 0: 253.1. Samples: 330768. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:04:53,753][3098297] Avg episode reward: [(0, '0.396')]
[2025-09-21 18:04:58,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 329728. Throughput: 0: 255.3. Samples: 332270. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:04:58,753][3098297] Avg episode reward: [(0, '0.386')]
[2025-09-21 18:05:03,753][3098297] Fps is (10 sec: 409.6, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 331776. Throughput: 0: 255.7. Samples: 333052. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:05:03,753][3098297] Avg episode reward: [(0, '0.378')]
[2025-09-21 18:05:08,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 331776. Throughput: 0: 257.0. Samples: 334594. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:05:08,757][3098297] Avg episode reward: [(0, '0.363')]
[2025-09-21 18:05:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 333824. Throughput: 0: 257.5. Samples: 336156. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:05:13,753][3098297] Avg episode reward: [(0, '0.363')]
[2025-09-21 18:05:18,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 334848. Throughput: 0: 257.3. Samples: 336928. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:05:18,757][3098297] Avg episode reward: [(0, '0.363')]
[2025-09-21 18:05:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 336896. Throughput: 0: 257.6. Samples: 338490. Policy #0 lag: (min: 0.0, avg: 1.7, max: 9.0)
[2025-09-21 18:05:23,753][3098297] Avg episode reward: [(0, '0.351')]
[2025-09-21 18:05:28,493][3098647] Updated weights for policy 0, policy_version 330 (0.0093)
[2025-09-21 18:05:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 337920. Throughput: 0: 257.7. Samples: 340032. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:05:28,753][3098297] Avg episode reward: [(0, '0.351')]
[2025-09-21 18:05:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 338944. Throughput: 0: 257.4. Samples: 340804. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:05:33,753][3098297] Avg episode reward: [(0, '0.351')]
[2025-09-21 18:05:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 340992. Throughput: 0: 257.4. Samples: 342352. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:05:38,754][3098297] Avg episode reward: [(0, '0.345')]
[2025-09-21 18:05:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 340992. Throughput: 0: 258.8. Samples: 343916. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:05:43,753][3098297] Avg episode reward: [(0, '0.345')]
[2025-09-21 18:05:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 343040. Throughput: 0: 258.7. Samples: 344694. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:05:48,753][3098297] Avg episode reward: [(0, '0.346')]
[2025-09-21 18:05:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 344064. Throughput: 0: 259.0. Samples: 346250. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:05:53,753][3098297] Avg episode reward: [(0, '0.346')]
[2025-09-21 18:05:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 345088. Throughput: 0: 258.2. Samples: 347774. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:05:58,757][3098297] Avg episode reward: [(0, '0.346')]
[2025-09-21 18:06:03,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 346112. Throughput: 0: 258.1. Samples: 348542. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:06:03,761][3098297] Avg episode reward: [(0, '0.347')]
[2025-09-21 18:06:07,831][3098647] Updated weights for policy 0, policy_version 340 (0.0097)
[2025-09-21 18:06:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 348160. Throughput: 0: 257.6. Samples: 350082. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:06:08,753][3098297] Avg episode reward: [(0, '0.347')]
[2025-09-21 18:06:13,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 349184. Throughput: 0: 257.6. Samples: 351626. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:06:13,753][3098297] Avg episode reward: [(0, '0.362')]
[2025-09-21 18:06:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 350208. Throughput: 0: 257.9. Samples: 352412. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:06:18,757][3098297] Avg episode reward: [(0, '0.362')]
[2025-09-21 18:06:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 351232. Throughput: 0: 257.9. Samples: 353958. Policy #0 lag: (min: 0.0, avg: 2.0, max: 8.0)
[2025-09-21 18:06:23,757][3098297] Avg episode reward: [(0, '0.362')]
[2025-09-21 18:06:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 353280. Throughput: 0: 257.4. Samples: 355500. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:06:28,758][3098297] Avg episode reward: [(0, '0.362')]
[2025-09-21 18:06:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 354304. Throughput: 0: 257.7. Samples: 356290. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:06:33,753][3098297] Avg episode reward: [(0, '0.362')]
[2025-09-21 18:06:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 355328. Throughput: 0: 257.0. Samples: 357816. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:06:38,760][3098297] Avg episode reward: [(0, '0.359')]
[2025-09-21 18:06:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 356352. Throughput: 0: 258.0. Samples: 359384. Policy #0 lag: (min: 0.0, avg: 1.6, max: 9.0)
[2025-09-21 18:06:43,757][3098297] Avg episode reward: [(0, '0.357')]
[2025-09-21 18:06:48,605][3098647] Updated weights for policy 0, policy_version 350 (0.0109)
[2025-09-21 18:06:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 358400. Throughput: 0: 258.2. Samples: 360162. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:06:48,753][3098297] Avg episode reward: [(0, '0.361')]
[2025-09-21 18:06:48,765][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000350_358400.pth...
[2025-09-21 18:06:48,791][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000289_295936.pth
[2025-09-21 18:06:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 359424. Throughput: 0: 256.3. Samples: 361616. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:06:53,753][3098297] Avg episode reward: [(0, '0.363')]
[2025-09-21 18:06:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 360448. Throughput: 0: 255.6. Samples: 363130. Policy #0 lag: (min: 0.0, avg: 3.0, max: 11.0)
[2025-09-21 18:06:58,764][3098297] Avg episode reward: [(0, '0.363')]
[2025-09-21 18:07:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 362496. Throughput: 0: 255.7. Samples: 363918. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:07:03,753][3098297] Avg episode reward: [(0, '0.363')]
[2025-09-21 18:07:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 363520. Throughput: 0: 255.3. Samples: 365446. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:07:08,753][3098297] Avg episode reward: [(0, '0.386')]
[2025-09-21 18:07:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 364544. Throughput: 0: 254.8. Samples: 366966. Policy #0 lag: (min: 0.0, avg: 2.2, max: 12.0)
[2025-09-21 18:07:13,753][3098297] Avg episode reward: [(0, '0.403')]
[2025-09-21 18:07:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 365568. Throughput: 0: 254.6. Samples: 367746. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:07:18,753][3098297] Avg episode reward: [(0, '0.412')]
[2025-09-21 18:07:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 366592. Throughput: 0: 254.4. Samples: 369264. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:07:23,758][3098297] Avg episode reward: [(0, '0.414')]
[2025-09-21 18:07:28,267][3098647] Updated weights for policy 0, policy_version 360 (0.0090)
[2025-09-21 18:07:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 368640. Throughput: 0: 253.7. Samples: 370802. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:07:28,753][3098297] Avg episode reward: [(0, '0.400')]
[2025-09-21 18:07:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 369664. Throughput: 0: 253.5. Samples: 371572. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 18:07:33,757][3098297] Avg episode reward: [(0, '0.405')]
[2025-09-21 18:07:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 370688. Throughput: 0: 255.3. Samples: 373106. Policy #0 lag: (min: 0.0, avg: 3.2, max: 11.0)
[2025-09-21 18:07:38,753][3098297] Avg episode reward: [(0, '0.413')]
[2025-09-21 18:07:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 372736. Throughput: 0: 255.6. Samples: 374632. Policy #0 lag: (min: 0.0, avg: 1.9, max: 6.0)
[2025-09-21 18:07:43,753][3098297] Avg episode reward: [(0, '0.414')]
[2025-09-21 18:07:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 373760. Throughput: 0: 255.5. Samples: 375414. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:07:48,753][3098297] Avg episode reward: [(0, '0.432')]
[2025-09-21 18:07:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 374784. Throughput: 0: 255.8. Samples: 376956. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:07:53,753][3098297] Avg episode reward: [(0, '0.452')]
[2025-09-21 18:07:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 375808. Throughput: 0: 255.3. Samples: 378456. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:07:58,753][3098297] Avg episode reward: [(0, '0.479')]
[2025-09-21 18:07:58,761][3098570] Saving new best policy, reward=0.479!
[2025-09-21 18:08:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 376832. Throughput: 0: 255.4. Samples: 379238. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:08:03,753][3098297] Avg episode reward: [(0, '0.487')]
[2025-09-21 18:08:03,754][3098570] Saving new best policy, reward=0.487!
[2025-09-21 18:08:07,749][3098647] Updated weights for policy 0, policy_version 370 (0.0069)
[2025-09-21 18:08:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 378880. Throughput: 0: 256.3. Samples: 380796. Policy #0 lag: (min: 0.0, avg: 2.9, max: 10.0)
[2025-09-21 18:08:08,753][3098297] Avg episode reward: [(0, '0.494')]
[2025-09-21 18:08:08,760][3098570] Saving new best policy, reward=0.494!
[2025-09-21 18:08:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 379904. Throughput: 0: 256.1. Samples: 382328. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:08:13,753][3098297] Avg episode reward: [(0, '0.500')]
[2025-09-21 18:08:13,754][3098570] Saving new best policy, reward=0.500!
[2025-09-21 18:08:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 380928. Throughput: 0: 256.5. Samples: 383114. Policy #0 lag: (min: 0.0, avg: 2.9, max: 10.0)
[2025-09-21 18:08:18,753][3098297] Avg episode reward: [(0, '0.516')]
[2025-09-21 18:08:18,773][3098570] Saving new best policy, reward=0.516!
[2025-09-21 18:08:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 381952. Throughput: 0: 256.5. Samples: 384650. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:08:23,753][3098297] Avg episode reward: [(0, '0.530')]
[2025-09-21 18:08:23,754][3098570] Saving new best policy, reward=0.530!
[2025-09-21 18:08:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 384000. Throughput: 0: 257.0. Samples: 386198. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:08:28,758][3098297] Avg episode reward: [(0, '0.530')]
[2025-09-21 18:08:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 385024. Throughput: 0: 257.1. Samples: 386984. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:08:33,757][3098297] Avg episode reward: [(0, '0.529')]
[2025-09-21 18:08:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 386048. Throughput: 0: 257.6. Samples: 388548. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:08:38,753][3098297] Avg episode reward: [(0, '0.529')]
[2025-09-21 18:08:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 387072. Throughput: 0: 259.2. Samples: 390118. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:08:43,753][3098297] Avg episode reward: [(0, '0.537')]
[2025-09-21 18:08:43,754][3098570] Saving new best policy, reward=0.537!
[2025-09-21 18:08:47,045][3098647] Updated weights for policy 0, policy_version 380 (0.0077)
[2025-09-21 18:08:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 389120. Throughput: 0: 258.7. Samples: 390878. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:08:48,753][3098297] Avg episode reward: [(0, '0.537')]
[2025-09-21 18:08:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000380_389120.pth...
[2025-09-21 18:08:48,790][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000319_326656.pth
[2025-09-21 18:08:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 390144. Throughput: 0: 258.8. Samples: 392440. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:08:53,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:08:53,754][3098570] Saving new best policy, reward=0.551!
[2025-09-21 18:08:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 391168. Throughput: 0: 258.6. Samples: 393964. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:08:58,757][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:03,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 393216. Throughput: 0: 258.6. Samples: 394752. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:09:03,761][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 394240. Throughput: 0: 258.7. Samples: 396290. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:09:08,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 395264. Throughput: 0: 258.9. Samples: 397850. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:09:13,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:18,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 396288. Throughput: 0: 258.7. Samples: 398626. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:09:18,758][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 398336. Throughput: 0: 259.0. Samples: 400202. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:09:23,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:27,164][3098647] Updated weights for policy 0, policy_version 390 (0.0035)
[2025-09-21 18:09:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 399360. Throughput: 0: 258.4. Samples: 401744. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:09:28,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 400384. Throughput: 0: 258.7. Samples: 402520. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:09:33,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 402432. Throughput: 0: 258.1. Samples: 404056. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:09:38,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 403456. Throughput: 0: 258.1. Samples: 405580. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:09:43,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 404480. Throughput: 0: 258.1. Samples: 406368. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:09:48,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 405504. Throughput: 0: 258.3. Samples: 407914. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:09:53,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:09:58,788][3098297] Fps is (10 sec: 306.1, 60 sec: 272.9, 300 sec: 256.8). Total num frames: 407552. Throughput: 0: 257.7. Samples: 409456. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 18:09:58,788][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 408576. Throughput: 0: 257.9. Samples: 410230. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:10:03,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:07,943][3098647] Updated weights for policy 0, policy_version 400 (0.0061)
[2025-09-21 18:10:08,753][3098297] Fps is (10 sec: 205.5, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 409600. Throughput: 0: 257.2. Samples: 411774. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:10:08,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 410624. Throughput: 0: 257.8. Samples: 413346. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:10:13,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:18,755][3098297] Fps is (10 sec: 307.1, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 412672. Throughput: 0: 257.7. Samples: 414116. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:10:18,756][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 413696. Throughput: 0: 258.6. Samples: 415692. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:10:23,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:28,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 414720. Throughput: 0: 259.1. Samples: 417240. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:10:28,764][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 415744. Throughput: 0: 259.0. Samples: 418024. Policy #0 lag: (min: 0.0, avg: 2.7, max: 9.0)
[2025-09-21 18:10:33,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 416768. Throughput: 0: 259.3. Samples: 419584. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:10:38,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 418816. Throughput: 0: 259.6. Samples: 421130. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:10:43,757][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:48,312][3098647] Updated weights for policy 0, policy_version 410 (0.0108)
[2025-09-21 18:10:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 419840. Throughput: 0: 260.0. Samples: 421928. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:10:48,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:48,795][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000410_419840.pth...
[2025-09-21 18:10:48,830][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000350_358400.pth
[2025-09-21 18:10:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 420864. Throughput: 0: 260.0. Samples: 423476. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:10:53,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:10:58,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.1, 300 sec: 260.3). Total num frames: 422912. Throughput: 0: 259.1. Samples: 425006. Policy #0 lag: (min: 0.0, avg: 2.0, max: 8.0)
[2025-09-21 18:10:58,757][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:11:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 423936. Throughput: 0: 259.6. Samples: 425798. Policy #0 lag: (min: 0.0, avg: 1.9, max: 12.0)
[2025-09-21 18:11:03,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:11:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 424960. Throughput: 0: 258.7. Samples: 427334. Policy #0 lag: (min: 0.0, avg: 1.9, max: 12.0)
[2025-09-21 18:11:08,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:11:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 425984. Throughput: 0: 258.9. Samples: 428890. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:11:13,753][3098297] Avg episode reward: [(0, '0.560')]
[2025-09-21 18:11:13,754][3098570] Saving new best policy, reward=0.560!
[2025-09-21 18:11:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 427008. Throughput: 0: 259.2. Samples: 429688. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:11:18,757][3098297] Avg episode reward: [(0, '0.560')]
[2025-09-21 18:11:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 429056. Throughput: 0: 258.7. Samples: 431224. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:11:23,757][3098297] Avg episode reward: [(0, '0.560')]
[2025-09-21 18:11:27,180][3098647] Updated weights for policy 0, policy_version 420 (0.0108)
[2025-09-21 18:11:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 430080. Throughput: 0: 259.0. Samples: 432784. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 18:11:28,758][3098297] Avg episode reward: [(0, '0.574')]
[2025-09-21 18:11:28,804][3098570] Saving new best policy, reward=0.574!
[2025-09-21 18:11:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 431104. Throughput: 0: 258.5. Samples: 433562. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:11:33,753][3098297] Avg episode reward: [(0, '0.574')]
[2025-09-21 18:11:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 433152. Throughput: 0: 258.6. Samples: 435112. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:11:38,757][3098297] Avg episode reward: [(0, '0.575')]
[2025-09-21 18:11:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 434176. Throughput: 0: 258.8. Samples: 436652. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:11:43,761][3098297] Avg episode reward: [(0, '0.575')]
[2025-09-21 18:11:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 435200. Throughput: 0: 258.7. Samples: 437442. Policy #0 lag: (min: 0.0, avg: 2.5, max: 12.0)
[2025-09-21 18:11:48,757][3098297] Avg episode reward: [(0, '0.575')]
[2025-09-21 18:11:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 436224. Throughput: 0: 258.6. Samples: 438970. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:11:53,753][3098297] Avg episode reward: [(0, '0.563')]
[2025-09-21 18:11:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 438272. Throughput: 0: 257.7. Samples: 440486. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:11:58,753][3098297] Avg episode reward: [(0, '0.566')]
[2025-09-21 18:12:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 439296. Throughput: 0: 257.6. Samples: 441278. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:12:03,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:12:06,147][3098647] Updated weights for policy 0, policy_version 430 (0.0080)
[2025-09-21 18:12:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 440320. Throughput: 0: 257.4. Samples: 442808. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:12:08,753][3098297] Avg episode reward: [(0, '0.551')]
[2025-09-21 18:12:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 441344. Throughput: 0: 257.3. Samples: 444362. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:12:13,756][3098297] Avg episode reward: [(0, '0.566')]
[2025-09-21 18:12:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 443392. Throughput: 0: 257.0. Samples: 445128. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:12:18,753][3098297] Avg episode reward: [(0, '0.566')]
[2025-09-21 18:12:23,753][3098297] Fps is (10 sec: 409.6, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 445440. Throughput: 0: 256.9. Samples: 446670. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:12:23,753][3098297] Avg episode reward: [(0, '0.566')]
[2025-09-21 18:12:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 445440. Throughput: 0: 257.4. Samples: 448236. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:12:28,753][3098297] Avg episode reward: [(0, '0.567')]
[2025-09-21 18:12:33,753][3098297] Fps is (10 sec: 102.4, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 446464. Throughput: 0: 257.2. Samples: 449016. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:12:33,753][3098297] Avg episode reward: [(0, '0.567')]
[2025-09-21 18:12:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 448512. Throughput: 0: 257.7. Samples: 450568. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:12:38,757][3098297] Avg episode reward: [(0, '0.566')]
[2025-09-21 18:12:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 449536. Throughput: 0: 258.2. Samples: 452106. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:12:43,758][3098297] Avg episode reward: [(0, '0.567')]
[2025-09-21 18:12:46,444][3098647] Updated weights for policy 0, policy_version 440 (0.0104)
[2025-09-21 18:12:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 450560. Throughput: 0: 258.1. Samples: 452892. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:12:48,753][3098297] Avg episode reward: [(0, '0.568')]
[2025-09-21 18:12:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000440_450560.pth...
[2025-09-21 18:12:48,789][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000380_389120.pth
[2025-09-21 18:12:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 452608. Throughput: 0: 257.9. Samples: 454414. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:12:53,753][3098297] Avg episode reward: [(0, '0.571')]
[2025-09-21 18:12:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 453632. Throughput: 0: 255.7. Samples: 455868. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:12:58,753][3098297] Avg episode reward: [(0, '0.562')]
[2025-09-21 18:13:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 454656. Throughput: 0: 255.6. Samples: 456628. Policy #0 lag: (min: 0.0, avg: 3.1, max: 11.0)
[2025-09-21 18:13:03,753][3098297] Avg episode reward: [(0, '0.549')]
[2025-09-21 18:13:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 455680. Throughput: 0: 253.0. Samples: 458054. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:13:08,753][3098297] Avg episode reward: [(0, '0.568')]
[2025-09-21 18:13:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 456704. Throughput: 0: 251.9. Samples: 459570. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:13:13,753][3098297] Avg episode reward: [(0, '0.563')]
[2025-09-21 18:13:18,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 458752. Throughput: 0: 250.8. Samples: 460304. Policy #0 lag: (min: 0.0, avg: 2.2, max: 7.0)
[2025-09-21 18:13:18,757][3098297] Avg episode reward: [(0, '0.560')]
[2025-09-21 18:13:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 221.9, 300 sec: 253.4). Total num frames: 458752. Throughput: 0: 249.3. Samples: 461784. Policy #0 lag: (min: 0.0, avg: 2.2, max: 7.0)
[2025-09-21 18:13:23,753][3098297] Avg episode reward: [(0, '0.562')]
[2025-09-21 18:13:28,327][3098647] Updated weights for policy 0, policy_version 450 (0.0056)
[2025-09-21 18:13:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 460800. Throughput: 0: 247.8. Samples: 463258. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:13:28,753][3098297] Avg episode reward: [(0, '0.562')]
[2025-09-21 18:13:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 461824. Throughput: 0: 244.9. Samples: 463914. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:13:33,753][3098297] Avg episode reward: [(0, '0.574')]
[2025-09-21 18:13:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 462848. Throughput: 0: 241.9. Samples: 465300. Policy #0 lag: (min: 0.0, avg: 1.1, max: 3.0)
[2025-09-21 18:13:38,753][3098297] Avg episode reward: [(0, '0.561')]
[2025-09-21 18:13:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 463872. Throughput: 0: 242.0. Samples: 466756. Policy #0 lag: (min: 0.0, avg: 3.2, max: 12.0)
[2025-09-21 18:13:43,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:13:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 464896. Throughput: 0: 240.7. Samples: 467458. Policy #0 lag: (min: 0.0, avg: 3.4, max: 10.0)
[2025-09-21 18:13:48,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:13:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 221.9, 300 sec: 253.4). Total num frames: 465920. Throughput: 0: 242.6. Samples: 468970. Policy #0 lag: (min: 0.0, avg: 1.9, max: 12.0)
[2025-09-21 18:13:53,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:13:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 467968. Throughput: 0: 240.7. Samples: 470400. Policy #0 lag: (min: 0.0, avg: 2.2, max: 6.0)
[2025-09-21 18:13:58,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 468992. Throughput: 0: 240.3. Samples: 471116. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:14:03,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 470016. Throughput: 0: 240.1. Samples: 472590. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:14:08,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:12,630][3098647] Updated weights for policy 0, policy_version 460 (0.0066)
[2025-09-21 18:14:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 471040. Throughput: 0: 240.8. Samples: 474094. Policy #0 lag: (min: 0.0, avg: 2.5, max: 14.0)
[2025-09-21 18:14:13,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 221.9, 300 sec: 249.9). Total num frames: 472064. Throughput: 0: 241.3. Samples: 474774. Policy #0 lag: (min: 0.0, avg: 2.5, max: 14.0)
[2025-09-21 18:14:18,761][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:23,756][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 474112. Throughput: 0: 244.0. Samples: 476280. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:14:23,757][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:28,753][3098297] Fps is (10 sec: 409.7, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 476160. Throughput: 0: 245.2. Samples: 477792. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:14:28,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:33,753][3098297] Fps is (10 sec: 204.9, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 476160. Throughput: 0: 244.9. Samples: 478478. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:14:33,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:38,755][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 477184. Throughput: 0: 245.2. Samples: 480006. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:14:38,759][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 479232. Throughput: 0: 246.4. Samples: 481490. Policy #0 lag: (min: 0.0, avg: 1.9, max: 12.0)
[2025-09-21 18:14:43,756][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 480256. Throughput: 0: 244.8. Samples: 482132. Policy #0 lag: (min: 0.0, avg: 2.2, max: 5.0)
[2025-09-21 18:14:48,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:48,764][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000469_480256.pth...
[2025-09-21 18:14:48,788][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000410_419840.pth
[2025-09-21 18:14:53,753][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 246.5). Total num frames: 480256. Throughput: 0: 244.4. Samples: 483588. Policy #0 lag: (min: 0.0, avg: 2.2, max: 5.0)
[2025-09-21 18:14:53,753][3098297] Avg episode reward: [(0, '0.572')]
[2025-09-21 18:14:53,847][3098647] Updated weights for policy 0, policy_version 470 (0.0065)
[2025-09-21 18:14:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 482304. Throughput: 0: 243.3. Samples: 485044. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:14:58,753][3098297] Avg episode reward: [(0, '0.574')]
[2025-09-21 18:15:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 483328. Throughput: 0: 243.9. Samples: 485748. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:15:03,753][3098297] Avg episode reward: [(0, '0.575')]
[2025-09-21 18:15:08,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 485376. Throughput: 0: 243.5. Samples: 487236. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:15:08,758][3098297] Avg episode reward: [(0, '0.575')]
[2025-09-21 18:15:08,789][3098570] Saving new best policy, reward=0.575!
[2025-09-21 18:15:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 486400. Throughput: 0: 243.4. Samples: 488744. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:15:13,754][3098297] Avg episode reward: [(0, '0.575')]
[2025-09-21 18:15:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 487424. Throughput: 0: 242.6. Samples: 489394. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:15:18,753][3098297] Avg episode reward: [(0, '0.582')]
[2025-09-21 18:15:18,764][3098570] Saving new best policy, reward=0.582!
[2025-09-21 18:15:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 488448. Throughput: 0: 242.4. Samples: 490912. Policy #0 lag: (min: 0.0, avg: 2.7, max: 12.0)
[2025-09-21 18:15:23,753][3098297] Avg episode reward: [(0, '0.584')]
[2025-09-21 18:15:23,754][3098570] Saving new best policy, reward=0.584!
[2025-09-21 18:15:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 490496. Throughput: 0: 244.0. Samples: 492470. Policy #0 lag: (min: 0.0, avg: 2.0, max: 12.0)
[2025-09-21 18:15:28,753][3098297] Avg episode reward: [(0, '0.584')]
[2025-09-21 18:15:33,367][3098647] Updated weights for policy 0, policy_version 480 (0.0046)
[2025-09-21 18:15:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 491520. Throughput: 0: 246.4. Samples: 493218. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:15:33,753][3098297] Avg episode reward: [(0, '0.587')]
[2025-09-21 18:15:33,754][3098570] Saving new best policy, reward=0.587!
[2025-09-21 18:15:38,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 492544. Throughput: 0: 248.7. Samples: 494782. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:15:38,757][3098297] Avg episode reward: [(0, '0.586')]
[2025-09-21 18:15:43,756][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 493568. Throughput: 0: 250.8. Samples: 496332. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:15:43,758][3098297] Avg episode reward: [(0, '0.587')]
[2025-09-21 18:15:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 495616. Throughput: 0: 252.1. Samples: 497094. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:15:48,753][3098297] Avg episode reward: [(0, '0.608')]
[2025-09-21 18:15:48,774][3098570] Saving new best policy, reward=0.608!
[2025-09-21 18:15:53,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 249.9). Total num frames: 496640. Throughput: 0: 253.1. Samples: 498626. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:15:53,756][3098297] Avg episode reward: [(0, '0.592')]
[2025-09-21 18:15:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 497664. Throughput: 0: 253.1. Samples: 500134. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:15:58,753][3098297] Avg episode reward: [(0, '0.595')]
[2025-09-21 18:16:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 498688. Throughput: 0: 255.6. Samples: 500896. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:16:03,753][3098297] Avg episode reward: [(0, '0.604')]
[2025-09-21 18:16:08,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 499712. Throughput: 0: 255.6. Samples: 502416. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:16:08,757][3098297] Avg episode reward: [(0, '0.607')]
[2025-09-21 18:16:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 500736. Throughput: 0: 255.4. Samples: 503964. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:16:13,754][3098297] Avg episode reward: [(0, '0.612')]
[2025-09-21 18:16:13,754][3098570] Saving new best policy, reward=0.612!
[2025-09-21 18:16:14,568][3098647] Updated weights for policy 0, policy_version 490 (0.0072)
[2025-09-21 18:16:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 246.5). Total num frames: 501760. Throughput: 0: 255.2. Samples: 504702. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:16:18,753][3098297] Avg episode reward: [(0, '0.617')]
[2025-09-21 18:16:18,940][3098570] Saving new best policy, reward=0.617!
[2025-09-21 18:16:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 503808. Throughput: 0: 254.9. Samples: 506254. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:16:23,761][3098297] Avg episode reward: [(0, '0.619')]
[2025-09-21 18:16:23,763][3098570] Saving new best policy, reward=0.619!
[2025-09-21 18:16:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 504832. Throughput: 0: 254.4. Samples: 507778. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 18:16:28,753][3098297] Avg episode reward: [(0, '0.635')]
[2025-09-21 18:16:28,767][3098570] Saving new best policy, reward=0.635!
[2025-09-21 18:16:33,756][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 506880. Throughput: 0: 254.6. Samples: 508552. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:16:33,757][3098297] Avg episode reward: [(0, '0.641')]
[2025-09-21 18:16:33,758][3098570] Saving new best policy, reward=0.641!
[2025-09-21 18:16:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 507904. Throughput: 0: 254.5. Samples: 510078. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 18:16:38,753][3098297] Avg episode reward: [(0, '0.647')]
[2025-09-21 18:16:38,768][3098570] Saving new best policy, reward=0.647!
[2025-09-21 18:16:43,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 508928. Throughput: 0: 255.3. Samples: 511622. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:16:43,753][3098297] Avg episode reward: [(0, '0.632')]
[2025-09-21 18:16:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 509952. Throughput: 0: 255.6. Samples: 512396. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:16:48,753][3098297] Avg episode reward: [(0, '0.629')]
[2025-09-21 18:16:50,347][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000499_510976.pth...
[2025-09-21 18:16:50,376][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000440_450560.pth
[2025-09-21 18:16:52,300][3098647] Updated weights for policy 0, policy_version 500 (0.0096)
[2025-09-21 18:16:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 512000. Throughput: 0: 255.7. Samples: 513924. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:16:53,753][3098297] Avg episode reward: [(0, '0.633')]
[2025-09-21 18:16:58,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 513024. Throughput: 0: 254.6. Samples: 515422. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:16:58,757][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:03,756][3098297] Fps is (10 sec: 204.7, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 514048. Throughput: 0: 255.1. Samples: 516180. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:17:03,758][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:08,759][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 515072. Throughput: 0: 255.2. Samples: 517736. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:17:08,763][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:13,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 246.5). Total num frames: 516096. Throughput: 0: 255.5. Samples: 519274. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:17:13,753][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:18,756][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 246.5). Total num frames: 518144. Throughput: 0: 255.6. Samples: 520054. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:17:18,759][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 519168. Throughput: 0: 255.9. Samples: 521592. Policy #0 lag: (min: 0.0, avg: 2.2, max: 5.0)
[2025-09-21 18:17:23,753][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:28,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 520192. Throughput: 0: 256.2. Samples: 523152. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:17:28,753][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:33,615][3098647] Updated weights for policy 0, policy_version 510 (0.0033)
[2025-09-21 18:17:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 522240. Throughput: 0: 256.2. Samples: 523926. Policy #0 lag: (min: 0.0, avg: 2.5, max: 12.0)
[2025-09-21 18:17:33,753][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 523264. Throughput: 0: 256.8. Samples: 525482. Policy #0 lag: (min: 0.0, avg: 2.5, max: 12.0)
[2025-09-21 18:17:38,753][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 524288. Throughput: 0: 258.0. Samples: 527032. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:17:43,764][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 246.5). Total num frames: 525312. Throughput: 0: 258.3. Samples: 527804. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:17:48,753][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:53,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 527360. Throughput: 0: 258.3. Samples: 529360. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:17:53,756][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:17:58,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 528384. Throughput: 0: 257.9. Samples: 530882. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:17:58,757][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:18:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 530432. Throughput: 0: 258.1. Samples: 531666. Policy #0 lag: (min: 0.0, avg: 1.8, max: 13.0)
[2025-09-21 18:18:03,753][3098297] Avg episode reward: [(0, '0.634')]
[2025-09-21 18:18:08,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 530432. Throughput: 0: 258.0. Samples: 533202. Policy #0 lag: (min: 0.0, avg: 1.8, max: 13.0)
[2025-09-21 18:18:08,757][3098297] Avg episode reward: [(0, '0.651')]
[2025-09-21 18:18:08,779][3098570] Saving new best policy, reward=0.651!
[2025-09-21 18:18:13,753][3098297] Fps is (10 sec: 102.4, 60 sec: 256.0, 300 sec: 246.5). Total num frames: 531456. Throughput: 0: 254.1. Samples: 534588. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:18:13,753][3098297] Avg episode reward: [(0, '0.651')]
[2025-09-21 18:18:14,756][3098647] Updated weights for policy 0, policy_version 520 (0.0072)
[2025-09-21 18:18:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 533504. Throughput: 0: 253.4. Samples: 535328. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:18:18,753][3098297] Avg episode reward: [(0, '0.669')]
[2025-09-21 18:18:18,777][3098570] Saving new best policy, reward=0.669!
[2025-09-21 18:18:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 534528. Throughput: 0: 252.8. Samples: 536858. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:18:23,757][3098297] Avg episode reward: [(0, '0.669')]
[2025-09-21 18:18:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 535552. Throughput: 0: 252.9. Samples: 538414. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 18:18:28,753][3098297] Avg episode reward: [(0, '0.669')]
[2025-09-21 18:18:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 537600. Throughput: 0: 253.1. Samples: 539194. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 18:18:33,756][3098297] Avg episode reward: [(0, '0.670')]
[2025-09-21 18:18:33,759][3098570] Saving new best policy, reward=0.670!
[2025-09-21 18:18:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 538624. Throughput: 0: 252.6. Samples: 540728. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:18:38,753][3098297] Avg episode reward: [(0, '0.654')]
[2025-09-21 18:18:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 539648. Throughput: 0: 253.1. Samples: 542270. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:18:43,753][3098297] Avg episode reward: [(0, '0.654')]
[2025-09-21 18:18:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 540672. Throughput: 0: 252.7. Samples: 543036. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:18:48,753][3098297] Avg episode reward: [(0, '0.655')]
[2025-09-21 18:18:48,762][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000528_540672.pth...
[2025-09-21 18:18:48,792][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000469_480256.pth
[2025-09-21 18:18:53,239][3098647] Updated weights for policy 0, policy_version 530 (0.0095)
[2025-09-21 18:18:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 542720. Throughput: 0: 252.9. Samples: 544582. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:18:53,753][3098297] Avg episode reward: [(0, '0.670')]
[2025-09-21 18:18:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 543744. Throughput: 0: 255.6. Samples: 546088. Policy #0 lag: (min: 0.0, avg: 3.0, max: 11.0)
[2025-09-21 18:18:58,753][3098297] Avg episode reward: [(0, '0.670')]
[2025-09-21 18:19:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 544768. Throughput: 0: 256.2. Samples: 546858. Policy #0 lag: (min: 0.0, avg: 2.3, max: 12.0)
[2025-09-21 18:19:03,753][3098297] Avg episode reward: [(0, '0.655')]
[2025-09-21 18:19:08,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 545792. Throughput: 0: 256.3. Samples: 548390. Policy #0 lag: (min: 0.0, avg: 1.7, max: 8.0)
[2025-09-21 18:19:08,757][3098297] Avg episode reward: [(0, '0.670')]
[2025-09-21 18:19:13,757][3098297] Fps is (10 sec: 204.7, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 546816. Throughput: 0: 256.0. Samples: 549934. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:19:13,757][3098297] Avg episode reward: [(0, '0.673')]
[2025-09-21 18:19:14,123][3098570] Saving new best policy, reward=0.673!
[2025-09-21 18:19:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 547840. Throughput: 0: 255.4. Samples: 550686. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:19:18,753][3098297] Avg episode reward: [(0, '0.673')]
[2025-09-21 18:19:23,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 549888. Throughput: 0: 255.7. Samples: 552236. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:19:23,753][3098297] Avg episode reward: [(0, '0.679')]
[2025-09-21 18:19:23,754][3098570] Saving new best policy, reward=0.679!
[2025-09-21 18:19:28,754][3098297] Fps is (10 sec: 409.5, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 551936. Throughput: 0: 255.5. Samples: 553770. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:19:28,759][3098297] Avg episode reward: [(0, '0.667')]
[2025-09-21 18:19:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 551936. Throughput: 0: 255.8. Samples: 554548. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:19:33,756][3098297] Avg episode reward: [(0, '0.668')]
[2025-09-21 18:19:34,179][3098647] Updated weights for policy 0, policy_version 540 (0.0087)
[2025-09-21 18:19:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 553984. Throughput: 0: 255.3. Samples: 556072. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:19:38,753][3098297] Avg episode reward: [(0, '0.669')]
[2025-09-21 18:19:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 555008. Throughput: 0: 256.6. Samples: 557636. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:19:43,753][3098297] Avg episode reward: [(0, '0.671')]
[2025-09-21 18:19:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 556032. Throughput: 0: 256.6. Samples: 558404. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:19:48,753][3098297] Avg episode reward: [(0, '0.670')]
[2025-09-21 18:19:53,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 558080. Throughput: 0: 256.6. Samples: 559938. Policy #0 lag: (min: 0.0, avg: 1.3, max: 4.0)
[2025-09-21 18:19:53,758][3098297] Avg episode reward: [(0, '0.683')]
[2025-09-21 18:19:53,760][3098570] Saving new best policy, reward=0.683!
[2025-09-21 18:19:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 558080. Throughput: 0: 254.9. Samples: 561404. Policy #0 lag: (min: 0.0, avg: 1.3, max: 4.0)
[2025-09-21 18:19:58,753][3098297] Avg episode reward: [(0, '0.683')]
[2025-09-21 18:20:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 560128. Throughput: 0: 255.0. Samples: 562160. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:20:03,753][3098297] Avg episode reward: [(0, '0.684')]
[2025-09-21 18:20:03,754][3098570] Saving new best policy, reward=0.684!
[2025-09-21 18:20:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 561152. Throughput: 0: 254.7. Samples: 563698. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:20:08,753][3098297] Avg episode reward: [(0, '0.684')]
[2025-09-21 18:20:12,438][3098647] Updated weights for policy 0, policy_version 550 (0.0054)
[2025-09-21 18:20:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 563200. Throughput: 0: 254.0. Samples: 565202. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:20:13,757][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:18,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 564224. Throughput: 0: 254.1. Samples: 565984. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:20:18,757][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 565248. Throughput: 0: 255.0. Samples: 567546. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:20:23,757][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 566272. Throughput: 0: 254.9. Samples: 569108. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:20:28,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 567296. Throughput: 0: 254.7. Samples: 569864. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:20:33,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 569344. Throughput: 0: 255.3. Samples: 571426. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:20:38,757][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 570368. Throughput: 0: 257.3. Samples: 572982. Policy #0 lag: (min: 0.0, avg: 1.9, max: 4.0)
[2025-09-21 18:20:43,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:48,756][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 571392. Throughput: 0: 257.9. Samples: 573768. Policy #0 lag: (min: 0.0, avg: 3.0, max: 11.0)
[2025-09-21 18:20:48,757][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:48,770][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000558_571392.pth...
[2025-09-21 18:20:48,911][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000499_510976.pth
[2025-09-21 18:20:53,158][3098647] Updated weights for policy 0, policy_version 560 (0.0094)
[2025-09-21 18:20:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 573440. Throughput: 0: 258.1. Samples: 575312. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:20:53,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:20:58,753][3098297] Fps is (10 sec: 307.3, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 574464. Throughput: 0: 258.0. Samples: 576812. Policy #0 lag: (min: 0.0, avg: 2.0, max: 4.0)
[2025-09-21 18:20:58,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:21:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 575488. Throughput: 0: 257.7. Samples: 577580. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:21:03,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:21:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 576512. Throughput: 0: 257.1. Samples: 579116. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:21:08,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:21:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 577536. Throughput: 0: 257.2. Samples: 580682. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:21:13,757][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:21:18,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 579584. Throughput: 0: 256.9. Samples: 581424. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:21:18,757][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:21:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 580608. Throughput: 0: 256.9. Samples: 582984. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:21:23,753][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:21:28,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 581632. Throughput: 0: 256.6. Samples: 584528. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 18:21:28,757][3098297] Avg episode reward: [(0, '0.675')]
[2025-09-21 18:21:32,407][3098647] Updated weights for policy 0, policy_version 570 (0.0060)
[2025-09-21 18:21:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 583680. Throughput: 0: 256.2. Samples: 585296. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:21:33,753][3098297] Avg episode reward: [(0, '0.675')]
[2025-09-21 18:21:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 584704. Throughput: 0: 255.9. Samples: 586828. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:21:38,760][3098297] Avg episode reward: [(0, '0.675')]
[2025-09-21 18:21:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 585728. Throughput: 0: 257.4. Samples: 588394. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:21:43,761][3098297] Avg episode reward: [(0, '0.675')]
[2025-09-21 18:21:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 586752. Throughput: 0: 257.4. Samples: 589162. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:21:48,753][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:21:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 587776. Throughput: 0: 257.6. Samples: 590710. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:21:53,753][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:21:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 589824. Throughput: 0: 256.7. Samples: 592234. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:21:58,757][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:22:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 590848. Throughput: 0: 257.3. Samples: 593004. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:22:03,753][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:22:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 592896. Throughput: 0: 256.9. Samples: 594544. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:22:08,753][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:22:13,694][3098647] Updated weights for policy 0, policy_version 580 (0.0094)
[2025-09-21 18:22:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 593920. Throughput: 0: 257.1. Samples: 596098. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:22:13,753][3098297] Avg episode reward: [(0, '0.674')]
[2025-09-21 18:22:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 594944. Throughput: 0: 257.5. Samples: 596884. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:22:18,757][3098297] Avg episode reward: [(0, '0.673')]
[2025-09-21 18:22:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 595968. Throughput: 0: 257.6. Samples: 598420. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:22:23,753][3098297] Avg episode reward: [(0, '0.676')]
[2025-09-21 18:22:28,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 596992. Throughput: 0: 257.4. Samples: 599976. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:22:28,755][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:22:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 598016. Throughput: 0: 257.6. Samples: 600756. Policy #0 lag: (min: 0.0, avg: 2.1, max: 12.0)
[2025-09-21 18:22:33,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:22:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 600064. Throughput: 0: 257.8. Samples: 602310. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:22:38,757][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:22:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 601088. Throughput: 0: 258.5. Samples: 603864. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:22:43,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:22:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 603136. Throughput: 0: 258.8. Samples: 604650. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:22:48,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:22:48,770][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000589_603136.pth...
[2025-09-21 18:22:48,795][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000528_540672.pth
[2025-09-21 18:22:53,233][3098647] Updated weights for policy 0, policy_version 590 (0.0067)
[2025-09-21 18:22:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 604160. Throughput: 0: 258.5. Samples: 606178. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:22:53,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:22:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 605184. Throughput: 0: 257.7. Samples: 607694. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:22:58,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:23:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 606208. Throughput: 0: 257.6. Samples: 608476. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:23:03,759][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:23:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 607232. Throughput: 0: 257.6. Samples: 610014. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:23:08,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:23:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 609280. Throughput: 0: 257.9. Samples: 611582. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:23:13,753][3098297] Avg episode reward: [(0, '0.678')]
[2025-09-21 18:23:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 610304. Throughput: 0: 257.7. Samples: 612352. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:23:18,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:23:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 611328. Throughput: 0: 257.6. Samples: 613900. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:23:23,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:23:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 613376. Throughput: 0: 257.3. Samples: 615444. Policy #0 lag: (min: 0.0, avg: 3.2, max: 13.0)
[2025-09-21 18:23:28,753][3098297] Avg episode reward: [(0, '0.678')]
[2025-09-21 18:23:32,813][3098647] Updated weights for policy 0, policy_version 600 (0.0106)
[2025-09-21 18:23:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 614400. Throughput: 0: 257.5. Samples: 616236. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:23:33,753][3098297] Avg episode reward: [(0, '0.696')]
[2025-09-21 18:23:33,754][3098570] Saving new best policy, reward=0.696!
[2025-09-21 18:23:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 615424. Throughput: 0: 257.6. Samples: 617772. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:23:38,759][3098297] Avg episode reward: [(0, '0.695')]
[2025-09-21 18:23:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 616448. Throughput: 0: 258.4. Samples: 619320. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:23:43,753][3098297] Avg episode reward: [(0, '0.695')]
[2025-09-21 18:23:48,756][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 617472. Throughput: 0: 258.1. Samples: 620092. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 18:23:48,757][3098297] Avg episode reward: [(0, '0.689')]
[2025-09-21 18:23:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 619520. Throughput: 0: 258.0. Samples: 621624. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 18:23:53,753][3098297] Avg episode reward: [(0, '0.688')]
[2025-09-21 18:23:58,757][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 620544. Throughput: 0: 256.7. Samples: 623134. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:23:58,760][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:24:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 621568. Throughput: 0: 256.8. Samples: 623910. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:24:03,753][3098297] Avg episode reward: [(0, '0.679')]
[2025-09-21 18:24:08,753][3098297] Fps is (10 sec: 307.3, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 623616. Throughput: 0: 256.3. Samples: 625432. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:24:08,753][3098297] Avg episode reward: [(0, '0.677')]
[2025-09-21 18:24:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 623616. Throughput: 0: 255.7. Samples: 626950. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:24:13,756][3098297] Avg episode reward: [(0, '0.679')]
[2025-09-21 18:24:14,638][3098647] Updated weights for policy 0, policy_version 610 (0.0114)
[2025-09-21 18:24:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 625664. Throughput: 0: 255.0. Samples: 627710. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:24:18,753][3098297] Avg episode reward: [(0, '0.680')]
[2025-09-21 18:24:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 626688. Throughput: 0: 254.8. Samples: 629236. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:24:23,753][3098297] Avg episode reward: [(0, '0.675')]
[2025-09-21 18:24:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 627712. Throughput: 0: 254.4. Samples: 630768. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:24:28,753][3098297] Avg episode reward: [(0, '0.691')]
[2025-09-21 18:24:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 629760. Throughput: 0: 254.6. Samples: 631546. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 18:24:33,753][3098297] Avg episode reward: [(0, '0.690')]
[2025-09-21 18:24:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 630784. Throughput: 0: 254.5. Samples: 633078. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:24:38,753][3098297] Avg episode reward: [(0, '0.692')]
[2025-09-21 18:24:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 631808. Throughput: 0: 255.1. Samples: 634612. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:24:43,753][3098297] Avg episode reward: [(0, '0.708')]
[2025-09-21 18:24:43,754][3098570] Saving new best policy, reward=0.708!
[2025-09-21 18:24:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 632832. Throughput: 0: 254.9. Samples: 635380. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:24:48,757][3098297] Avg episode reward: [(0, '0.709')]
[2025-09-21 18:24:48,774][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000618_632832.pth...
[2025-09-21 18:24:48,798][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000558_571392.pth
[2025-09-21 18:24:52,159][3098647] Updated weights for policy 0, policy_version 620 (0.0083)
[2025-09-21 18:24:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 634880. Throughput: 0: 255.0. Samples: 636908. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:24:53,753][3098297] Avg episode reward: [(0, '0.717')]
[2025-09-21 18:24:53,754][3098570] Saving new best policy, reward=0.717!
[2025-09-21 18:24:58,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 635904. Throughput: 0: 255.0. Samples: 638426. Policy #0 lag: (min: 0.0, avg: 2.9, max: 11.0)
[2025-09-21 18:24:58,753][3098297] Avg episode reward: [(0, '0.718')]
[2025-09-21 18:24:58,761][3098570] Saving new best policy, reward=0.718!
[2025-09-21 18:25:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 636928. Throughput: 0: 255.3. Samples: 639198. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:25:03,753][3098297] Avg episode reward: [(0, '0.718')]
[2025-09-21 18:25:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 638976. Throughput: 0: 255.7. Samples: 640742. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:25:08,753][3098297] Avg episode reward: [(0, '0.718')]
[2025-09-21 18:25:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 640000. Throughput: 0: 255.4. Samples: 642260. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:25:13,756][3098297] Avg episode reward: [(0, '0.718')]
[2025-09-21 18:25:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 641024. Throughput: 0: 255.2. Samples: 643030. Policy #0 lag: (min: 0.0, avg: 1.4, max: 5.0)
[2025-09-21 18:25:18,758][3098297] Avg episode reward: [(0, '0.717')]
[2025-09-21 18:25:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 642048. Throughput: 0: 255.2. Samples: 644562. Policy #0 lag: (min: 0.0, avg: 1.4, max: 5.0)
[2025-09-21 18:25:23,753][3098297] Avg episode reward: [(0, '0.716')]
[2025-09-21 18:25:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 643072. Throughput: 0: 255.8. Samples: 646122. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:25:28,764][3098297] Avg episode reward: [(0, '0.712')]
[2025-09-21 18:25:32,493][3098647] Updated weights for policy 0, policy_version 630 (0.0083)
[2025-09-21 18:25:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 645120. Throughput: 0: 255.8. Samples: 646892. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:25:33,756][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:25:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 646144. Throughput: 0: 256.2. Samples: 648436. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:25:38,759][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:25:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 647168. Throughput: 0: 256.9. Samples: 649986. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:25:43,756][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:25:43,763][3098570] Saving new best policy, reward=0.725!
[2025-09-21 18:25:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 648192. Throughput: 0: 257.1. Samples: 650768. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:25:48,758][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:25:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 650240. Throughput: 0: 256.4. Samples: 652282. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:25:53,753][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:25:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 651264. Throughput: 0: 256.5. Samples: 653804. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:25:58,753][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:26:03,753][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 651264. Throughput: 0: 257.0. Samples: 654596. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:26:03,753][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:26:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 654336. Throughput: 0: 257.0. Samples: 656128. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:26:08,753][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:26:12,471][3098647] Updated weights for policy 0, policy_version 640 (0.0094)
[2025-09-21 18:26:13,754][3098297] Fps is (10 sec: 409.5, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 655360. Throughput: 0: 256.9. Samples: 657684. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:26:13,756][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:26:18,753][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 655360. Throughput: 0: 256.9. Samples: 658450. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:26:18,753][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:26:18,952][3098570] Saving new best policy, reward=0.726!
[2025-09-21 18:26:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 657408. Throughput: 0: 257.0. Samples: 660002. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:26:23,753][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:26:28,753][3098297] Fps is (10 sec: 409.6, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 659456. Throughput: 0: 257.3. Samples: 661566. Policy #0 lag: (min: 0.0, avg: 3.0, max: 11.0)
[2025-09-21 18:26:28,753][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:26:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 660480. Throughput: 0: 257.6. Samples: 662360. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:26:33,768][3098297] Avg episode reward: [(0, '0.710')]
[2025-09-21 18:26:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 661504. Throughput: 0: 257.8. Samples: 663882. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:26:38,757][3098297] Avg episode reward: [(0, '0.709')]
[2025-09-21 18:26:43,756][3098297] Fps is (10 sec: 307.1, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 663552. Throughput: 0: 258.4. Samples: 665434. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:26:43,758][3098297] Avg episode reward: [(0, '0.709')]
[2025-09-21 18:26:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 663552. Throughput: 0: 258.3. Samples: 666218. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:26:48,757][3098297] Avg episode reward: [(0, '0.710')]
[2025-09-21 18:26:48,818][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000648_663552.pth...
[2025-09-21 18:26:48,846][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000589_603136.pth
[2025-09-21 18:26:53,126][3098647] Updated weights for policy 0, policy_version 650 (0.0072)
[2025-09-21 18:26:53,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 665600. Throughput: 0: 258.5. Samples: 667760. Policy #0 lag: (min: 0.0, avg: 1.6, max: 9.0)
[2025-09-21 18:26:53,753][3098297] Avg episode reward: [(0, '0.711')]
[2025-09-21 18:26:58,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 666624. Throughput: 0: 257.4. Samples: 669268. Policy #0 lag: (min: 0.0, avg: 1.6, max: 9.0)
[2025-09-21 18:26:58,758][3098297] Avg episode reward: [(0, '0.711')]
[2025-09-21 18:27:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 667648. Throughput: 0: 257.6. Samples: 670042. Policy #0 lag: (min: 0.0, avg: 2.3, max: 5.0)
[2025-09-21 18:27:03,757][3098297] Avg episode reward: [(0, '0.712')]
[2025-09-21 18:27:08,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 669696. Throughput: 0: 257.5. Samples: 671592. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:27:08,757][3098297] Avg episode reward: [(0, '0.712')]
[2025-09-21 18:27:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 670720. Throughput: 0: 257.1. Samples: 673134. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:27:13,753][3098297] Avg episode reward: [(0, '0.711')]
[2025-09-21 18:27:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 671744. Throughput: 0: 256.8. Samples: 673914. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:27:18,753][3098297] Avg episode reward: [(0, '0.713')]
[2025-09-21 18:27:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 672768. Throughput: 0: 257.7. Samples: 675480. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:27:23,753][3098297] Avg episode reward: [(0, '0.713')]
[2025-09-21 18:27:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 674816. Throughput: 0: 257.8. Samples: 677034. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:27:28,759][3098297] Avg episode reward: [(0, '0.713')]
[2025-09-21 18:27:32,084][3098647] Updated weights for policy 0, policy_version 660 (0.0066)
[2025-09-21 18:27:33,758][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 675840. Throughput: 0: 257.9. Samples: 677826. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:27:33,760][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:27:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 676864. Throughput: 0: 258.3. Samples: 679382. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:27:38,761][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:27:43,754][3098297] Fps is (10 sec: 204.9, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 677888. Throughput: 0: 259.4. Samples: 680940. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:27:43,757][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:27:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 679936. Throughput: 0: 259.1. Samples: 681702. Policy #0 lag: (min: 0.0, avg: 1.9, max: 4.0)
[2025-09-21 18:27:48,753][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:27:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 680960. Throughput: 0: 259.3. Samples: 683262. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:27:53,753][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:27:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 681984. Throughput: 0: 259.3. Samples: 684802. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:27:58,757][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:28:03,755][3098297] Fps is (10 sec: 307.1, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 684032. Throughput: 0: 259.2. Samples: 685578. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:28:03,756][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:28:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 684032. Throughput: 0: 258.9. Samples: 687130. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:28:08,753][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:28:12,853][3098647] Updated weights for policy 0, policy_version 670 (0.0056)
[2025-09-21 18:28:13,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 686080. Throughput: 0: 259.2. Samples: 688698. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 18:28:13,753][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:28:18,755][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 687104. Throughput: 0: 258.9. Samples: 689474. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 18:28:18,758][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:28:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 689152. Throughput: 0: 259.0. Samples: 691036. Policy #0 lag: (min: 0.0, avg: 2.4, max: 12.0)
[2025-09-21 18:28:23,754][3098297] Avg episode reward: [(0, '0.713')]
[2025-09-21 18:28:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 690176. Throughput: 0: 258.6. Samples: 692576. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:28:28,757][3098297] Avg episode reward: [(0, '0.713')]
[2025-09-21 18:28:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 692224. Throughput: 0: 259.0. Samples: 693356. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:28:33,753][3098297] Avg episode reward: [(0, '0.713')]
[2025-09-21 18:28:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 692224. Throughput: 0: 258.6. Samples: 694900. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:28:38,757][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:28:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 694272. Throughput: 0: 258.9. Samples: 696450. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:28:43,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:28:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 695296. Throughput: 0: 259.1. Samples: 697238. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:28:48,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:28:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000679_695296.pth...
[2025-09-21 18:28:48,789][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000618_632832.pth
[2025-09-21 18:28:52,245][3098647] Updated weights for policy 0, policy_version 680 (0.0052)
[2025-09-21 18:28:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 696320. Throughput: 0: 259.1. Samples: 698788. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:28:53,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:28:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 698368. Throughput: 0: 257.8. Samples: 700298. Policy #0 lag: (min: 0.0, avg: 2.4, max: 12.0)
[2025-09-21 18:28:58,760][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:29:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 698368. Throughput: 0: 257.9. Samples: 701080. Policy #0 lag: (min: 0.0, avg: 2.4, max: 12.0)
[2025-09-21 18:29:03,759][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:29:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 700416. Throughput: 0: 257.8. Samples: 702636. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:29:08,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:29:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 701440. Throughput: 0: 258.4. Samples: 704202. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:29:13,756][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:29:18,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 702464. Throughput: 0: 258.2. Samples: 704976. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:29:18,757][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:29:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 704512. Throughput: 0: 258.2. Samples: 706518. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:29:23,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:29:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 705536. Throughput: 0: 258.6. Samples: 708088. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:29:28,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:29:30,264][3098647] Updated weights for policy 0, policy_version 690 (0.0050)
[2025-09-21 18:29:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 706560. Throughput: 0: 258.1. Samples: 708852. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:29:33,753][3098297] Avg episode reward: [(0, '0.707')]
[2025-09-21 18:29:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 707584. Throughput: 0: 258.3. Samples: 710414. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:29:38,757][3098297] Avg episode reward: [(0, '0.707')]
[2025-09-21 18:29:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 709632. Throughput: 0: 259.4. Samples: 711972. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:29:43,753][3098297] Avg episode reward: [(0, '0.707')]
[2025-09-21 18:29:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 710656. Throughput: 0: 259.8. Samples: 712772. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 18:29:48,753][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:29:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 711680. Throughput: 0: 259.5. Samples: 714312. Policy #0 lag: (min: 0.0, avg: 2.7, max: 12.0)
[2025-09-21 18:29:53,753][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:29:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 712704. Throughput: 0: 258.9. Samples: 715852. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:29:58,760][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:30:03,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 714752. Throughput: 0: 258.9. Samples: 716628. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:30:03,756][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:30:08,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 715776. Throughput: 0: 258.5. Samples: 718150. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:30:08,758][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:30:09,575][3098647] Updated weights for policy 0, policy_version 700 (0.0103)
[2025-09-21 18:30:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 716800. Throughput: 0: 258.4. Samples: 719718. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:30:13,753][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:30:18,755][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 718848. Throughput: 0: 258.3. Samples: 720476. Policy #0 lag: (min: 0.0, avg: 1.8, max: 11.0)
[2025-09-21 18:30:18,764][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:30:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 719872. Throughput: 0: 257.6. Samples: 722006. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:30:23,753][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:30:28,753][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 719872. Throughput: 0: 257.1. Samples: 723542. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:30:28,753][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:30:28,920][3098570] Signal inference workers to stop experience collection...
[2025-09-21 18:30:28,975][3098647] InferenceWorker_p0-w0: stopping experience collection
[2025-09-21 18:30:29,689][3098570] Signal inference workers to resume experience collection...
[2025-09-21 18:30:29,690][3098647] InferenceWorker_p0-w0: resuming experience collection
[2025-09-21 18:30:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 721920. Throughput: 0: 254.0. Samples: 724202. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:30:33,753][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:30:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 722944. Throughput: 0: 253.9. Samples: 725736. Policy #0 lag: (min: 0.0, avg: 3.1, max: 11.0)
[2025-09-21 18:30:38,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:30:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 724992. Throughput: 0: 253.7. Samples: 727270. Policy #0 lag: (min: 0.0, avg: 2.4, max: 5.0)
[2025-09-21 18:30:43,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:30:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 726016. Throughput: 0: 254.0. Samples: 728056. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:30:48,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:30:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000709_726016.pth...
[2025-09-21 18:30:48,790][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000648_663552.pth
[2025-09-21 18:30:50,663][3098647] Updated weights for policy 0, policy_version 710 (0.0062)
[2025-09-21 18:30:53,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 727040. Throughput: 0: 254.4. Samples: 729598. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:30:53,757][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:30:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 728064. Throughput: 0: 253.3. Samples: 731116. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:30:58,758][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:31:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 729088. Throughput: 0: 253.9. Samples: 731900. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:31:03,760][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:31:08,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 731136. Throughput: 0: 253.7. Samples: 733424. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:31:08,753][3098297] Avg episode reward: [(0, '0.708')]
[2025-09-21 18:31:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 732160. Throughput: 0: 254.3. Samples: 734984. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 18:31:13,753][3098297] Avg episode reward: [(0, '0.708')]
[2025-09-21 18:31:18,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 734208. Throughput: 0: 256.5. Samples: 735744. Policy #0 lag: (min: 0.0, avg: 3.2, max: 13.0)
[2025-09-21 18:31:18,757][3098297] Avg episode reward: [(0, '0.712')]
[2025-09-21 18:31:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 735232. Throughput: 0: 256.9. Samples: 737298. Policy #0 lag: (min: 0.0, avg: 3.2, max: 13.0)
[2025-09-21 18:31:23,753][3098297] Avg episode reward: [(0, '0.711')]
[2025-09-21 18:31:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 736256. Throughput: 0: 257.2. Samples: 738844. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:31:28,753][3098297] Avg episode reward: [(0, '0.715')]
[2025-09-21 18:31:30,873][3098647] Updated weights for policy 0, policy_version 720 (0.0075)
[2025-09-21 18:31:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 737280. Throughput: 0: 257.0. Samples: 739622. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:31:33,756][3098297] Avg episode reward: [(0, '0.715')]
[2025-09-21 18:31:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 738304. Throughput: 0: 256.9. Samples: 741160. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:31:38,759][3098297] Avg episode reward: [(0, '0.715')]
[2025-09-21 18:31:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 740352. Throughput: 0: 257.1. Samples: 742684. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:31:43,753][3098297] Avg episode reward: [(0, '0.715')]
[2025-09-21 18:31:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 741376. Throughput: 0: 257.0. Samples: 743464. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:31:48,753][3098297] Avg episode reward: [(0, '0.716')]
[2025-09-21 18:31:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 742400. Throughput: 0: 256.8. Samples: 744980. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:31:53,753][3098297] Avg episode reward: [(0, '0.716')]
[2025-09-21 18:31:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 743424. Throughput: 0: 255.4. Samples: 746476. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:31:58,753][3098297] Avg episode reward: [(0, '0.720')]
[2025-09-21 18:32:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 745472. Throughput: 0: 255.5. Samples: 747242. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:32:03,753][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:32:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 745472. Throughput: 0: 254.8. Samples: 748762. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:32:08,753][3098297] Avg episode reward: [(0, '0.688')]
[2025-09-21 18:32:12,089][3098647] Updated weights for policy 0, policy_version 730 (0.0100)
[2025-09-21 18:32:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 747520. Throughput: 0: 253.8. Samples: 750266. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:32:13,756][3098297] Avg episode reward: [(0, '0.690')]
[2025-09-21 18:32:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 748544. Throughput: 0: 253.7. Samples: 751040. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:32:18,753][3098297] Avg episode reward: [(0, '0.690')]
[2025-09-21 18:32:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 750592. Throughput: 0: 250.5. Samples: 752432. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:32:23,753][3098297] Avg episode reward: [(0, '0.708')]
[2025-09-21 18:32:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 751616. Throughput: 0: 249.5. Samples: 753910. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:32:28,753][3098297] Avg episode reward: [(0, '0.715')]
[2025-09-21 18:32:33,759][3098297] Fps is (10 sec: 204.7, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 752640. Throughput: 0: 249.3. Samples: 754686. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:32:33,759][3098297] Avg episode reward: [(0, '0.714')]
[2025-09-21 18:32:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 753664. Throughput: 0: 249.5. Samples: 756208. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:32:38,753][3098297] Avg episode reward: [(0, '0.687')]
[2025-09-21 18:32:43,753][3098297] Fps is (10 sec: 204.9, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 754688. Throughput: 0: 250.7. Samples: 757756. Policy #0 lag: (min: 0.0, avg: 1.8, max: 6.0)
[2025-09-21 18:32:43,753][3098297] Avg episode reward: [(0, '0.689')]
[2025-09-21 18:32:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 756736. Throughput: 0: 250.9. Samples: 758532. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:32:48,753][3098297] Avg episode reward: [(0, '0.690')]
[2025-09-21 18:32:48,764][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000739_756736.pth...
[2025-09-21 18:32:48,795][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000679_695296.pth
[2025-09-21 18:32:52,321][3098647] Updated weights for policy 0, policy_version 740 (0.0055)
[2025-09-21 18:32:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 757760. Throughput: 0: 250.6. Samples: 760040. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:32:53,753][3098297] Avg episode reward: [(0, '0.690')]
[2025-09-21 18:32:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 758784. Throughput: 0: 250.4. Samples: 761534. Policy #0 lag: (min: 0.0, avg: 2.1, max: 8.0)
[2025-09-21 18:32:58,758][3098297] Avg episode reward: [(0, '0.689')]
[2025-09-21 18:33:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 759808. Throughput: 0: 250.6. Samples: 762316. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:33:03,753][3098297] Avg episode reward: [(0, '0.690')]
[2025-09-21 18:33:08,753][3098297] Fps is (10 sec: 307.3, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 761856. Throughput: 0: 253.4. Samples: 763836. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:33:08,753][3098297] Avg episode reward: [(0, '0.707')]
[2025-09-21 18:33:13,756][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 762880. Throughput: 0: 255.1. Samples: 765390. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:33:13,757][3098297] Avg episode reward: [(0, '0.708')]
[2025-09-21 18:33:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 763904. Throughput: 0: 254.7. Samples: 766148. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:33:18,753][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:33:23,754][3098297] Fps is (10 sec: 204.9, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 764928. Throughput: 0: 255.2. Samples: 767692. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:33:23,758][3098297] Avg episode reward: [(0, '0.703')]
[2025-09-21 18:33:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 766976. Throughput: 0: 255.2. Samples: 769242. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:33:28,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:33:31,473][3098647] Updated weights for policy 0, policy_version 750 (0.0068)
[2025-09-21 18:33:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 768000. Throughput: 0: 255.3. Samples: 770020. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:33:33,756][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:33:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 769024. Throughput: 0: 256.3. Samples: 771572. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:33:38,757][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:33:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 771072. Throughput: 0: 257.6. Samples: 773126. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:33:43,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:33:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 772096. Throughput: 0: 257.6. Samples: 773910. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:33:48,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:33:53,755][3098297] Fps is (10 sec: 204.7, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 773120. Throughput: 0: 258.3. Samples: 775462. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:33:53,756][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:33:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 774144. Throughput: 0: 257.1. Samples: 776960. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:33:58,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 775168. Throughput: 0: 257.5. Samples: 777738. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:34:03,755][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 777216. Throughput: 0: 257.1. Samples: 779262. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:34:08,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:11,689][3098647] Updated weights for policy 0, policy_version 760 (0.0078)
[2025-09-21 18:34:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 778240. Throughput: 0: 257.1. Samples: 780810. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:34:13,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 779264. Throughput: 0: 257.5. Samples: 781606. Policy #0 lag: (min: 0.0, avg: 2.3, max: 12.0)
[2025-09-21 18:34:18,757][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 781312. Throughput: 0: 257.0. Samples: 783136. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:34:23,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 782336. Throughput: 0: 256.5. Samples: 784670. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:34:28,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 783360. Throughput: 0: 256.7. Samples: 785462. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:34:33,760][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:34:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 785408. Throughput: 0: 256.9. Samples: 787022. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:34:38,753][3098297] Avg episode reward: [(0, '0.706')]
[2025-09-21 18:34:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 786432. Throughput: 0: 258.0. Samples: 788572. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:34:43,753][3098297] Avg episode reward: [(0, '0.700')]
[2025-09-21 18:34:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 787456. Throughput: 0: 258.1. Samples: 789350. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:34:48,753][3098297] Avg episode reward: [(0, '0.700')]
[2025-09-21 18:34:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000769_787456.pth...
[2025-09-21 18:34:48,790][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000709_726016.pth
[2025-09-21 18:34:51,335][3098647] Updated weights for policy 0, policy_version 770 (0.0084)
[2025-09-21 18:34:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 788480. Throughput: 0: 258.4. Samples: 790888. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:34:53,753][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:34:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 789504. Throughput: 0: 257.6. Samples: 792402. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:34:58,754][3098297] Avg episode reward: [(0, '0.702')]
[2025-09-21 18:35:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 791552. Throughput: 0: 257.1. Samples: 793174. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:35:03,753][3098297] Avg episode reward: [(0, '0.700')]
[2025-09-21 18:35:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 792576. Throughput: 0: 257.6. Samples: 794726. Policy #0 lag: (min: 0.0, avg: 2.9, max: 11.0)
[2025-09-21 18:35:08,753][3098297] Avg episode reward: [(0, '0.700')]
[2025-09-21 18:35:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 793600. Throughput: 0: 258.0. Samples: 796278. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:35:13,753][3098297] Avg episode reward: [(0, '0.701')]
[2025-09-21 18:35:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 794624. Throughput: 0: 257.7. Samples: 797058. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:35:18,758][3098297] Avg episode reward: [(0, '0.701')]
[2025-09-21 18:35:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 796672. Throughput: 0: 257.1. Samples: 798590. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:35:23,753][3098297] Avg episode reward: [(0, '0.701')]
[2025-09-21 18:35:28,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 797696. Throughput: 0: 257.3. Samples: 800152. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:35:28,753][3098297] Avg episode reward: [(0, '0.718')]
[2025-09-21 18:35:32,129][3098647] Updated weights for policy 0, policy_version 780 (0.0050)
[2025-09-21 18:35:33,752][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 798720. Throughput: 0: 257.6. Samples: 800944. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:35:33,753][3098297] Avg episode reward: [(0, '0.718')]
[2025-09-21 18:35:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 800768. Throughput: 0: 256.6. Samples: 802436. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:35:38,753][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:35:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 801792. Throughput: 0: 255.7. Samples: 803908. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:35:43,753][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:35:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 802816. Throughput: 0: 254.7. Samples: 804636. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:35:48,754][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:35:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 803840. Throughput: 0: 252.7. Samples: 806096. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:35:53,754][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:35:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 804864. Throughput: 0: 249.6. Samples: 807508. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:35:58,753][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:36:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 805888. Throughput: 0: 248.7. Samples: 808248. Policy #0 lag: (min: 0.0, avg: 1.1, max: 5.0)
[2025-09-21 18:36:03,753][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:36:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 806912. Throughput: 0: 246.5. Samples: 809684. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:36:08,753][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:36:11,307][3098647] Updated weights for policy 0, policy_version 790 (0.0037)
[2025-09-21 18:36:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 808960. Throughput: 0: 245.8. Samples: 811212. Policy #0 lag: (min: 0.0, avg: 2.5, max: 12.0)
[2025-09-21 18:36:13,753][3098297] Avg episode reward: [(0, '0.721')]
[2025-09-21 18:36:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 809984. Throughput: 0: 245.5. Samples: 811990. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:36:18,753][3098297] Avg episode reward: [(0, '0.722')]
[2025-09-21 18:36:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 811008. Throughput: 0: 246.7. Samples: 813536. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:36:23,753][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:36:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 812032. Throughput: 0: 248.4. Samples: 815086. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:36:28,753][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:36:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 814080. Throughput: 0: 249.3. Samples: 815856. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:36:33,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:36:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 815104. Throughput: 0: 250.8. Samples: 817384. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:36:38,757][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:36:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 816128. Throughput: 0: 253.9. Samples: 818934. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:36:43,753][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:36:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 818176. Throughput: 0: 254.7. Samples: 819710. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:36:48,753][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:36:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000799_818176.pth...
[2025-09-21 18:36:48,791][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000739_756736.pth
[2025-09-21 18:36:53,111][3098647] Updated weights for policy 0, policy_version 800 (0.0077)
[2025-09-21 18:36:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 819200. Throughput: 0: 256.8. Samples: 821238. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:36:53,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:36:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 820224. Throughput: 0: 256.2. Samples: 822740. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:36:58,753][3098297] Avg episode reward: [(0, '0.724')]
[2025-09-21 18:37:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 821248. Throughput: 0: 256.3. Samples: 823524. Policy #0 lag: (min: 0.0, avg: 1.9, max: 8.0)
[2025-09-21 18:37:03,756][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:37:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 822272. Throughput: 0: 256.0. Samples: 825056. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:37:08,753][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:37:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 824320. Throughput: 0: 256.2. Samples: 826616. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:37:13,756][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:37:18,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 825344. Throughput: 0: 257.0. Samples: 827420. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:37:18,757][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:37:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 826368. Throughput: 0: 257.0. Samples: 828950. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:37:23,759][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:37:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 828416. Throughput: 0: 257.0. Samples: 830498. Policy #0 lag: (min: 0.0, avg: 1.9, max: 6.0)
[2025-09-21 18:37:28,760][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:37:32,488][3098647] Updated weights for policy 0, policy_version 810 (0.0111)
[2025-09-21 18:37:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 829440. Throughput: 0: 257.2. Samples: 831286. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:37:33,757][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:37:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 830464. Throughput: 0: 257.5. Samples: 832824. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:37:38,753][3098297] Avg episode reward: [(0, '0.725')]
[2025-09-21 18:37:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 831488. Throughput: 0: 259.0. Samples: 834394. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:37:43,753][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:37:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 833536. Throughput: 0: 258.6. Samples: 835162. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:37:48,753][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:37:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 834560. Throughput: 0: 258.9. Samples: 836708. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:37:53,753][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:37:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 835584. Throughput: 0: 257.8. Samples: 838218. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 18:37:58,753][3098297] Avg episode reward: [(0, '0.727')]
[2025-09-21 18:38:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 837632. Throughput: 0: 257.3. Samples: 838996. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 18:38:03,753][3098297] Avg episode reward: [(0, '0.726')]
[2025-09-21 18:38:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 837632. Throughput: 0: 257.2. Samples: 840522. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 18:38:08,753][3098297] Avg episode reward: [(0, '0.729')]
[2025-09-21 18:38:08,765][3098570] Saving new best policy, reward=0.729!
[2025-09-21 18:38:11,624][3098647] Updated weights for policy 0, policy_version 820 (0.0107)
[2025-09-21 18:38:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 839680. Throughput: 0: 257.1. Samples: 842068. Policy #0 lag: (min: 0.0, avg: 1.5, max: 6.0)
[2025-09-21 18:38:13,756][3098297] Avg episode reward: [(0, '0.730')]
[2025-09-21 18:38:13,759][3098570] Saving new best policy, reward=0.730!
[2025-09-21 18:38:18,756][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 840704. Throughput: 0: 256.8. Samples: 842844. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:38:18,758][3098297] Avg episode reward: [(0, '0.730')]
[2025-09-21 18:38:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 841728. Throughput: 0: 256.9. Samples: 844384. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:38:23,757][3098297] Avg episode reward: [(0, '0.722')]
[2025-09-21 18:38:28,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 843776. Throughput: 0: 256.5. Samples: 845938. Policy #0 lag: (min: 0.0, avg: 1.1, max: 4.0)
[2025-09-21 18:38:28,761][3098297] Avg episode reward: [(0, '0.706')]
[2025-09-21 18:38:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 844800. Throughput: 0: 256.5. Samples: 846706. Policy #0 lag: (min: 0.0, avg: 2.8, max: 10.0)
[2025-09-21 18:38:33,756][3098297] Avg episode reward: [(0, '0.706')]
[2025-09-21 18:38:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 845824. Throughput: 0: 257.1. Samples: 848276. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:38:38,758][3098297] Avg episode reward: [(0, '0.706')]
[2025-09-21 18:38:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 846848. Throughput: 0: 258.3. Samples: 849842. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:38:43,753][3098297] Avg episode reward: [(0, '0.706')]
[2025-09-21 18:38:48,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 848896. Throughput: 0: 258.4. Samples: 850622. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:38:48,753][3098297] Avg episode reward: [(0, '0.706')]
[2025-09-21 18:38:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000829_848896.pth...
[2025-09-21 18:38:48,793][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000769_787456.pth
[2025-09-21 18:38:50,485][3098647] Updated weights for policy 0, policy_version 830 (0.0066)
[2025-09-21 18:38:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 849920. Throughput: 0: 258.8. Samples: 852168. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:38:53,753][3098297] Avg episode reward: [(0, '0.706')]
[2025-09-21 18:38:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 850944. Throughput: 0: 258.4. Samples: 853696. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:38:58,754][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:39:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 852992. Throughput: 0: 258.3. Samples: 854466. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:39:03,753][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:39:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 854016. Throughput: 0: 258.7. Samples: 856026. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:39:08,753][3098297] Avg episode reward: [(0, '0.704')]
[2025-09-21 18:39:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 855040. Throughput: 0: 258.9. Samples: 857588. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:39:13,753][3098297] Avg episode reward: [(0, '0.722')]
[2025-09-21 18:39:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 857088. Throughput: 0: 258.9. Samples: 858354. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:39:18,753][3098297] Avg episode reward: [(0, '0.722')]
[2025-09-21 18:39:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 858112. Throughput: 0: 258.8. Samples: 859924. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:39:23,757][3098297] Avg episode reward: [(0, '0.722')]
[2025-09-21 18:39:28,755][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 858112. Throughput: 0: 259.0. Samples: 861496. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:39:28,757][3098297] Avg episode reward: [(0, '0.723')]
[2025-09-21 18:39:31,587][3098647] Updated weights for policy 0, policy_version 840 (0.0075)
[2025-09-21 18:39:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 860160. Throughput: 0: 258.9. Samples: 862272. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:39:33,753][3098297] Avg episode reward: [(0, '0.738')]
[2025-09-21 18:39:33,889][3098570] Saving new best policy, reward=0.738!
[2025-09-21 18:39:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 861184. Throughput: 0: 258.6. Samples: 863804. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:39:38,753][3098297] Avg episode reward: [(0, '0.737')]
[2025-09-21 18:39:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 862208. Throughput: 0: 259.2. Samples: 865362. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:39:43,753][3098297] Avg episode reward: [(0, '0.735')]
[2025-09-21 18:39:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 864256. Throughput: 0: 259.5. Samples: 866142. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:39:48,753][3098297] Avg episode reward: [(0, '0.735')]
[2025-09-21 18:39:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 865280. Throughput: 0: 259.3. Samples: 867694. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:39:53,753][3098297] Avg episode reward: [(0, '0.735')]
[2025-09-21 18:39:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 866304. Throughput: 0: 258.7. Samples: 869230. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:39:58,753][3098297] Avg episode reward: [(0, '0.735')]
[2025-09-21 18:40:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 868352. Throughput: 0: 258.6. Samples: 869990. Policy #0 lag: (min: 0.0, avg: 2.0, max: 12.0)
[2025-09-21 18:40:03,753][3098297] Avg episode reward: [(0, '0.734')]
[2025-09-21 18:40:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 869376. Throughput: 0: 258.2. Samples: 871544. Policy #0 lag: (min: 0.0, avg: 2.0, max: 12.0)
[2025-09-21 18:40:08,753][3098297] Avg episode reward: [(0, '0.734')]
[2025-09-21 18:40:11,712][3098647] Updated weights for policy 0, policy_version 850 (0.0077)
[2025-09-21 18:40:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 870400. Throughput: 0: 257.5. Samples: 873082. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:40:13,753][3098297] Avg episode reward: [(0, '0.734')]
[2025-09-21 18:40:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 871424. Throughput: 0: 257.3. Samples: 873852. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:40:18,758][3098297] Avg episode reward: [(0, '0.735')]
[2025-09-21 18:40:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 873472. Throughput: 0: 257.9. Samples: 875408. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:40:23,757][3098297] Avg episode reward: [(0, '0.735')]
[2025-09-21 18:40:28,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 874496. Throughput: 0: 257.5. Samples: 876950. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:40:28,760][3098297] Avg episode reward: [(0, '0.736')]
[2025-09-21 18:40:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 875520. Throughput: 0: 257.3. Samples: 877720. Policy #0 lag: (min: 0.0, avg: 2.4, max: 12.0)
[2025-09-21 18:40:33,757][3098297] Avg episode reward: [(0, '0.738')]
[2025-09-21 18:40:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 877568. Throughput: 0: 256.6. Samples: 879242. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:40:38,757][3098297] Avg episode reward: [(0, '0.756')]
[2025-09-21 18:40:38,793][3098570] Saving new best policy, reward=0.756!
[2025-09-21 18:40:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 878592. Throughput: 0: 257.3. Samples: 880808. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:40:43,753][3098297] Avg episode reward: [(0, '0.768')]
[2025-09-21 18:40:43,754][3098570] Saving new best policy, reward=0.768!
[2025-09-21 18:40:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 879616. Throughput: 0: 256.9. Samples: 881550. Policy #0 lag: (min: 0.0, avg: 2.0, max: 12.0)
[2025-09-21 18:40:48,753][3098297] Avg episode reward: [(0, '0.770')]
[2025-09-21 18:40:48,763][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000859_879616.pth...
[2025-09-21 18:40:48,792][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000799_818176.pth
[2025-09-21 18:40:48,796][3098570] Saving new best policy, reward=0.770!
[2025-09-21 18:40:51,298][3098647] Updated weights for policy 0, policy_version 860 (0.0104)
[2025-09-21 18:40:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 880640. Throughput: 0: 256.0. Samples: 883064. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:40:53,753][3098297] Avg episode reward: [(0, '0.770')]
[2025-09-21 18:40:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 881664. Throughput: 0: 255.2. Samples: 884568. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:40:58,757][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 18:40:58,785][3098570] Saving new best policy, reward=0.771!
[2025-09-21 18:41:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 882688. Throughput: 0: 255.3. Samples: 885338. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:41:03,753][3098297] Avg episode reward: [(0, '0.772')]
[2025-09-21 18:41:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 884736. Throughput: 0: 254.1. Samples: 886842. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 18:41:08,753][3098297] Avg episode reward: [(0, '0.772')]
[2025-09-21 18:41:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 885760. Throughput: 0: 254.4. Samples: 888396. Policy #0 lag: (min: 0.0, avg: 3.4, max: 11.0)
[2025-09-21 18:41:13,756][3098297] Avg episode reward: [(0, '0.779')]
[2025-09-21 18:41:13,759][3098570] Saving new best policy, reward=0.779!
[2025-09-21 18:41:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 886784. Throughput: 0: 254.4. Samples: 889168. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:41:18,757][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:41:18,790][3098570] Saving new best policy, reward=0.783!
[2025-09-21 18:41:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 888832. Throughput: 0: 255.0. Samples: 890716. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:41:23,753][3098297] Avg episode reward: [(0, '0.789')]
[2025-09-21 18:41:23,754][3098570] Saving new best policy, reward=0.789!
[2025-09-21 18:41:28,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 889856. Throughput: 0: 254.6. Samples: 892266. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:41:28,753][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:41:28,762][3098570] Saving new best policy, reward=0.792!
[2025-09-21 18:41:31,984][3098647] Updated weights for policy 0, policy_version 870 (0.0059)
[2025-09-21 18:41:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 890880. Throughput: 0: 255.6. Samples: 893050. Policy #0 lag: (min: 0.0, avg: 1.3, max: 4.0)
[2025-09-21 18:41:33,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:41:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 891904. Throughput: 0: 256.0. Samples: 894582. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:41:38,753][3098297] Avg episode reward: [(0, '0.788')]
[2025-09-21 18:41:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 893952. Throughput: 0: 256.0. Samples: 896088. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:41:43,753][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:41:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 894976. Throughput: 0: 256.6. Samples: 896884. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:41:48,753][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:41:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 896000. Throughput: 0: 256.9. Samples: 898402. Policy #0 lag: (min: 0.0, avg: 3.0, max: 10.0)
[2025-09-21 18:41:53,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:41:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 898048. Throughput: 0: 256.0. Samples: 899916. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:41:58,757][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:42:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 898048. Throughput: 0: 256.2. Samples: 900696. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:42:03,756][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:42:08,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 900096. Throughput: 0: 256.1. Samples: 902240. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:42:08,756][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:42:11,130][3098647] Updated weights for policy 0, policy_version 880 (0.0054)
[2025-09-21 18:42:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 901120. Throughput: 0: 256.0. Samples: 903786. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:42:13,757][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:42:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 902144. Throughput: 0: 255.6. Samples: 904550. Policy #0 lag: (min: 0.0, avg: 3.1, max: 12.0)
[2025-09-21 18:42:18,754][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:42:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 903168. Throughput: 0: 256.0. Samples: 906104. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:42:23,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:42:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 905216. Throughput: 0: 257.1. Samples: 907658. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:42:28,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:42:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 906240. Throughput: 0: 256.8. Samples: 908440. Policy #0 lag: (min: 0.0, avg: 2.8, max: 10.0)
[2025-09-21 18:42:33,756][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 18:42:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 907264. Throughput: 0: 257.4. Samples: 909986. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:42:38,757][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:42:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 909312. Throughput: 0: 258.1. Samples: 911530. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:42:43,753][3098297] Avg episode reward: [(0, '0.784')]
[2025-09-21 18:42:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 910336. Throughput: 0: 258.1. Samples: 912308. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:42:48,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:42:48,760][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000889_910336.pth...
[2025-09-21 18:42:48,787][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000829_848896.pth
[2025-09-21 18:42:53,559][3098647] Updated weights for policy 0, policy_version 890 (0.0093)
[2025-09-21 18:42:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 911360. Throughput: 0: 258.0. Samples: 913850. Policy #0 lag: (min: 0.0, avg: 1.7, max: 9.0)
[2025-09-21 18:42:53,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:42:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 913408. Throughput: 0: 257.0. Samples: 915350. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:42:58,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:43:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 914432. Throughput: 0: 257.2. Samples: 916122. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:43:03,754][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:43:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 915456. Throughput: 0: 257.3. Samples: 917684. Policy #0 lag: (min: 0.0, avg: 1.9, max: 9.0)
[2025-09-21 18:43:08,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:43:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 917504. Throughput: 0: 257.1. Samples: 919230. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:43:13,757][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:43:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 917504. Throughput: 0: 257.1. Samples: 920008. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:43:18,753][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:43:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 919552. Throughput: 0: 257.4. Samples: 921568. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 18:43:23,753][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:43:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 920576. Throughput: 0: 257.7. Samples: 923126. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:43:28,754][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:43:30,663][3098647] Updated weights for policy 0, policy_version 900 (0.0058)
[2025-09-21 18:43:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 921600. Throughput: 0: 257.2. Samples: 923882. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:43:33,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:43:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 922624. Throughput: 0: 257.9. Samples: 925454. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:43:38,757][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:43:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 924672. Throughput: 0: 258.7. Samples: 926992. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:43:43,753][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:43:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 925696. Throughput: 0: 258.6. Samples: 927760. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:43:48,753][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:43:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 926720. Throughput: 0: 258.8. Samples: 929328. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:43:53,753][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:43:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 928768. Throughput: 0: 257.9. Samples: 930836. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 18:43:58,753][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:44:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 929792. Throughput: 0: 258.0. Samples: 931620. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:44:03,753][3098297] Avg episode reward: [(0, '0.780')]
[2025-09-21 18:44:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 930816. Throughput: 0: 257.6. Samples: 933162. Policy #0 lag: (min: 0.0, avg: 1.7, max: 10.0)
[2025-09-21 18:44:08,753][3098297] Avg episode reward: [(0, '0.780')]
[2025-09-21 18:44:09,367][3098647] Updated weights for policy 0, policy_version 910 (0.0091)
[2025-09-21 18:44:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 931840. Throughput: 0: 257.5. Samples: 934714. Policy #0 lag: (min: 0.0, avg: 1.7, max: 10.0)
[2025-09-21 18:44:13,753][3098297] Avg episode reward: [(0, '0.780')]
[2025-09-21 18:44:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 932864. Throughput: 0: 257.9. Samples: 935486. Policy #0 lag: (min: 0.0, avg: 2.1, max: 6.0)
[2025-09-21 18:44:18,757][3098297] Avg episode reward: [(0, '0.780')]
[2025-09-21 18:44:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 934912. Throughput: 0: 257.5. Samples: 937042. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:44:23,753][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:44:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 935936. Throughput: 0: 257.9. Samples: 938596. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:44:28,753][3098297] Avg episode reward: [(0, '0.793')]
[2025-09-21 18:44:28,762][3098570] Saving new best policy, reward=0.793!
[2025-09-21 18:44:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 936960. Throughput: 0: 257.9. Samples: 939364. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 18:44:33,753][3098297] Avg episode reward: [(0, '0.809')]
[2025-09-21 18:44:33,912][3098570] Saving new best policy, reward=0.809!
[2025-09-21 18:44:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 939008. Throughput: 0: 257.6. Samples: 940920. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:44:38,753][3098297] Avg episode reward: [(0, '0.810')]
[2025-09-21 18:44:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 940032. Throughput: 0: 258.4. Samples: 942466. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:44:43,753][3098297] Avg episode reward: [(0, '0.811')]
[2025-09-21 18:44:43,754][3098570] Saving new best policy, reward=0.811!
[2025-09-21 18:44:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 941056. Throughput: 0: 258.4. Samples: 943250. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:44:48,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:44:48,768][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000919_941056.pth...
[2025-09-21 18:44:48,893][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000859_879616.pth
[2025-09-21 18:44:50,764][3098647] Updated weights for policy 0, policy_version 920 (0.0102)
[2025-09-21 18:44:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 943104. Throughput: 0: 258.2. Samples: 944782. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:44:53,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:44:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 943104. Throughput: 0: 257.5. Samples: 946302. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:44:58,757][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:45:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 945152. Throughput: 0: 257.6. Samples: 947078. Policy #0 lag: (min: 0.0, avg: 2.8, max: 10.0)
[2025-09-21 18:45:03,756][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:45:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 946176. Throughput: 0: 257.5. Samples: 948628. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:45:08,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:45:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 947200. Throughput: 0: 257.6. Samples: 950190. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:45:13,757][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:45:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 949248. Throughput: 0: 257.6. Samples: 950956. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 18:45:18,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:45:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 950272. Throughput: 0: 257.2. Samples: 952494. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 18:45:23,754][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:45:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 951296. Throughput: 0: 255.5. Samples: 953964. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:45:28,753][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:45:29,319][3098647] Updated weights for policy 0, policy_version 930 (0.0066)
[2025-09-21 18:45:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 952320. Throughput: 0: 253.7. Samples: 954668. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:45:33,756][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:45:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 953344. Throughput: 0: 253.4. Samples: 956186. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:45:38,753][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:45:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 955392. Throughput: 0: 252.3. Samples: 957656. Policy #0 lag: (min: 0.0, avg: 1.7, max: 11.0)
[2025-09-21 18:45:43,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:45:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 956416. Throughput: 0: 252.0. Samples: 958416. Policy #0 lag: (min: 0.0, avg: 1.7, max: 11.0)
[2025-09-21 18:45:48,754][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:45:53,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 957440. Throughput: 0: 249.5. Samples: 959854. Policy #0 lag: (min: 0.0, avg: 2.0, max: 6.0)
[2025-09-21 18:45:53,756][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:45:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 958464. Throughput: 0: 246.7. Samples: 961290. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:45:58,757][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:46:03,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 960512. Throughput: 0: 246.5. Samples: 962048. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:46:03,768][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:46:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 961536. Throughput: 0: 244.5. Samples: 963496. Policy #0 lag: (min: 0.0, avg: 1.9, max: 6.0)
[2025-09-21 18:46:08,753][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:46:12,712][3098647] Updated weights for policy 0, policy_version 940 (0.0036)
[2025-09-21 18:46:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 962560. Throughput: 0: 243.9. Samples: 964938. Policy #0 lag: (min: 0.0, avg: 1.8, max: 13.0)
[2025-09-21 18:46:13,753][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:46:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 963584. Throughput: 0: 245.5. Samples: 965716. Policy #0 lag: (min: 0.0, avg: 2.5, max: 13.0)
[2025-09-21 18:46:18,758][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:46:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 964608. Throughput: 0: 244.4. Samples: 967186. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:46:23,756][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:46:28,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 966656. Throughput: 0: 244.8. Samples: 968670. Policy #0 lag: (min: 0.0, avg: 2.7, max: 12.0)
[2025-09-21 18:46:28,754][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:46:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 967680. Throughput: 0: 244.9. Samples: 969436. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:46:33,755][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:46:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 968704. Throughput: 0: 245.0. Samples: 970880. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:46:38,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:46:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 969728. Throughput: 0: 245.9. Samples: 972356. Policy #0 lag: (min: 0.0, avg: 2.6, max: 12.0)
[2025-09-21 18:46:43,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:46:48,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 970752. Throughput: 0: 246.0. Samples: 973120. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:46:48,757][3098297] Avg episode reward: [(0, '0.799')]
[2025-09-21 18:46:48,773][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000948_970752.pth...
[2025-09-21 18:46:48,797][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000889_910336.pth
[2025-09-21 18:46:53,076][3098647] Updated weights for policy 0, policy_version 950 (0.0047)
[2025-09-21 18:46:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 972800. Throughput: 0: 245.8. Samples: 974556. Policy #0 lag: (min: 0.0, avg: 1.6, max: 6.0)
[2025-09-21 18:46:53,753][3098297] Avg episode reward: [(0, '0.799')]
[2025-09-21 18:46:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 972800. Throughput: 0: 243.4. Samples: 975890. Policy #0 lag: (min: 0.0, avg: 1.6, max: 6.0)
[2025-09-21 18:46:58,757][3098297] Avg episode reward: [(0, '0.799')]
[2025-09-21 18:47:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 974848. Throughput: 0: 242.6. Samples: 976634. Policy #0 lag: (min: 0.0, avg: 2.8, max: 12.0)
[2025-09-21 18:47:03,753][3098297] Avg episode reward: [(0, '0.799')]
[2025-09-21 18:47:08,753][3098297] Fps is (10 sec: 307.3, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 975872. Throughput: 0: 241.9. Samples: 978070. Policy #0 lag: (min: 0.0, avg: 2.8, max: 12.0)
[2025-09-21 18:47:08,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:47:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 976896. Throughput: 0: 239.1. Samples: 979430. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:47:13,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:47:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 977920. Throughput: 0: 239.2. Samples: 980200. Policy #0 lag: (min: 0.0, avg: 1.7, max: 10.0)
[2025-09-21 18:47:18,753][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:47:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 979968. Throughput: 0: 241.2. Samples: 981736. Policy #0 lag: (min: 0.0, avg: 2.8, max: 12.0)
[2025-09-21 18:47:23,753][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:47:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 980992. Throughput: 0: 242.7. Samples: 983278. Policy #0 lag: (min: 0.0, avg: 2.9, max: 12.0)
[2025-09-21 18:47:28,753][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:47:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 982016. Throughput: 0: 243.0. Samples: 984056. Policy #0 lag: (min: 0.0, avg: 1.9, max: 7.0)
[2025-09-21 18:47:33,753][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:47:35,926][3098647] Updated weights for policy 0, policy_version 960 (0.0071)
[2025-09-21 18:47:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 983040. Throughput: 0: 245.1. Samples: 985588. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:47:38,757][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:47:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 985088. Throughput: 0: 250.0. Samples: 987140. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:47:43,761][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:47:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 986112. Throughput: 0: 250.8. Samples: 987920. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:47:48,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:47:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 987136. Throughput: 0: 253.0. Samples: 989454. Policy #0 lag: (min: 0.0, avg: 2.3, max: 13.0)
[2025-09-21 18:47:53,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:47:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 988160. Throughput: 0: 256.3. Samples: 990962. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:47:58,758][3098297] Avg episode reward: [(0, '0.789')]
[2025-09-21 18:48:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 989184. Throughput: 0: 256.8. Samples: 991758. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:48:03,757][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:48:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 246.5). Total num frames: 990208. Throughput: 0: 256.6. Samples: 993284. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:48:08,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:48:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 992256. Throughput: 0: 256.3. Samples: 994812. Policy #0 lag: (min: 0.0, avg: 2.3, max: 13.0)
[2025-09-21 18:48:13,756][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:48:14,620][3098647] Updated weights for policy 0, policy_version 970 (0.0096)
[2025-09-21 18:48:18,755][3098297] Fps is (10 sec: 409.5, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 994304. Throughput: 0: 256.5. Samples: 995600. Policy #0 lag: (min: 0.0, avg: 2.0, max: 6.0)
[2025-09-21 18:48:18,758][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:48:23,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 994304. Throughput: 0: 256.8. Samples: 997144. Policy #0 lag: (min: 0.0, avg: 2.0, max: 6.0)
[2025-09-21 18:48:23,757][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:48:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 996352. Throughput: 0: 256.4. Samples: 998676. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:48:28,755][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:48:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 997376. Throughput: 0: 256.3. Samples: 999456. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:48:33,757][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:48:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 998400. Throughput: 0: 256.3. Samples: 1000986. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 18:48:38,753][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:48:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 999424. Throughput: 0: 257.5. Samples: 1002548. Policy #0 lag: (min: 0.0, avg: 1.4, max: 6.0)
[2025-09-21 18:48:43,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:48:48,755][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1001472. Throughput: 0: 256.7. Samples: 1003308. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:48:48,758][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:48:48,801][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000978_1001472.pth...
[2025-09-21 18:48:48,825][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000919_941056.pth
[2025-09-21 18:48:53,758][3098297] Fps is (10 sec: 307.0, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1002496. Throughput: 0: 256.5. Samples: 1004828. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:48:53,759][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:48:56,407][3098647] Updated weights for policy 0, policy_version 980 (0.0041)
[2025-09-21 18:48:58,755][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 1004544. Throughput: 0: 255.9. Samples: 1006326. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2025-09-21 18:48:58,759][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 18:49:03,754][3098297] Fps is (10 sec: 307.3, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 1005568. Throughput: 0: 255.2. Samples: 1007086. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:49:03,757][3098297] Avg episode reward: [(0, '0.784')]
[2025-09-21 18:49:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 1006592. Throughput: 0: 255.1. Samples: 1008624. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:49:08,753][3098297] Avg episode reward: [(0, '0.784')]
[2025-09-21 18:49:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1007616. Throughput: 0: 255.1. Samples: 1010158. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:49:13,756][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:49:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 1008640. Throughput: 0: 255.0. Samples: 1010932. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:49:18,754][3098297] Avg episode reward: [(0, '0.793')]
[2025-09-21 18:49:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1009664. Throughput: 0: 255.2. Samples: 1012470. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 18:49:23,753][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:49:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1011712. Throughput: 0: 254.3. Samples: 1013992. Policy #0 lag: (min: 0.0, avg: 1.7, max: 12.0)
[2025-09-21 18:49:28,753][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 18:49:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1012736. Throughput: 0: 254.5. Samples: 1014760. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:49:33,753][3098297] Avg episode reward: [(0, '0.787')]
[2025-09-21 18:49:34,392][3098647] Updated weights for policy 0, policy_version 990 (0.0061)
[2025-09-21 18:49:38,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1013760. Throughput: 0: 255.0. Samples: 1016302. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:49:38,757][3098297] Avg episode reward: [(0, '0.787')]
[2025-09-21 18:49:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 1015808. Throughput: 0: 256.2. Samples: 1017854. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:49:43,756][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 18:49:48,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1016832. Throughput: 0: 256.1. Samples: 1018612. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:49:48,758][3098297] Avg episode reward: [(0, '0.777')]
[2025-09-21 18:49:53,753][3098297] Fps is (10 sec: 102.4, 60 sec: 239.0, 300 sec: 249.9). Total num frames: 1016832. Throughput: 0: 256.5. Samples: 1020166. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:49:53,753][3098297] Avg episode reward: [(0, '0.777')]
[2025-09-21 18:49:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 1018880. Throughput: 0: 255.8. Samples: 1021668. Policy #0 lag: (min: 0.0, avg: 2.8, max: 13.0)
[2025-09-21 18:49:58,757][3098297] Avg episode reward: [(0, '0.793')]
[2025-09-21 18:50:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 1019904. Throughput: 0: 255.6. Samples: 1022436. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:50:03,753][3098297] Avg episode reward: [(0, '0.793')]
[2025-09-21 18:50:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1021952. Throughput: 0: 255.5. Samples: 1023968. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:50:08,753][3098297] Avg episode reward: [(0, '0.794')]
[2025-09-21 18:50:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1022976. Throughput: 0: 255.5. Samples: 1025488. Policy #0 lag: (min: 0.0, avg: 3.1, max: 13.0)
[2025-09-21 18:50:13,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:50:15,533][3098647] Updated weights for policy 0, policy_version 1000 (0.0058)
[2025-09-21 18:50:18,759][3098297] Fps is (10 sec: 204.7, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1024000. Throughput: 0: 255.3. Samples: 1026252. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:50:18,761][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:50:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 1026048. Throughput: 0: 255.5. Samples: 1027800. Policy #0 lag: (min: 0.0, avg: 2.0, max: 6.0)
[2025-09-21 18:50:23,758][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:50:28,755][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1027072. Throughput: 0: 255.3. Samples: 1029344. Policy #0 lag: (min: 0.0, avg: 1.7, max: 11.0)
[2025-09-21 18:50:28,757][3098297] Avg episode reward: [(0, '0.796')]
[2025-09-21 18:50:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1028096. Throughput: 0: 255.2. Samples: 1030096. Policy #0 lag: (min: 0.0, avg: 1.7, max: 11.0)
[2025-09-21 18:50:33,756][3098297] Avg episode reward: [(0, '0.796')]
[2025-09-21 18:50:38,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1029120. Throughput: 0: 254.8. Samples: 1031634. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:50:38,760][3098297] Avg episode reward: [(0, '0.796')]
[2025-09-21 18:50:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1031168. Throughput: 0: 256.0. Samples: 1033190. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:50:43,757][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:50:48,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1032192. Throughput: 0: 256.4. Samples: 1033974. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:50:48,758][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:50:48,793][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001008_1032192.pth...
[2025-09-21 18:50:48,828][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000948_970752.pth
[2025-09-21 18:50:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 253.4). Total num frames: 1033216. Throughput: 0: 256.4. Samples: 1035508. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:50:53,753][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:50:55,517][3098647] Updated weights for policy 0, policy_version 1010 (0.0083)
[2025-09-21 18:50:58,757][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1034240. Throughput: 0: 256.9. Samples: 1037050. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:50:58,759][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 249.9). Total num frames: 1035264. Throughput: 0: 256.8. Samples: 1037808. Policy #0 lag: (min: 0.0, avg: 2.0, max: 12.0)
[2025-09-21 18:51:03,759][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:08,755][3098297] Fps is (10 sec: 204.9, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 1036288. Throughput: 0: 256.9. Samples: 1039360. Policy #0 lag: (min: 0.0, avg: 2.2, max: 13.0)
[2025-09-21 18:51:08,760][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1038336. Throughput: 0: 255.7. Samples: 1040852. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:51:13,756][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1039360. Throughput: 0: 256.2. Samples: 1041626. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:51:18,753][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1041408. Throughput: 0: 256.1. Samples: 1043158. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:51:23,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:51:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1042432. Throughput: 0: 255.6. Samples: 1044692. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 18:51:28,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:51:33,753][3098297] Fps is (10 sec: 102.4, 60 sec: 238.9, 300 sec: 249.9). Total num frames: 1042432. Throughput: 0: 255.5. Samples: 1045472. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 18:51:33,753][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:51:34,836][3098647] Updated weights for policy 0, policy_version 1020 (0.0074)
[2025-09-21 18:51:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1044480. Throughput: 0: 255.4. Samples: 1047002. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:51:38,757][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:51:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 1045504. Throughput: 0: 255.8. Samples: 1048558. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:51:43,753][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:48,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1047552. Throughput: 0: 256.0. Samples: 1049330. Policy #0 lag: (min: 0.0, avg: 2.1, max: 11.0)
[2025-09-21 18:51:48,758][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1048576. Throughput: 0: 255.4. Samples: 1050854. Policy #0 lag: (min: 0.0, avg: 2.6, max: 11.0)
[2025-09-21 18:51:53,753][3098297] Avg episode reward: [(0, '0.790')]
[2025-09-21 18:51:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1049600. Throughput: 0: 255.9. Samples: 1052366. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:51:58,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:52:03,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1051648. Throughput: 0: 255.8. Samples: 1053136. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:52:03,756][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:52:08,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1051648. Throughput: 0: 255.9. Samples: 1054676. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:52:08,757][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:52:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1053696. Throughput: 0: 256.2. Samples: 1056222. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:52:13,753][3098297] Avg episode reward: [(0, '0.796')]
[2025-09-21 18:52:15,088][3098647] Updated weights for policy 0, policy_version 1030 (0.0115)
[2025-09-21 18:52:18,758][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1054720. Throughput: 0: 255.9. Samples: 1056986. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:52:18,761][3098297] Avg episode reward: [(0, '0.796')]
[2025-09-21 18:52:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1056768. Throughput: 0: 256.4. Samples: 1058538. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:52:23,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:52:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1057792. Throughput: 0: 256.3. Samples: 1060090. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:52:28,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:52:33,754][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1058816. Throughput: 0: 256.2. Samples: 1060860. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:52:33,756][3098297] Avg episode reward: [(0, '0.794')]
[2025-09-21 18:52:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1059840. Throughput: 0: 256.8. Samples: 1062410. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:52:38,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:52:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1061888. Throughput: 0: 257.5. Samples: 1063954. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:52:43,764][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:52:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1062912. Throughput: 0: 257.7. Samples: 1064732. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:52:48,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:52:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001038_1062912.pth...
[2025-09-21 18:52:48,788][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000000978_1001472.pth
[2025-09-21 18:52:53,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1063936. Throughput: 0: 258.6. Samples: 1066312. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:52:53,755][3098297] Avg episode reward: [(0, '0.794')]
[2025-09-21 18:52:55,315][3098647] Updated weights for policy 0, policy_version 1040 (0.0094)
[2025-09-21 18:52:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1064960. Throughput: 0: 258.5. Samples: 1067854. Policy #0 lag: (min: 0.0, avg: 3.2, max: 12.0)
[2025-09-21 18:52:58,758][3098297] Avg episode reward: [(0, '0.794')]
[2025-09-21 18:53:03,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1067008. Throughput: 0: 258.9. Samples: 1068638. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:53:03,757][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:08,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1068032. Throughput: 0: 259.0. Samples: 1070192. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:53:08,756][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1069056. Throughput: 0: 259.9. Samples: 1071784. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:53:13,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:18,757][3098297] Fps is (10 sec: 204.7, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1070080. Throughput: 0: 260.3. Samples: 1072572. Policy #0 lag: (min: 0.0, avg: 1.5, max: 5.0)
[2025-09-21 18:53:18,760][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 1071104. Throughput: 0: 260.6. Samples: 1074138. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:53:23,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:28,753][3098297] Fps is (10 sec: 204.9, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 1072128. Throughput: 0: 261.1. Samples: 1075704. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 18:53:28,753][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1074176. Throughput: 0: 261.2. Samples: 1076488. Policy #0 lag: (min: 0.0, avg: 1.9, max: 8.0)
[2025-09-21 18:53:33,756][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:36,172][3098647] Updated weights for policy 0, policy_version 1050 (0.0093)
[2025-09-21 18:53:38,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1075200. Throughput: 0: 260.1. Samples: 1078018. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:53:38,758][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 253.4). Total num frames: 1076224. Throughput: 0: 260.4. Samples: 1079572. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:53:43,757][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:48,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1078272. Throughput: 0: 260.4. Samples: 1080354. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 18:53:48,759][3098297] Avg episode reward: [(0, '0.795')]
[2025-09-21 18:53:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1079296. Throughput: 0: 259.7. Samples: 1081878. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:53:53,753][3098297] Avg episode reward: [(0, '0.803')]
[2025-09-21 18:53:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1080320. Throughput: 0: 258.5. Samples: 1083416. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:53:58,769][3098297] Avg episode reward: [(0, '0.803')]
[2025-09-21 18:54:03,754][3098297] Fps is (10 sec: 307.1, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1082368. Throughput: 0: 258.2. Samples: 1084192. Policy #0 lag: (min: 0.0, avg: 2.1, max: 5.0)
[2025-09-21 18:54:03,755][3098297] Avg episode reward: [(0, '0.802')]
[2025-09-21 18:54:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1083392. Throughput: 0: 257.6. Samples: 1085728. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:54:08,753][3098297] Avg episode reward: [(0, '0.802')]
[2025-09-21 18:54:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1084416. Throughput: 0: 257.6. Samples: 1087296. Policy #0 lag: (min: 0.0, avg: 2.7, max: 11.0)
[2025-09-21 18:54:13,756][3098297] Avg episode reward: [(0, '0.802')]
[2025-09-21 18:54:16,447][3098647] Updated weights for policy 0, policy_version 1060 (0.0118)
[2025-09-21 18:54:18,755][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1086464. Throughput: 0: 258.0. Samples: 1088096. Policy #0 lag: (min: 0.0, avg: 1.7, max: 11.0)
[2025-09-21 18:54:18,757][3098297] Avg episode reward: [(0, '0.803')]
[2025-09-21 18:54:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1087488. Throughput: 0: 258.4. Samples: 1089646. Policy #0 lag: (min: 0.0, avg: 2.9, max: 11.0)
[2025-09-21 18:54:23,760][3098297] Avg episode reward: [(0, '0.803')]
[2025-09-21 18:54:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1088512. Throughput: 0: 258.8. Samples: 1091216. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:54:28,753][3098297] Avg episode reward: [(0, '0.803')]
[2025-09-21 18:54:33,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1089536. Throughput: 0: 258.9. Samples: 1092006. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:54:33,760][3098297] Avg episode reward: [(0, '0.803')]
[2025-09-21 18:54:38,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 253.4). Total num frames: 1090560. Throughput: 0: 259.9. Samples: 1093574. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:54:38,763][3098297] Avg episode reward: [(0, '0.803')]
[2025-09-21 18:54:43,753][3098297] Fps is (10 sec: 307.3, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1092608. Throughput: 0: 260.4. Samples: 1095132. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:54:43,753][3098297] Avg episode reward: [(0, '0.802')]
[2025-09-21 18:54:48,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1093632. Throughput: 0: 260.9. Samples: 1095930. Policy #0 lag: (min: 0.0, avg: 3.2, max: 10.0)
[2025-09-21 18:54:48,753][3098297] Avg episode reward: [(0, '0.802')]
[2025-09-21 18:54:48,765][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001068_1093632.pth...
[2025-09-21 18:54:48,797][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001008_1032192.pth
[2025-09-21 18:54:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1094656. Throughput: 0: 261.3. Samples: 1097486. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 18:54:53,753][3098297] Avg episode reward: [(0, '0.801')]
[2025-09-21 18:54:54,058][3098647] Updated weights for policy 0, policy_version 1070 (0.0104)
[2025-09-21 18:54:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1096704. Throughput: 0: 260.3. Samples: 1099010. Policy #0 lag: (min: 0.0, avg: 1.6, max: 4.0)
[2025-09-21 18:54:58,753][3098297] Avg episode reward: [(0, '0.801')]
[2025-09-21 18:55:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1097728. Throughput: 0: 260.6. Samples: 1099822. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:55:03,753][3098297] Avg episode reward: [(0, '0.801')]
[2025-09-21 18:55:08,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1098752. Throughput: 0: 260.5. Samples: 1101368. Policy #0 lag: (min: 0.0, avg: 2.0, max: 11.0)
[2025-09-21 18:55:08,757][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:55:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1100800. Throughput: 0: 260.6. Samples: 1102942. Policy #0 lag: (min: 0.0, avg: 2.8, max: 9.0)
[2025-09-21 18:55:13,756][3098297] Avg episode reward: [(0, '0.800')]
[2025-09-21 18:55:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1101824. Throughput: 0: 260.8. Samples: 1103742. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:55:18,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1102848. Throughput: 0: 260.7. Samples: 1105306. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:55:23,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1104896. Throughput: 0: 260.9. Samples: 1106874. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:55:28,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:33,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1104896. Throughput: 0: 260.7. Samples: 1107664. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 18:55:33,769][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:33,956][3098647] Updated weights for policy 0, policy_version 1080 (0.0120)
[2025-09-21 18:55:38,754][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1106944. Throughput: 0: 261.4. Samples: 1109248. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:55:38,757][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:43,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1107968. Throughput: 0: 262.4. Samples: 1110816. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 18:55:43,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1108992. Throughput: 0: 261.8. Samples: 1111602. Policy #0 lag: (min: 0.0, avg: 2.2, max: 11.0)
[2025-09-21 18:55:48,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1111040. Throughput: 0: 262.1. Samples: 1113164. Policy #0 lag: (min: 0.0, avg: 2.8, max: 12.0)
[2025-09-21 18:55:53,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:55:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1112064. Throughput: 0: 261.2. Samples: 1114698. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:55:58,756][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:56:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 263.8). Total num frames: 1114112. Throughput: 0: 260.9. Samples: 1115482. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 18:56:03,753][3098297] Avg episode reward: [(0, '0.798')]
[2025-09-21 18:56:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1115136. Throughput: 0: 260.7. Samples: 1117036. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 18:56:08,753][3098297] Avg episode reward: [(0, '0.797')]
[2025-09-21 18:56:12,756][3098647] Updated weights for policy 0, policy_version 1090 (0.0075)
[2025-09-21 18:56:13,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1116160. Throughput: 0: 260.8. Samples: 1118608. Policy #0 lag: (min: 0.0, avg: 1.8, max: 8.0)
[2025-09-21 18:56:13,753][3098297] Avg episode reward: [(0, '0.793')]
[2025-09-21 18:56:18,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1117184. Throughput: 0: 260.4. Samples: 1119382. Policy #0 lag: (min: 0.0, avg: 1.8, max: 8.0)
[2025-09-21 18:56:18,753][3098297] Avg episode reward: [(0, '0.793')]
[2025-09-21 18:56:23,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1118208. Throughput: 0: 259.9. Samples: 1120942. Policy #0 lag: (min: 0.0, avg: 1.6, max: 6.0)
[2025-09-21 18:56:23,753][3098297] Avg episode reward: [(0, '0.794')]
[2025-09-21 18:56:28,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 263.8). Total num frames: 1120256. Throughput: 0: 259.2. Samples: 1122482. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 18:56:28,753][3098297] Avg episode reward: [(0, '0.794')]
[2025-09-21 18:56:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1121280. Throughput: 0: 259.4. Samples: 1123274. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:56:33,753][3098297] Avg episode reward: [(0, '0.794')]
[2025-09-21 18:56:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1122304. Throughput: 0: 258.2. Samples: 1124784. Policy #0 lag: (min: 0.0, avg: 2.5, max: 11.0)
[2025-09-21 18:56:38,753][3098297] Avg episode reward: [(0, '0.792')]
[2025-09-21 18:56:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1124352. Throughput: 0: 258.6. Samples: 1126336. Policy #0 lag: (min: 0.0, avg: 2.0, max: 8.0)
[2025-09-21 18:56:43,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:56:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1124352. Throughput: 0: 258.7. Samples: 1127122. Policy #0 lag: (min: 0.0, avg: 2.0, max: 8.0)
[2025-09-21 18:56:48,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:56:49,529][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001099_1125376.pth...
[2025-09-21 18:56:49,656][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001038_1062912.pth
[2025-09-21 18:56:52,816][3098647] Updated weights for policy 0, policy_version 1100 (0.0093)
[2025-09-21 18:56:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1126400. Throughput: 0: 258.2. Samples: 1128656. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:56:53,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:56:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1127424. Throughput: 0: 257.2. Samples: 1130184. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:56:58,753][3098297] Avg episode reward: [(0, '0.773')]
[2025-09-21 18:57:03,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 263.8). Total num frames: 1129472. Throughput: 0: 257.3. Samples: 1130960. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:57:03,753][3098297] Avg episode reward: [(0, '0.773')]
[2025-09-21 18:57:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1130496. Throughput: 0: 257.2. Samples: 1132518. Policy #0 lag: (min: 0.0, avg: 3.3, max: 12.0)
[2025-09-21 18:57:08,754][3098297] Avg episode reward: [(0, '0.784')]
[2025-09-21 18:57:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1131520. Throughput: 0: 257.8. Samples: 1134082. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 18:57:13,756][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:57:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1133568. Throughput: 0: 257.8. Samples: 1134876. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 18:57:18,753][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:57:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1134592. Throughput: 0: 258.9. Samples: 1136436. Policy #0 lag: (min: 0.0, avg: 2.0, max: 6.0)
[2025-09-21 18:57:23,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:57:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1135616. Throughput: 0: 259.3. Samples: 1138004. Policy #0 lag: (min: 0.0, avg: 1.7, max: 7.0)
[2025-09-21 18:57:28,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:57:32,926][3098647] Updated weights for policy 0, policy_version 1110 (0.0076)
[2025-09-21 18:57:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1136640. Throughput: 0: 259.3. Samples: 1138790. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 18:57:33,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:57:38,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1138688. Throughput: 0: 259.9. Samples: 1140352. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:57:38,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:57:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1138688. Throughput: 0: 260.7. Samples: 1141914. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 18:57:43,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:57:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1140736. Throughput: 0: 260.9. Samples: 1142700. Policy #0 lag: (min: 0.0, avg: 2.2, max: 13.0)
[2025-09-21 18:57:48,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:57:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1141760. Throughput: 0: 260.7. Samples: 1144250. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 18:57:53,753][3098297] Avg episode reward: [(0, '0.791')]
[2025-09-21 18:57:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1143808. Throughput: 0: 259.7. Samples: 1145766. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:57:58,753][3098297] Avg episode reward: [(0, '0.775')]
[2025-09-21 18:58:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1143808. Throughput: 0: 259.7. Samples: 1146562. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:58:03,753][3098297] Avg episode reward: [(0, '0.775')]
[2025-09-21 18:58:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1145856. Throughput: 0: 259.2. Samples: 1148102. Policy #0 lag: (min: 0.0, avg: 1.8, max: 9.0)
[2025-09-21 18:58:08,753][3098297] Avg episode reward: [(0, '0.776')]
[2025-09-21 18:58:10,994][3098647] Updated weights for policy 0, policy_version 1120 (0.0076)
[2025-09-21 18:58:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1146880. Throughput: 0: 259.3. Samples: 1149674. Policy #0 lag: (min: 0.0, avg: 2.0, max: 6.0)
[2025-09-21 18:58:13,753][3098297] Avg episode reward: [(0, '0.780')]
[2025-09-21 18:58:18,755][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 260.3). Total num frames: 1147904. Throughput: 0: 259.2. Samples: 1150454. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:58:18,757][3098297] Avg episode reward: [(0, '0.780')]
[2025-09-21 18:58:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 263.8). Total num frames: 1149952. Throughput: 0: 259.5. Samples: 1152028. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 18:58:23,756][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:58:28,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1150976. Throughput: 0: 259.5. Samples: 1153594. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:58:28,758][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:58:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1152000. Throughput: 0: 259.5. Samples: 1154378. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:58:33,753][3098297] Avg episode reward: [(0, '0.780')]
[2025-09-21 18:58:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 260.3). Total num frames: 1153024. Throughput: 0: 260.1. Samples: 1155954. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:58:38,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:58:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1155072. Throughput: 0: 261.0. Samples: 1157510. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:58:43,753][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 18:58:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1156096. Throughput: 0: 261.0. Samples: 1158308. Policy #0 lag: (min: 0.0, avg: 2.0, max: 5.0)
[2025-09-21 18:58:48,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:58:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001129_1156096.pth...
[2025-09-21 18:58:48,787][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001068_1093632.pth
[2025-09-21 18:58:50,634][3098647] Updated weights for policy 0, policy_version 1130 (0.0074)
[2025-09-21 18:58:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1157120. Throughput: 0: 261.7. Samples: 1159878. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:58:53,754][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:58:58,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1158144. Throughput: 0: 260.8. Samples: 1161412. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 18:58:58,756][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:03,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1160192. Throughput: 0: 260.7. Samples: 1162186. Policy #0 lag: (min: 0.0, avg: 1.9, max: 4.0)
[2025-09-21 18:59:03,768][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:08,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1161216. Throughput: 0: 260.2. Samples: 1163738. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:59:08,756][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1162240. Throughput: 0: 260.2. Samples: 1165304. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 18:59:13,758][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:18,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1164288. Throughput: 0: 260.1. Samples: 1166084. Policy #0 lag: (min: 0.0, avg: 1.7, max: 7.0)
[2025-09-21 18:59:18,757][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1165312. Throughput: 0: 259.9. Samples: 1167648. Policy #0 lag: (min: 0.0, avg: 1.7, max: 7.0)
[2025-09-21 18:59:23,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1166336. Throughput: 0: 260.6. Samples: 1169236. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 18:59:28,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:29,505][3098647] Updated weights for policy 0, policy_version 1140 (0.0084)
[2025-09-21 18:59:33,754][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 263.8). Total num frames: 1168384. Throughput: 0: 260.5. Samples: 1170032. Policy #0 lag: (min: 0.0, avg: 1.5, max: 4.0)
[2025-09-21 18:59:33,757][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1169408. Throughput: 0: 260.7. Samples: 1171608. Policy #0 lag: (min: 0.0, avg: 1.9, max: 10.0)
[2025-09-21 18:59:38,758][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:43,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1170432. Throughput: 0: 261.6. Samples: 1173184. Policy #0 lag: (min: 0.0, avg: 2.3, max: 10.0)
[2025-09-21 18:59:43,756][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 18:59:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 263.8). Total num frames: 1172480. Throughput: 0: 262.1. Samples: 1173978. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 18:59:48,753][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:59:53,753][3098297] Fps is (10 sec: 307.3, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1173504. Throughput: 0: 262.4. Samples: 1175544. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:59:53,753][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 18:59:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1174528. Throughput: 0: 261.8. Samples: 1177084. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 18:59:58,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 19:00:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1175552. Throughput: 0: 262.1. Samples: 1177876. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 19:00:03,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 19:00:08,113][3098647] Updated weights for policy 0, policy_version 1150 (0.0063)
[2025-09-21 19:00:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1177600. Throughput: 0: 262.0. Samples: 1179438. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 19:00:08,753][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 19:00:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1178624. Throughput: 0: 261.2. Samples: 1180988. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 19:00:13,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 19:00:18,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1179648. Throughput: 0: 261.2. Samples: 1181788. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 19:00:18,759][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 19:00:23,756][3098297] Fps is (10 sec: 204.7, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1180672. Throughput: 0: 260.7. Samples: 1183338. Policy #0 lag: (min: 0.0, avg: 1.7, max: 4.0)
[2025-09-21 19:00:23,759][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 19:00:28,756][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1181696. Throughput: 0: 260.2. Samples: 1184892. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 19:00:28,762][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 19:00:33,754][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1183744. Throughput: 0: 260.1. Samples: 1185682. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 19:00:33,756][3098297] Avg episode reward: [(0, '0.781')]
[2025-09-21 19:00:38,753][3098297] Fps is (10 sec: 307.3, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1184768. Throughput: 0: 259.9. Samples: 1187238. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 19:00:38,753][3098297] Avg episode reward: [(0, '0.782')]
[2025-09-21 19:00:43,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1185792. Throughput: 0: 260.6. Samples: 1188812. Policy #0 lag: (min: 0.0, avg: 2.4, max: 9.0)
[2025-09-21 19:00:43,753][3098297] Avg episode reward: [(0, '0.783')]
[2025-09-21 19:00:47,733][3098647] Updated weights for policy 0, policy_version 1160 (0.0085)
[2025-09-21 19:00:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1187840. Throughput: 0: 260.5. Samples: 1189598. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 19:00:48,753][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 19:00:48,765][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001160_1187840.pth...
[2025-09-21 19:00:48,793][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001099_1125376.pth
[2025-09-21 19:00:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1188864. Throughput: 0: 260.3. Samples: 1191150. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 19:00:53,753][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 19:00:58,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1189888. Throughput: 0: 258.0. Samples: 1192600. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 19:00:58,753][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 19:01:03,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1190912. Throughput: 0: 256.7. Samples: 1193338. Policy #0 lag: (min: 0.0, avg: 1.7, max: 5.0)
[2025-09-21 19:01:03,753][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 19:01:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1192960. Throughput: 0: 254.9. Samples: 1194806. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 19:01:08,753][3098297] Avg episode reward: [(0, '0.787')]
[2025-09-21 19:01:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1192960. Throughput: 0: 254.9. Samples: 1196360. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 19:01:13,756][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 19:01:18,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1195008. Throughput: 0: 254.8. Samples: 1197148. Policy #0 lag: (min: 0.0, avg: 1.7, max: 9.0)
[2025-09-21 19:01:18,760][3098297] Avg episode reward: [(0, '0.786')]
[2025-09-21 19:01:23,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1196032. Throughput: 0: 254.3. Samples: 1198680. Policy #0 lag: (min: 0.0, avg: 3.1, max: 13.0)
[2025-09-21 19:01:23,756][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:01:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1197056. Throughput: 0: 254.0. Samples: 1200240. Policy #0 lag: (min: 0.0, avg: 2.7, max: 10.0)
[2025-09-21 19:01:28,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:01:28,893][3098647] Updated weights for policy 0, policy_version 1170 (0.0094)
[2025-09-21 19:01:33,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1199104. Throughput: 0: 253.6. Samples: 1201010. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 19:01:33,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:01:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1200128. Throughput: 0: 253.3. Samples: 1202548. Policy #0 lag: (min: 0.0, avg: 2.8, max: 11.0)
[2025-09-21 19:01:38,761][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:01:43,754][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1201152. Throughput: 0: 255.2. Samples: 1204084. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 19:01:43,756][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:01:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1203200. Throughput: 0: 256.0. Samples: 1204856. Policy #0 lag: (min: 0.0, avg: 1.7, max: 8.0)
[2025-09-21 19:01:48,753][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:01:53,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1203200. Throughput: 0: 256.9. Samples: 1206366. Policy #0 lag: (min: 0.0, avg: 1.7, max: 8.0)
[2025-09-21 19:01:53,757][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:01:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1205248. Throughput: 0: 256.2. Samples: 1207888. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 19:01:58,757][3098297] Avg episode reward: [(0, '0.785')]
[2025-09-21 19:02:03,753][3098297] Fps is (10 sec: 409.7, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1207296. Throughput: 0: 255.9. Samples: 1208662. Policy #0 lag: (min: 0.0, avg: 1.9, max: 11.0)
[2025-09-21 19:02:03,753][3098297] Avg episode reward: [(0, '0.788')]
[2025-09-21 19:02:07,609][3098647] Updated weights for policy 0, policy_version 1180 (0.0076)
[2025-09-21 19:02:08,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1208320. Throughput: 0: 256.5. Samples: 1210220. Policy #0 lag: (min: 0.0, avg: 2.5, max: 9.0)
[2025-09-21 19:02:08,753][3098297] Avg episode reward: [(0, '0.788')]
[2025-09-21 19:02:13,754][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1209344. Throughput: 0: 256.4. Samples: 1211778. Policy #0 lag: (min: 0.0, avg: 2.0, max: 12.0)
[2025-09-21 19:02:13,756][3098297] Avg episode reward: [(0, '0.789')]
[2025-09-21 19:02:18,764][3098297] Fps is (10 sec: 204.6, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1210368. Throughput: 0: 256.6. Samples: 1212558. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 19:02:18,769][3098297] Avg episode reward: [(0, '0.789')]
[2025-09-21 19:02:23,756][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1212416. Throughput: 0: 256.9. Samples: 1214110. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 19:02:23,762][3098297] Avg episode reward: [(0, '0.788')]
[2025-09-21 19:02:28,754][3098297] Fps is (10 sec: 205.0, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1212416. Throughput: 0: 257.6. Samples: 1215676. Policy #0 lag: (min: 0.0, avg: 1.9, max: 5.0)
[2025-09-21 19:02:28,759][3098297] Avg episode reward: [(0, '0.788')]
[2025-09-21 19:02:33,753][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1214464. Throughput: 0: 258.0. Samples: 1216468. Policy #0 lag: (min: 0.0, avg: 1.6, max: 8.0)
[2025-09-21 19:02:33,753][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:02:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1215488. Throughput: 0: 259.1. Samples: 1218024. Policy #0 lag: (min: 0.0, avg: 2.4, max: 8.0)
[2025-09-21 19:02:38,757][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:02:43,788][3098297] Fps is (10 sec: 306.1, 60 sec: 272.9, 300 sec: 260.3). Total num frames: 1217536. Throughput: 0: 260.1. Samples: 1219602. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 19:02:43,798][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:02:47,370][3098647] Updated weights for policy 0, policy_version 1190 (0.0058)
[2025-09-21 19:02:48,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1218560. Throughput: 0: 260.3. Samples: 1220374. Policy #0 lag: (min: 0.0, avg: 2.0, max: 9.0)
[2025-09-21 19:02:48,756][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:02:48,791][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001190_1218560.pth...
[2025-09-21 19:02:48,818][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001129_1156096.pth
[2025-09-21 19:02:53,753][3098297] Fps is (10 sec: 205.5, 60 sec: 273.1, 300 sec: 256.9). Total num frames: 1219584. Throughput: 0: 260.4. Samples: 1221938. Policy #0 lag: (min: 0.0, avg: 2.2, max: 9.0)
[2025-09-21 19:02:53,753][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:02:58,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1220608. Throughput: 0: 260.0. Samples: 1223478. Policy #0 lag: (min: 0.0, avg: 1.8, max: 7.0)
[2025-09-21 19:02:58,757][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:03:03,754][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1221632. Throughput: 0: 260.3. Samples: 1224268. Policy #0 lag: (min: 0.0, avg: 1.9, max: 6.0)
[2025-09-21 19:03:03,756][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:03:08,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1223680. Throughput: 0: 260.3. Samples: 1225822. Policy #0 lag: (min: 0.0, avg: 2.6, max: 9.0)
[2025-09-21 19:03:08,756][3098297] Avg episode reward: [(0, '0.773')]
[2025-09-21 19:03:13,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1224704. Throughput: 0: 260.6. Samples: 1227402. Policy #0 lag: (min: 0.0, avg: 2.3, max: 11.0)
[2025-09-21 19:03:13,756][3098297] Avg episode reward: [(0, '0.773')]
[2025-09-21 19:03:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1226752. Throughput: 0: 260.3. Samples: 1228182. Policy #0 lag: (min: 0.0, avg: 2.0, max: 10.0)
[2025-09-21 19:03:18,753][3098297] Avg episode reward: [(0, '0.773')]
[2025-09-21 19:03:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1227776. Throughput: 0: 261.0. Samples: 1229770. Policy #0 lag: (min: 0.0, avg: 1.8, max: 5.0)
[2025-09-21 19:03:23,753][3098297] Avg episode reward: [(0, '0.773')]
[2025-09-21 19:03:26,263][3098647] Updated weights for policy 0, policy_version 1200 (0.0132)
[2025-09-21 19:03:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1228800. Throughput: 0: 261.2. Samples: 1231348. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 19:03:28,753][3098297] Avg episode reward: [(0, '0.773')]
[2025-09-21 19:03:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1229824. Throughput: 0: 261.3. Samples: 1232134. Policy #0 lag: (min: 0.0, avg: 2.5, max: 12.0)
[2025-09-21 19:03:33,753][3098297] Avg episode reward: [(0, '0.774')]
[2025-09-21 19:03:38,755][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1231872. Throughput: 0: 261.5. Samples: 1233706. Policy #0 lag: (min: 0.0, avg: 2.1, max: 8.0)
[2025-09-21 19:03:38,757][3098297] Avg episode reward: [(0, '0.774')]
[2025-09-21 19:03:43,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.1, 300 sec: 260.3). Total num frames: 1232896. Throughput: 0: 262.0. Samples: 1235268. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 19:03:43,753][3098297] Avg episode reward: [(0, '0.775')]
[2025-09-21 19:03:48,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1233920. Throughput: 0: 262.1. Samples: 1236062. Policy #0 lag: (min: 0.0, avg: 2.1, max: 9.0)
[2025-09-21 19:03:48,753][3098297] Avg episode reward: [(0, '0.775')]
[2025-09-21 19:03:53,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 263.8). Total num frames: 1235968. Throughput: 0: 262.2. Samples: 1237620. Policy #0 lag: (min: 0.0, avg: 2.5, max: 10.0)
[2025-09-21 19:03:53,753][3098297] Avg episode reward: [(0, '0.775')]
[2025-09-21 19:03:58,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1236992. Throughput: 0: 260.1. Samples: 1239106. Policy #0 lag: (min: 0.0, avg: 1.8, max: 4.0)
[2025-09-21 19:03:58,753][3098297] Avg episode reward: [(0, '0.776')]
[2025-09-21 19:04:03,756][3098297] Fps is (10 sec: 204.7, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1238016. Throughput: 0: 260.0. Samples: 1239882. Policy #0 lag: (min: 0.0, avg: 1.2, max: 4.0)
[2025-09-21 19:04:03,757][3098297] Avg episode reward: [(0, '0.776')]
[2025-09-21 19:04:05,972][3098647] Updated weights for policy 0, policy_version 1210 (0.0098)
[2025-09-21 19:04:08,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1239040. Throughput: 0: 259.0. Samples: 1241424. Policy #0 lag: (min: 0.0, avg: 2.2, max: 10.0)
[2025-09-21 19:04:08,753][3098297] Avg episode reward: [(0, '0.776')]
[2025-09-21 19:04:13,754][3098297] Fps is (10 sec: 204.9, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1240064. Throughput: 0: 258.8. Samples: 1242996. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 19:04:13,756][3098297] Avg episode reward: [(0, '0.776')]
[2025-09-21 19:04:18,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1242112. Throughput: 0: 258.8. Samples: 1243780. Policy #0 lag: (min: 0.0, avg: 2.3, max: 9.0)
[2025-09-21 19:04:18,753][3098297] Avg episode reward: [(0, '0.776')]
[2025-09-21 19:04:23,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1243136. Throughput: 0: 258.9. Samples: 1245356. Policy #0 lag: (min: 0.0, avg: 1.6, max: 5.0)
[2025-09-21 19:04:23,753][3098297] Avg episode reward: [(0, '0.777')]
[2025-09-21 19:04:28,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1244160. Throughput: 0: 258.9. Samples: 1246920. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 19:04:28,753][3098297] Avg episode reward: [(0, '0.777')]
[2025-09-21 19:04:33,753][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1245184. Throughput: 0: 258.7. Samples: 1247702. Policy #0 lag: (min: 0.0, avg: 2.1, max: 10.0)
[2025-09-21 19:04:33,753][3098297] Avg episode reward: [(0, '0.778')]
[2025-09-21 19:04:38,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1246208. Throughput: 0: 259.1. Samples: 1249278. Policy #0 lag: (min: 0.0, avg: 2.4, max: 11.0)
[2025-09-21 19:04:38,753][3098297] Avg episode reward: [(0, '0.778')]
[2025-09-21 19:04:43,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1248256. Throughput: 0: 260.5. Samples: 1250830. Policy #0 lag: (min: 0.0, avg: 2.1, max: 8.0)
[2025-09-21 19:04:43,756][3098297] Avg episode reward: [(0, '0.778')]
[2025-09-21 19:04:46,772][3098647] Updated weights for policy 0, policy_version 1220 (0.0112)
[2025-09-21 19:04:48,753][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1249280. Throughput: 0: 260.9. Samples: 1251622. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 19:04:48,753][3098297] Avg episode reward: [(0, '0.778')]
[2025-09-21 19:04:48,761][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001221_1250304.pth...
[2025-09-21 19:04:48,796][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001160_1187840.pth
[2025-09-21 19:04:53,753][3098297] Fps is (10 sec: 204.8, 60 sec: 238.9, 300 sec: 256.9). Total num frames: 1250304. Throughput: 0: 261.2. Samples: 1253176. Policy #0 lag: (min: 0.0, avg: 2.6, max: 10.0)
[2025-09-21 19:04:53,753][3098297] Avg episode reward: [(0, '0.778')]
[2025-09-21 19:04:58,754][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 260.3). Total num frames: 1252352. Throughput: 0: 260.6. Samples: 1254724. Policy #0 lag: (min: 0.0, avg: 1.8, max: 10.0)
[2025-09-21 19:04:58,757][3098297] Avg episode reward: [(0, '0.770')]
[2025-09-21 19:05:03,755][3098297] Fps is (10 sec: 307.2, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1253376. Throughput: 0: 260.6. Samples: 1255506. Policy #0 lag: (min: 0.0, avg: 2.4, max: 10.0)
[2025-09-21 19:05:03,757][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:05:08,755][3098297] Fps is (10 sec: 204.8, 60 sec: 256.0, 300 sec: 256.9). Total num frames: 1254400. Throughput: 0: 260.1. Samples: 1257062. Policy #0 lag: (min: 0.0, avg: 3.1, max: 13.0)
[2025-09-21 19:05:08,757][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:05:13,753][3098297] Fps is (10 sec: 307.2, 60 sec: 273.1, 300 sec: 260.3). Total num frames: 1256448. Throughput: 0: 260.2. Samples: 1258628. Policy #0 lag: (min: 0.0, avg: 2.1, max: 8.0)
[2025-09-21 19:05:13,753][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:37:08,476][3098297] Heartbeat reconnected after 1915 seconds from Batcher_0
[2025-09-21 19:37:08,480][3098297] Fps is (10 sec: 1.1, 60 sec: 7.3, 300 sec: 34.4). Total num frames: 1256448. Throughput: 0: 5.6. Samples: 1258628. Policy #0 lag: (min: 0.0, avg: 2.1, max: 8.0)
[2025-09-21 19:37:08,482][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:37:08,517][3098297] No heartbeat for components: LearnerWorker_p0 (1915 seconds), InferenceWorker_p0-w0 (1915 seconds), RolloutWorker_w0 (1915 seconds), RolloutWorker_w1 (1915 seconds), RolloutWorker_w2 (1915 seconds), RolloutWorker_w3 (1915 seconds), RolloutWorker_w4 (1915 seconds), RolloutWorker_w5 (1915 seconds), RolloutWorker_w6 (1915 seconds), RolloutWorker_w7 (1915 seconds), RolloutWorker_w8 (1915 seconds), RolloutWorker_w9 (1915 seconds), RolloutWorker_w10 (1915 seconds), RolloutWorker_w11 (1915 seconds), RolloutWorker_w12 (1913 seconds), RolloutWorker_w13 (1914 seconds), RolloutWorker_w14 (1914 seconds), RolloutWorker_w15 (1914 seconds), RolloutWorker_w16 (1913 seconds), RolloutWorker_w17 (1914 seconds), RolloutWorker_w18 (1914 seconds), RolloutWorker_w19 (1914 seconds), RolloutWorker_w20 (1915 seconds), RolloutWorker_w21 (1915 seconds), RolloutWorker_w22 (1914 seconds), RolloutWorker_w23 (1915 seconds), RolloutWorker_w24 (1915 seconds), RolloutWorker_w25 (1915 seconds), RolloutWorker_w26 (1915 seconds), RolloutWorker_w27 (1915 seconds), RolloutWorker_w28 (1915 seconds), RolloutWorker_w29 (1915 seconds), RolloutWorker_w30 (1915 seconds), RolloutWorker_w31 (1914 seconds)
[2025-09-21 19:37:08,521][3098297] Stopping training due to lack of heartbeats from <class 'sample_factory.algo.learning.learner_worker.LearnerWorker'>, <class 'sample_factory.algo.sampling.inference_worker.InferenceWorker'>, <class 'sample_factory.algo.sampling.rollout_worker.RolloutWorker'>
[2025-09-21 19:37:08,517][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001227_1256448.pth...
[2025-09-21 19:37:08,528][3098297] Fps is (10 sec: 0.0, 60 sec: 6.8, 300 sec: 34.0). Total num frames: 1256448. Throughput: 0: 4.8. Samples: 1258628. Policy #0 lag: (min: 0.0, avg: 2.1, max: 8.0)
[2025-09-21 19:37:08,529][3098297] Avg episode reward: [(0, '0.771')]
[2025-09-21 19:37:08,536][3098570] Stopping Batcher_0...
[2025-09-21 19:37:08,558][3098297] No heartbeat for components: LearnerWorker_p0 (1915 seconds), InferenceWorker_p0-w0 (1915 seconds), RolloutWorker_w0 (1915 seconds), RolloutWorker_w1 (1915 seconds), RolloutWorker_w2 (1915 seconds), RolloutWorker_w3 (1915 seconds), RolloutWorker_w4 (1915 seconds), RolloutWorker_w5 (1915 seconds), RolloutWorker_w6 (1915 seconds), RolloutWorker_w7 (1915 seconds), RolloutWorker_w8 (1915 seconds), RolloutWorker_w9 (1915 seconds), RolloutWorker_w10 (1915 seconds), RolloutWorker_w11 (1915 seconds), RolloutWorker_w12 (1913 seconds), RolloutWorker_w13 (1914 seconds), RolloutWorker_w14 (1914 seconds), RolloutWorker_w15 (1914 seconds), RolloutWorker_w16 (1913 seconds), RolloutWorker_w17 (1914 seconds), RolloutWorker_w18 (1914 seconds), RolloutWorker_w19 (1914 seconds), RolloutWorker_w20 (1915 seconds), RolloutWorker_w21 (1915 seconds), RolloutWorker_w22 (1915 seconds), RolloutWorker_w23 (1915 seconds), RolloutWorker_w24 (1915 seconds), RolloutWorker_w25 (1915 seconds), RolloutWorker_w26 (1915 seconds), RolloutWorker_w27 (1915 seconds), RolloutWorker_w28 (1915 seconds), RolloutWorker_w29 (1915 seconds), RolloutWorker_w30 (1915 seconds), RolloutWorker_w31 (1915 seconds)
[2025-09-21 19:37:08,549][3098570] Loop batcher_evt_loop terminating...
[2025-09-21 19:37:08,560][3098297] Stopping training due to lack of heartbeats from <class 'sample_factory.algo.learning.learner_worker.LearnerWorker'>, <class 'sample_factory.algo.sampling.inference_worker.InferenceWorker'>, <class 'sample_factory.algo.sampling.rollout_worker.RolloutWorker'>
[2025-09-21 19:37:08,561][3098297] Heartbeat reconnected after 1915 seconds from LearnerWorker_p0
[2025-09-21 19:37:08,572][3098297] Heartbeat reconnected after 1915 seconds from InferenceWorker_p0-w0
[2025-09-21 19:37:08,574][3098297] Component Batcher_0 stopped!
[2025-09-21 19:37:08,576][3098297] Waiting for ['LearnerWorker_p0', 'InferenceWorker_p0-w0', 'RolloutWorker_w0', 'RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w4', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w11', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w14', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w18', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,612][3098570] Removing ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001190_1218560.pth
[2025-09-21 19:37:08,621][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001227_1256448.pth...
[2025-09-21 19:37:08,639][3098647] Weights refcount: 2 0
[2025-09-21 19:37:08,641][3098647] Stopping InferenceWorker_p0-w0...
[2025-09-21 19:37:08,643][3098647] Loop inference_proc0-0_evt_loop terminating...
[2025-09-21 19:37:08,642][3098297] Component InferenceWorker_p0-w0 stopped!
[2025-09-21 19:37:08,646][3098297] Waiting for ['LearnerWorker_p0', 'RolloutWorker_w0', 'RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w4', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w11', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w14', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w18', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,658][3098570] Saving ./train_dir/RotationDynamicMaxRange/checkpoint_p0/checkpoint_000001227_1256448.pth...
[2025-09-21 19:37:08,663][3098297] Component RolloutWorker_w11 stopped!
[2025-09-21 19:37:08,663][3098657] Stopping RolloutWorker_w11...
[2025-09-21 19:37:08,663][3098297] Waiting for ['LearnerWorker_p0', 'RolloutWorker_w0', 'RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w4', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w14', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w18', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,663][3098657] Loop rollout_proc11_evt_loop terminating...
[2025-09-21 19:37:08,665][3098651] Stopping RolloutWorker_w4...
[2025-09-21 19:37:08,666][3098651] Loop rollout_proc4_evt_loop terminating...
[2025-09-21 19:37:08,669][3098297] Component RolloutWorker_w4 stopped!
[2025-09-21 19:37:08,669][3098297] Waiting for ['LearnerWorker_p0', 'RolloutWorker_w0', 'RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w14', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w18', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,684][3098297] Component LearnerWorker_p0 stopped!
[2025-09-21 19:37:08,684][3098570] Stopping LearnerWorker_p0...
[2025-09-21 19:37:08,685][3098570] Loop learner_proc0_evt_loop terminating...
[2025-09-21 19:37:08,685][3098297] Waiting for ['RolloutWorker_w0', 'RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w14', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w18', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,686][3098297] Heartbeat reconnected after 1914 seconds from RolloutWorker_w17
[2025-09-21 19:37:08,702][3098649] Stopping RolloutWorker_w0...
[2025-09-21 19:37:08,702][3098297] Component RolloutWorker_w0 stopped!
[2025-09-21 19:37:08,702][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w14', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w18', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,702][3098649] Loop rollout_proc0_evt_loop terminating...
[2025-09-21 19:37:08,703][3098297] Component RolloutWorker_w14 stopped!
[2025-09-21 19:37:08,703][3098668] Stopping RolloutWorker_w14...
[2025-09-21 19:37:08,703][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w18', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,704][3098668] Loop rollout_proc14_evt_loop terminating...
[2025-09-21 19:37:08,706][3098297] Component RolloutWorker_w18 stopped!
[2025-09-21 19:37:08,707][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w12', 'RolloutWorker_w13', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,713][3098297] Component RolloutWorker_w13 stopped!
[2025-09-21 19:37:08,713][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w12', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,713][3098666] Stopping RolloutWorker_w13...
[2025-09-21 19:37:08,710][3098675] Stopping RolloutWorker_w18...
[2025-09-21 19:37:08,714][3098666] Loop rollout_proc13_evt_loop terminating...
[2025-09-21 19:37:08,721][3098297] Component RolloutWorker_w12 stopped!
[2025-09-21 19:37:08,721][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w26', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,721][3098663] Stopping RolloutWorker_w12...
[2025-09-21 19:37:08,722][3098663] Loop rollout_proc12_evt_loop terminating...
[2025-09-21 19:37:08,715][3098675] Loop rollout_proc18_evt_loop terminating...
[2025-09-21 19:37:08,733][3098297] Component RolloutWorker_w26 stopped!
[2025-09-21 19:37:08,733][3098690] Stopping RolloutWorker_w26...
[2025-09-21 19:37:08,733][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w2', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,737][3098690] Loop rollout_proc26_evt_loop terminating...
[2025-09-21 19:37:08,739][3098297] Component RolloutWorker_w2 stopped!
[2025-09-21 19:37:08,739][3098652] Stopping RolloutWorker_w2...
[2025-09-21 19:37:08,740][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w17', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,740][3098652] Loop rollout_proc2_evt_loop terminating...
[2025-09-21 19:37:08,742][3098297] Heartbeat reconnected after 1915 seconds from RolloutWorker_w22
[2025-09-21 19:37:08,763][3098297] Component RolloutWorker_w17 stopped!
[2025-09-21 19:37:08,763][3098671] Stopping RolloutWorker_w17...
[2025-09-21 19:37:08,763][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w25', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,764][3098671] Loop rollout_proc17_evt_loop terminating...
[2025-09-21 19:37:08,786][3098297] Component RolloutWorker_w25 stopped!
[2025-09-21 19:37:08,786][3098684] Stopping RolloutWorker_w25...
[2025-09-21 19:37:08,786][3098656] Stopping RolloutWorker_w8...
[2025-09-21 19:37:08,787][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w8', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,787][3098297] Component RolloutWorker_w8 stopped!
[2025-09-21 19:37:08,787][3098684] Loop rollout_proc25_evt_loop terminating...
[2025-09-21 19:37:08,787][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w10', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,787][3098656] Loop rollout_proc8_evt_loop terminating...
[2025-09-21 19:37:08,794][3098665] Stopping RolloutWorker_w10...
[2025-09-21 19:37:08,795][3098683] Stopping RolloutWorker_w22...
[2025-09-21 19:37:08,795][3098665] Loop rollout_proc10_evt_loop terminating...
[2025-09-21 19:37:08,795][3098683] Loop rollout_proc22_evt_loop terminating...
[2025-09-21 19:37:08,796][3098297] Component RolloutWorker_w10 stopped!
[2025-09-21 19:37:08,796][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w22', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,797][3098297] Component RolloutWorker_w22 stopped!
[2025-09-21 19:37:08,797][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w21', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,798][3098297] Component RolloutWorker_w21 stopped!
[2025-09-21 19:37:08,798][3098680] Stopping RolloutWorker_w21...
[2025-09-21 19:37:08,798][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w30', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,798][3098680] Loop rollout_proc21_evt_loop terminating...
[2025-09-21 19:37:08,799][3098297] Component RolloutWorker_w30 stopped!
[2025-09-21 19:37:08,799][3098691] Stopping RolloutWorker_w30...
[2025-09-21 19:37:08,800][3098691] Loop rollout_proc30_evt_loop terminating...
[2025-09-21 19:37:08,801][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w27', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,803][3098297] Component RolloutWorker_w27 stopped!
[2025-09-21 19:37:08,804][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w20', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,802][3098688] Stopping RolloutWorker_w27...
[2025-09-21 19:37:08,806][3098688] Loop rollout_proc27_evt_loop terminating...
[2025-09-21 19:37:08,818][3098297] Component RolloutWorker_w20 stopped!
[2025-09-21 19:37:08,818][3098679] Stopping RolloutWorker_w20...
[2025-09-21 19:37:08,818][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w28', 'RolloutWorker_w29', 'RolloutWorker_w31'] to stop...
[2025-09-21 19:37:08,819][3098679] Loop rollout_proc20_evt_loop terminating...
[2025-09-21 19:37:08,838][3098692] Stopping RolloutWorker_w31...
[2025-09-21 19:37:08,839][3098297] Component RolloutWorker_w31 stopped!
[2025-09-21 19:37:08,839][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w23', 'RolloutWorker_w24', 'RolloutWorker_w28', 'RolloutWorker_w29'] to stop...
[2025-09-21 19:37:08,840][3098692] Loop rollout_proc31_evt_loop terminating...
[2025-09-21 19:37:08,844][3098297] Component RolloutWorker_w23 stopped!
[2025-09-21 19:37:08,844][3098674] Stopping RolloutWorker_w23...
[2025-09-21 19:37:08,845][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w24', 'RolloutWorker_w28', 'RolloutWorker_w29'] to stop...
[2025-09-21 19:37:08,845][3098674] Loop rollout_proc23_evt_loop terminating...
[2025-09-21 19:37:08,851][3098297] Component RolloutWorker_w29 stopped!
[2025-09-21 19:37:08,851][3098297] Waiting for ['RolloutWorker_w1', 'RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w24', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,853][3098297] Component RolloutWorker_w1 stopped!
[2025-09-21 19:37:08,853][3098297] Waiting for ['RolloutWorker_w3', 'RolloutWorker_w5', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w24', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,853][3098648] Stopping RolloutWorker_w1...
[2025-09-21 19:37:08,851][3098693] Stopping RolloutWorker_w29...
[2025-09-21 19:37:08,854][3098648] Loop rollout_proc1_evt_loop terminating...
[2025-09-21 19:37:08,854][3098693] Loop rollout_proc29_evt_loop terminating...
[2025-09-21 19:37:08,865][3098297] Component RolloutWorker_w5 stopped!
[2025-09-21 19:37:08,865][3098653] Stopping RolloutWorker_w5...
[2025-09-21 19:37:08,866][3098297] Waiting for ['RolloutWorker_w3', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w15', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w24', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,866][3098653] Loop rollout_proc5_evt_loop terminating...
[2025-09-21 19:37:08,885][3098297] Component RolloutWorker_w15 stopped!
[2025-09-21 19:37:08,885][3098667] Stopping RolloutWorker_w15...
[2025-09-21 19:37:08,885][3098297] Waiting for ['RolloutWorker_w3', 'RolloutWorker_w6', 'RolloutWorker_w7', 'RolloutWorker_w9', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w24', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,885][3098297] Component RolloutWorker_w7 stopped!
[2025-09-21 19:37:08,885][3098655] Stopping RolloutWorker_w7...
[2025-09-21 19:37:08,886][3098297] Waiting for ['RolloutWorker_w3', 'RolloutWorker_w6', 'RolloutWorker_w9', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w24', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,885][3098667] Loop rollout_proc15_evt_loop terminating...
[2025-09-21 19:37:08,886][3098297] Component RolloutWorker_w24 stopped!
[2025-09-21 19:37:08,886][3098687] Stopping RolloutWorker_w24...
[2025-09-21 19:37:08,886][3098297] Waiting for ['RolloutWorker_w3', 'RolloutWorker_w6', 'RolloutWorker_w9', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,887][3098687] Loop rollout_proc24_evt_loop terminating...
[2025-09-21 19:37:08,886][3098655] Loop rollout_proc7_evt_loop terminating...
[2025-09-21 19:37:08,890][3098658] Stopping RolloutWorker_w9...
[2025-09-21 19:37:08,891][3098297] Component RolloutWorker_w9 stopped!
[2025-09-21 19:37:08,891][3098297] Waiting for ['RolloutWorker_w3', 'RolloutWorker_w6', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,891][3098658] Loop rollout_proc9_evt_loop terminating...
[2025-09-21 19:37:08,895][3098297] Component RolloutWorker_w6 stopped!
[2025-09-21 19:37:08,895][3098654] Stopping RolloutWorker_w6...
[2025-09-21 19:37:08,895][3098297] Waiting for ['RolloutWorker_w3', 'RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,895][3098654] Loop rollout_proc6_evt_loop terminating...
[2025-09-21 19:37:08,897][3098297] Component RolloutWorker_w3 stopped!
[2025-09-21 19:37:08,897][3098650] Stopping RolloutWorker_w3...
[2025-09-21 19:37:08,898][3098297] Waiting for ['RolloutWorker_w16', 'RolloutWorker_w19', 'RolloutWorker_w28'] to stop...
[2025-09-21 19:37:08,900][3098650] Loop rollout_proc3_evt_loop terminating...
[2025-09-21 19:37:08,905][3098297] Component RolloutWorker_w28 stopped!
[2025-09-21 19:37:08,905][3098689] Stopping RolloutWorker_w28...
[2025-09-21 19:37:08,905][3098297] Waiting for ['RolloutWorker_w16', 'RolloutWorker_w19'] to stop...
[2025-09-21 19:37:08,906][3098689] Loop rollout_proc28_evt_loop terminating...
[2025-09-21 19:37:08,914][3098297] Component RolloutWorker_w19 stopped!
[2025-09-21 19:37:08,914][3098297] Waiting for ['RolloutWorker_w16'] to stop...
[2025-09-21 19:37:08,914][3098678] Stopping RolloutWorker_w19...
[2025-09-21 19:37:08,914][3098678] Loop rollout_proc19_evt_loop terminating...
[2025-09-21 19:37:08,927][3098297] Component RolloutWorker_w16 stopped!
[2025-09-21 19:37:08,927][3098669] Stopping RolloutWorker_w16...
[2025-09-21 19:37:08,928][3098297] Waiting for process learner_proc0 to stop...
[2025-09-21 19:37:08,928][3098669] Loop rollout_proc16_evt_loop terminating...
[2025-09-21 19:37:10,616][3098297] Waiting for process inference_proc0-0 to join...
[2025-09-21 19:37:10,616][3098297] Waiting for process rollout_proc0 to join...
[2025-09-21 19:37:10,616][3098297] Waiting for process rollout_proc1 to join...
[2025-09-21 19:37:10,617][3098297] Waiting for process rollout_proc2 to join...
[2025-09-21 19:37:10,617][3098297] Waiting for process rollout_proc3 to join...
[2025-09-21 19:37:10,692][3098297] Waiting for process rollout_proc4 to join...
[2025-09-21 19:37:10,692][3098297] Waiting for process rollout_proc5 to join...
[2025-09-21 19:37:10,794][3098297] Waiting for process rollout_proc6 to join...
[2025-09-21 19:37:10,925][3098297] Waiting for process rollout_proc7 to join...
[2025-09-21 19:37:10,926][3098297] Waiting for process rollout_proc8 to join...
[2025-09-21 19:37:10,926][3098297] Waiting for process rollout_proc9 to join...
[2025-09-21 19:37:10,926][3098297] Waiting for process rollout_proc10 to join...
[2025-09-21 19:37:10,926][3098297] Waiting for process rollout_proc11 to join...
[2025-09-21 19:37:10,926][3098297] Waiting for process rollout_proc12 to join...
[2025-09-21 19:37:10,927][3098297] Waiting for process rollout_proc13 to join...
[2025-09-21 19:37:10,927][3098297] Waiting for process rollout_proc14 to join...
[2025-09-21 19:37:10,927][3098297] Waiting for process rollout_proc15 to join...
[2025-09-21 19:37:10,927][3098297] Waiting for process rollout_proc16 to join...
[2025-09-21 19:37:10,982][3098297] Waiting for process rollout_proc17 to join...
[2025-09-21 19:37:10,983][3098297] Waiting for process rollout_proc18 to join...
[2025-09-21 19:37:10,983][3098297] Waiting for process rollout_proc19 to join...
[2025-09-21 19:37:10,983][3098297] Waiting for process rollout_proc20 to join...
[2025-09-21 19:37:10,983][3098297] Waiting for process rollout_proc21 to join...
[2025-09-21 19:37:10,984][3098297] Waiting for process rollout_proc22 to join...
[2025-09-21 19:37:10,984][3098297] Waiting for process rollout_proc23 to join...
[2025-09-21 19:37:10,984][3098297] Waiting for process rollout_proc24 to join...
[2025-09-21 19:37:10,984][3098297] Waiting for process rollout_proc25 to join...
[2025-09-21 19:37:10,984][3098297] Waiting for process rollout_proc26 to join...
[2025-09-21 19:37:10,985][3098297] Waiting for process rollout_proc27 to join...
[2025-09-21 19:37:10,986][3098297] Waiting for process rollout_proc28 to join...
[2025-09-21 19:37:10,986][3098297] Waiting for process rollout_proc29 to join...
[2025-09-21 19:37:10,987][3098297] Waiting for process rollout_proc30 to join...
[2025-09-21 19:37:10,987][3098297] Waiting for process rollout_proc31 to join...
[2025-09-21 19:37:10,988][3098297] Batcher 0 profile tree view:
batching: 15.7126, releasing_batches: 0.0833
[2025-09-21 19:37:10,989][3098297] InferenceWorker_p0-w0 profile tree view:
wait_policy: 0.0052
  wait_policy_total: 5152.9707
update_model: 25.8617
  weight_update: 0.0084
one_step: 0.0103
  handle_policy_step: 1439.2774
    deserialize: 27.0127, stack: 8.6294, obs_to_device_normalize: 187.3552, forward: 938.2616, send_messages: 103.9601
    prepare_outputs: 91.9715
      to_cpu: 17.1339
[2025-09-21 19:37:10,991][3098297] Learner 0 profile tree view:
misc: 0.0205, prepare_batch: 16.7792
train: 505.6709
  epoch_init: 0.0236, minibatch_init: 0.0181, losses_postprocess: 0.1879, kl_divergence: 1.1281, after_optimizer: 4.7740
  calculate_losses: 157.9784
    losses_init: 0.0193, forward_head: 2.6422, bptt_initial: 1.9652, tail: 3.9157, advantages_returns: 0.2273, losses: 0.8998
    bptt: 147.7122
      bptt_forward_core: 147.0429
  update: 340.5971
    clip: 2.8631
[2025-09-21 19:37:10,994][3098297] RolloutWorker_w0 profile tree view:
wait_for_trajectories: 0.2180, enqueue_policy_requests: 10.1786, env_step: 6768.9523, overhead: 9.1462, complete_rollouts: 1.2667
save_policy_outputs: 17.0058
  split_output_tensors: 6.8801
[2025-09-21 19:37:10,995][3098297] RolloutWorker_w31 profile tree view:
wait_for_trajectories: 0.2142, enqueue_policy_requests: 9.9170, env_step: 6754.8065, overhead: 8.9403, complete_rollouts: 1.0888
save_policy_outputs: 17.2644
  split_output_tensors: 6.8279
[2025-09-21 19:37:10,996][3098297] Loop Runner_EvtLoop terminating...
[2025-09-21 19:37:10,997][3098297] Runner profile tree view:
main_loop: 6857.8465
[2025-09-21 19:37:10,998][3098297] Collected {0: 1256448}, FPS: 183.2
